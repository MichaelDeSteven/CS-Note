# 计算机网络

## 概述

### 定义

计算机网络：网络是由若干个计算机和连接这些计算机的链路组成。

### 互联网的组成部分

互联网由边缘部分和核心部分组成

* 边缘部分：由所有连接在互联网上的主机组成
* 核心部分：将这些主机连接起来的路由器组成，为边缘部分提供服务

### 端系统通信方式

* 客户-服务器模式（CS结构）：一端作为客户向服务器请求，另一端作为服务器负责响应客户的请求
* 对等模式（P2P结构）：不区分客户和服务器，主机能充当客户也能作为服务器向其它主机提供服务



### 电路交换和分组交换

#### 电路交换

电路交换需要建立一条专门的物理线路，通话的两个用户始终占用端到端的通信资源，直到双方通信结束，电路交换必定是是面向连接的，需要经过建立连接—通信—释放连接这几个阶段

缺点：计算机网络具有突发性的特点，由于通信过程中不可能一直使用传输链路，因此电路交换对线路的利用率很低

优点：由于通信双方始终占用端到端的通信资源，因此电路交换保证了可靠性

#### 分组交换

报文：要发送的整块数据

分组：将较长的报文划分为一个个更小的等长数据段，在每一个数据段前面加上由必要控制信息组成的首部后，称为分组，分组是互联网中传送的数据单元

特点：采用存储转发技术，首先主机将报文划分成多个分组，路由器收到这些分组后首先会暂时存储起来，检查其首部，查找转发表，每个分组都独立地选择传输路径，待所有分组到达最终目的地时，接收端会根据分组的首部将分组还原成报文

优点

* 高速：使用存储转的分组交换，实质采用了数据通信的过程中断续分配带宽的策略，提高了通信线路的传输效率
* 迅速：以分组为传输单位，分组交换可以不用实现链接就能够向其他主机发送分组
* 灵活：路由器根据分组的目的地能够为独立地为每一个分组选择合适的转发路由
* 可靠：分组交换拥有保证可靠性的网络协议如TCP协议。

缺点：存在时延问题，例如分组在各个路由器存储转发时需要排队，造成一定的排队时延







### 计算机网络性能指标

1. **速率**：单位时间内比特的传输速率

2. **网络带宽**：单位时间内最高的传输速率

3. **吞吐量**：单位时间内网络的数据量

4. **时延**：又分为排队时延、处理时延、发送时延、传播时延

5. **时延带宽积**：传播时延*网络带宽

6. **往返时间**：在很多情况下，互联网上的信息往往是双向交互，因此需要知道它们的往返时间

7. **利用率**：分为信道利用率和网络利用率，利用率和时延是一对矛盾关系，利用率越高，时延也就越高



### 计算机网络体系结构

计算机网络采用分层的好处

1. 各层之间相互独立，将复杂的计算机网络分解成若干个易处理的问题，降低问题的复杂度，每一层不需要知道下一层如何实现，而是直接调用该层的接口服务
2. 灵活性好：当某一层需要发生变化时，接口关系不变，那么直接或者间接调用当前层的接口将不受影响
3. 易于实现和维护：分层设计使得计算机网络这样一个庞大而复杂的系统变得易于实现和调试

一般有三种计算机网络分层：OSI七层模型、5层协议以及TCP/IP的4层体系

#### TCP/IP

TCP/IP由应用层、传输层、网络层、网络接口层组成

#### 5层协议

由应用层、传输层、网络层、数据链路层、物理层

#### OSI七层模型

OSI七层模型自底向上有：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层

* 物理层：考虑的是怎么样在传输媒体上传输数据比特流，而不是具体的传输媒体。物理层的作用是尽可能屏蔽通信手段和传输媒体的差异，使数据链路层感受不到这些差异
* 数据链路层：为了解决两台主机的数据传输。发送时报文是一段一段的链路上传输的，这就需要专门的链路层协议。将网络层传下来的IP数据包封装成帧，每一帧都包含了数据和必要的控制信息（同步信息、地址信息、差错控制），接收数据时，还需要直到数据部分的起始和结束的比特，才能提取出数据上交给网络层
* 网络层：主要负责为不同主机提供通信服务，使用了IP地址来标识不同的主机，确定数据包传输路径和负责将数据包转发到目的地
* 传输层：负责向两台主机的进程之间的通信提供通用的服务，主要使用的是TCP/UDP协议
* 会话层：在不同的机器上的用户建立以及管理会话
* 表示层：数据的压缩、加密解密
* 应用层：为特定的应用程序提供传输服务



![](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E7%BD%91%E7%BB%9C/pic/osi.png)





## 物理层

主要任务：将数据链路层上的帧转换成比特流，然后在传输媒体上传输，同时尽可能屏蔽来自传输媒体或者传输手段的差异



### 网络设备

#### 集线器

集线器位于物理层，它是一个具有多个端口的设备，主要功能是对接收的信号进行再生整形和放大，集线器不智能不会过滤数据，唯一的作用是将某一端口接收到的比特流复制到它所有端口，连接到该集线器的所有设备都可以收到数据。这种做法会产生安全问题，同时也会对网络造成不必要的带宽浪费

#### 网桥

多个集线器连接在了一起，又是集线器时广播通信，所以我们需要一种设备，能够有效的隔离子网。网桥的出现能够使得局域网得到有效的划分

网桥是位于数据链路层的，其工作原理是它内部有含有一张过滤表，网桥工作一段时间后会记录所有出口的MAC地址，当网桥收到数据帧检查目的MAC地址，然后再确定将该帧转发到哪一个接口，或把它丢弃



#### 交换机

交换机工作在数据链路层，交换机与集线器很相似，也是一个具有多个端口的设备，但是它与集线器不同的地方在于它是“智能”的，它拥有自学习的功能。同时它也是一个多接口网桥，网桥只能一次分析和转发一个帧，而交换机具有并行性，同时连通多对接口，使多对主机能同时通信，通信过程中是独占传输媒体、无碰撞地传输数据。

自学习过程

![](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E7%BD%91%E7%BB%9C/pic/自学习.png)



#### 路由器

路由器工作在网络层，当它收到一个数据包时会检查数据包的IP地址，IP地址不合法则直接丢弃，若IP地址属于自己网络就接受它，如果不是发送给自己所在网络的将会查找路由表将该数据包转发到目的路由



#### 网卡

位于数据链路层，该硬件标识了硬件地址又称为物理地址或MAC地址，由48位构成



## 数据链路层

* 链路：指的是相邻结点传输数据的物理路线
* 数据链路：链路加上一些必要的通信协议来控制数据的传输

### 基本问题

* 封装成帧：在数据包的前后加上首部和尾部，然后就构成了帧，在帧首部和尾部进行帧定界，来确定帧的开始和结束位置
* 透明传输：解决数据部分被当作是帧的结尾从而影响数据的传输的问题，可以采用字节填充的方式或者加入转义字符
* 差错检测：比特传输过程中，有可能出现比特差错：0变1，1变0，数据链路层需要有差错检测的措施，一般采用CRC冗余校验



### 点对点信道

#### ppp协议

**构成**

![](https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=353916427,4220333459&fm=26&gp=0.jpg?ynotemdtimestamp=1610158026833)



* F（flag）字段表示PPP协议的边界，值为0X7E
* A（address）字段表示地址，由于是点到点的，所以值始终为FF
* C（Controll）：控制字段，0x03目前没有特殊意义
* 协议字段：LCP（链路控制协议）
* FCD：帧校验序列，通过循环冗余



**字节填充**

* 信息字段出现0x7E则转化为（0x7D, 0x5E）
* 信息字段出现0x7D则转化为（0x7D,0x5D）
* 信息字段出现小于0x20的字符，则在该字符前加入一个0x7D，同时将该字符的编码加以改变，比如0x03会转化为(0x7D,0x23)



**零比特填充**

* 发送端扫描数据字段，出现连续5个1则立即填入1个0
* 接收端扫描数据字段，出现连续5个1则把后面的0删除



**CRC循环冗余校验**

* 发送端将数据分组，假定每组k个比特，CRC运算就是将待传送数据添加待检测的冗余码，然后构成一个帧发送出去
* 假定冗余码为n位，那么就在带传送数据后面加入n位0得到M，双方协商一个除数P，然后M除以P得到余数R即为冗余码，将冗余码添加到M即为发送的数据
* 接收端将接收的数据以帧为单位进行CRC检验：把每一个帧都除以同一个除数P，检查余数R是否为0，如果R不为0那么这个帧出现了差错，将其丢弃





### 广播信道

* 局域网：地理范围和主机数量有限，网络为一个单位所有
* 以太网：实现以太网的协议

**MAC帧格式**

![](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E7%BD%91%E7%BB%9C/pic/MAC帧格式.png)

* 以太网最大传输单元MTU=1500
* MAC帧最小为64字节，目的地址+源地址+FSC+类型一共占18个字节



#### CSMA/CD协议

* 载波监听：在发送前和发送后不断检测信道，发送前检测是为了获取发送权，发送后检测是为了及时检测发送的数据有没有与其它站碰撞
* 多点接入：说明了该网络是一个总线型网络，多个用户接入一根总线
* 碰撞检测：便发送变监听信道，当发送数据与其他站产生冲突时，则停止发送数据等待一段随机时间再发送



MTU是什么？为什么被设定为1500字节

MTU指数据链路层传输包的最大传输单元，1500字节是综合考虑了信道利用率和信道状态的折中方法，若帧长过短那么信道利用率低，而帧长过长，出错重传效率会降低。

1. 数据包越大，出错的可能性越大
2. 数据包一旦重传，重传的花费会变多，进而导致网速变慢
3. 时延增大，数据包在被完整收到的时候才会开始校验检查，确认收到的每个bit都没有出错，如果帧过大，将花费过多的时间在校验上，就无法及时将包交给上层
4. 最初以太网工作方式是采用载波监听多点接入/碰撞检测CSMA/CD，所有机器是半双工通信，因为网络是共享的，不能让机器占用太长时间网络，这样会影响其他机器的通信，同时MTU也不能过短，这和以太网帧半双工通信有关，比如在10Mbs以太网当中，争用期2τ = 51.2μs（最迟可以确定没有发生碰撞的时间）可以发送512比特即64字节，假定某个站发送了一个很短的帧，在发送完毕之前没有检测出碰撞。假定这个帧在继续向前传播到达目的站时发送了碰撞，那么目的站会收到有差错的帧，发送站却不知道这个帧发生了碰撞。





## 网络层

任务：将各种异构的网络连接起来，提供主机之间通信的服务

### 网络层提供的服务

网络层应该提供什么样的服务？为什么？

网络层提供**简单灵活、面向无连接、尽最大努力交付**的服务，即可靠交付交给端系统来负责，因为这样做的好处使得网络造价大大降低，运行方式灵活，能适应多种应用。

| 对比方面                       | 虚电路服务                                 | 数据报服务                                       |
| ------------------------------ | ------------------------------------------ | ------------------------------------------------ |
| 思路                           | 可靠通信应当由网络来保证                   | 可靠通信应当由端系统来保证                       |
| 连接的建立                     | 面向连接                                   | 面向无连接                                       |
| 终点地址                       | 仅在连接阶段使用，每个分组使用短的虚电路号 | 每个分组都有终点的完整地址                       |
| 分组的转发                     | 属于同一虚电路的分组按照同一路由进行转发   | 每个分组独立选择路由进行转发                     |
| 结点出现故障时                 | 所有通过故障结点的虚电路均不能工作         | 出故障的结点可能会丢失分组，一些路由可能发生变化 |
| 分组的顺序                     | 按顺序到达终点                             | 到达终点的时间不一定按照顺序                     |
| 端到端之间的差错处理和流量控制 | 由网络负责                                 | 由主机负责                                       |







### 网际协议IP

#### **IP数据报格式**

一个IP数据报由首部和数据组成，首部前一部分固定长度为20字节

![](https://img-blog.csdn.net/20131220194104812?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2UxMjNfemhvdXdlaQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

1. 版本：占4位，标识IP协议的版本号，如目前广泛使用的IP协议版本号为4（即IPv4）、起步阶段的IPv6
2. 首部长度：占4位，值为1表示4个字节，由于首部最短长度为20个字节，所以值最小为5，若可选字段不为4字节的整数倍，就会用填充字段来填充尾部
3. 区分服务：8位，用来获得更好的服务，一般情况不用
4. 总长度：指首部和数据之和的长度。单位为字节，16位表示数据报字段最大为$2^{16}-1$
5. 标识：占16位，计数器，用来产生IP数据报的标识
6. 标志：占3位，目前只有后两位有意义，标志字段中间一位是DF（Dont Fragment）0表示无分片，末位是MF（More Fragment）MF=1表示后面有分片
7. 片偏移：占13位，较长分组分片后，根据片偏移和标识字段来恢复原分组，片偏移单位为8字节
8. 生存时间：占8位，简称TTL（Time to Live）表明数据包的寿命，为了防止数据报无限制地在互联网兜圈子，以路由器跳数为单位，最大值为255，TTL为0则丢弃数据报
9. 协议：占8位，指明携带的数据使用了何种协议，如TCP、UDP协议，使得目的主机IP层知道应将数据部分上交给哪个协议处理
10. 首部检验和：只检验数据报的首部，路由器每次收到数据报都要重新计算检验和，不检验数据部分可以减少计算工作量
11. 源地址：32位
12. 目的地址：32位
13. 可选字段：用来支持排除、测量和安全，可选字段长度可变，最终会被填充成为4字节的整数倍
14. 数据部分：数据包携带的信息

#### IP地址

介绍：IP地址就是给每个连接在互联网上的主机（或者路由器）分配一个全世界范围内的唯一的32位标识符

特点

* IP地址是分等级的：首先是便于管理，IP地址管理机构在分配IP地址时只分配网络号，而剩下的主机号由得到的网络号单位自行分配。其次是路由器根据网络号来转发分组，大大减少了路由器表项的条目数，从而减少了路由表的占用内存。
* IP地址是标识主机或者路由器的接口
* 用转发器或者网桥连接起来的若干个局域网仍为一个网络
* IP地址是平等的



**编制方式**

1. **二级地址**

IP地址:={<网络号>, <主机号>}

根据网络号来划分A、B、C、D、E类地址

![](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=2428428384,3350566780&fm=26&gp=0.jpg?ynotemdtimestamp=1610608168894)



记忆技巧

* 从0-255划分为一半，取右半段继续划分直到总段数为5段则划分完毕

```
 A：0xxxxxxxx  私有地址：10.0.0.0-10.255.255.255
 B：10xxxxxx 私有地址：172.16.0.0-172.16.255.255
 C：110xxxxx 私有地址：192.168.0.0-192.168.255.255
 D：1110xxxx
 E：1111xxxx
```



2. 划分子网

解决的问题：解决了IP地址利用率低的问题，假如一个网段申请了C类地址，该网络可以接入255台主机，但是却用不了那么多，因此利用子网划分的技术可以将该网段分成两个子网。

IP地址:={<网络号>,<子网号>,<主机号>}

子网掩码：由连续的1组成用来判断网络号和子网



3. 构造超网

解决的问题：通过路由聚合将相同网络前缀的网络号合并在了一起，减少了路由表项数目的大小

IP地址:={<网络前缀号>, <主机号>}

无分类编址CIDR消除了传统的A、B和C类地址以及子网的概念，使用网络前缀和主机号来进行编码，网络前缀的长度可以根据需要变化。

路由表查找算法：最长前缀匹配，使用了字典树的底层数据结构



#### IP地址与MAC地址

1. MAC地址是硬件实现的，也叫做物理地址，一般是无法改变的，而IP地址是逻辑实现的，通过分配或者自定
2. 物理地址是物理层、数据链路层使用的，而IP地址是网络层以上使用的地址
3. IP地址是指向最终目的地的，而数据包没经过下一跳路由器，其物理地址都会发生改变

使用IP地址通信而不使用MAC地址通信的原因：世界上的网络大多都是异构的，各个网络进行通信必须进行非常复杂的硬件地址转换，而使用通过ARP地址解析协议，通过虚拟的IP，降低了硬件地址转换的复杂度



#### 分组转发算法

* 普通的路由转发算法

1. 根据数据包获取目的IP地址D进而网络地址N
2. 判断是否为本地，若网络N与此路由器直接相连，则直接将数据报交付给目的主机D，否则是间接交付，执行3
3. 特定主机路由：若路由表中的目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由，否则执行4
4. 下一跳路由：若路由表有到达网络地址N的路由，则把数据报传送给路由表所指明的下一跳路由（由路由器找到下一跳路由IP地址，然后由网络接口软件使用ARP将IP地址转化为硬件地址，并将此物理地址放在链路层的MAC帧的首部，然后根据该物理地址找到下一条路由）
5. 默认路由：若路由表中有默认路由，则把数据报传送给路由表中所指明的默认路由器；否则执行6
6. 分组出错：报告转发分组出错



#### 虚拟专用网VPN

作用：使外部主机访问专用网。





#### 网络地址转换NAT

作用：专用网内部主机使用本地IP地址想访问互联网，需要把将本地IP转换为全球IP



### 地址解析协议ARP

作用：已知一个主机或路由器的IP地址，需要找到其MAC地址

过程

1. 若ARP高速缓存表中有指定IP地址到物理地址的映射则找到结果，否则执行2
2. ARP进程在本局域网上广播一个ARP请求分组
3. 本局域网内的所有主机上运行ARP进程都收到此ARP请求分组
4. 某主机与ARP请求分组要查询的IP地址一致，就收下这个ARP请求分组（当前主机ARP表也会保存发起者的IP地址到硬件地址的映射），并向发出者发送ARP响应分组（单播），这个响应分组携带了当前主机的物理地址
5. 发出者收到响应分组后，将目标IP地址对应的物理地址存入ARP高速缓存表



### 网际控制报文协议ICMP

作用：为了更加有效地转发IP数据报和提高交付成功机会

#### ICMP询问报文



1. 回送请求和回答报文：主机或路由器向特定的目的主机发送回送请求报文，收到该报文的主机必须向源地址发送会送回答报文，用于了解目的主机是否可达和状态
2. 时间戳请求和回答报文：用于请求目的路由器或者主机回答当前的日期和时间，用于时钟同步和测量时间

#### ICMP差错报文

1. 终点不可达：当路由器或主机不能交付数据报时就向源点发送终点不可达差错报告报文
2. 时间超过：当路由器收到生存时间为0的数据报，丢弃该数据报后，再向源点发送时间超过差错报告报文
3. 参数问题：当数据报首部字段的值不正确时，就丢弃该数据报，并向源点发送参数问题请求报文
4. 改变路由（重定向）：路由器把改变路由报文发送给主机，让主机知道下次应将数据报发送到另外的路由

#### 应用

* PING命令：测试两台主机的连通性

* Traceroute命令：用于跟踪路由



### 路由器结构

* 由多个输入输出端口组成的专用计算机，其任务是转发分组

路由器结构可以分为两个部分，路由选择部分和分组转发部分

![](https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=1498252813,1934406112&fm=26&gp=0.jpg)



**路由选择部分**

* 根据路由选择协议构造出路由器表，同时经常或者定期和相邻的路由器交换路由信息从而不断更新和维护路由表





**分组转发部分**

* 由交换结构、输入输出端口，作用是根据交换结构中的转发表对分组进行处理，将某个输入端口进入的分组从一个合适的输出端口转发出去。



### 路由选择

理想的路由算法：正确和完整、稳定、计算简单、公平、最佳

最佳的路由算法：相对于某种特定条件下较为合理的路由算法

静态路由选择协议：简单、开销小，不能适应网络状态的变化

动态路由选择协议：自适应路由选择，能较好地适应网络状态的变化，实现较为复杂、开销也较为大

自治系统AS：互联网使用分层次的路由选择协议，因此可以把互联网划分为许多个较小的自治系统即AS，AS使用了单一的技术来管理AS内的所有路由器，这些路由器选择同一路由选择协议和共同度量来确定分组在AS内的路由，同时还使用一种AS之间的路由选择协议确定分组在AS之间的路由

内部网关协议：自治系统内选择的路由选择协议

外部网关协议：自治系统之间选择的路由选择协议



#### 内部网关协议IGP

**RIP**

基于距离向量的路由选择协议，最大的优点是简单

* 和相邻的路由器交换路由信息
* 信息包含了某网络、到达某网络所需要的跳数，下一跳的路由器
* 按固定时间间隔交换路由信息

距离向量算法

对每个相邻的路由器发送的RIP报文执行以下步骤

1. 将下一跳路由改为当前路由器，跳数均增加1
2. 检测所有条目，若原来路由表中没有目的网络N，则把该项目添加到路由表，否则执行3
3. 若下一跳路由器与原来路由表中的条目相同则直接更新（以最新的消息为准），否则执行4
4. 下一跳路由器不同，比较跳数大小，若跳数比原来小则更新（距离变小，应该更新）否则执行5
5. 什么都不做

评价

1. 实现简单开销小，适用于小型的网络，最大跳数为16（表示不可达）
2. 好消息传得快，坏消息传得慢（当网络故障时，要经过较长时间才能将此信息传送给所有的路由器）



**OSPF**

基于Dijkstra算法的一种链路状态的路由选择协议，具有更新过程收敛快的特点

* 采用泛洪法向自治系统内的所有路由器发送信息
* 信息为相邻的所有路由器的链路状态（与哪些路由器相邻，到相邻路由器的代价）
* 只有当链路状态发生变化时，才向所有路由器用泛洪法发送信息

链路状态数据库：各路由器频繁交换信息后，所有路由器最终都会建立一个链路状态数据库，也即全网的拓扑结构图

区域划分

原因：为了更好地管理较大的网络，将泛洪法交换链路信息的范围缩小到某个区域，从而减小整个网络的通信量

分层次的区域划分

主干区域：位于上层的区域，标识符为0.0.0.0，用于连通下层区域



分组类型

* 问候分组：用来发现了和维持邻站的可达性
* 数据库描述分组：向邻站给出自己的链路状态数据库中的所有链路状态的摘要信息
* 链路状态请求分组：向对方请求某链路状态的项目的详细信息
* 链路状态更新分组：用泛洪法对全网更新链路状态的信息
* 链路状态确认分组：对链路状态更新分组的确认

OSPF基本操作

* 问候分组确认可达性

每两个相邻路由器每隔10s要交换一次问候分组。确认邻站是否可达

* 其它分组类型用于同步链路状态数据库

路由器并不是将自己的链路状态信息向全网广播的，虽然这样能得到完整的链路状态数据库，但是开销太大，OSPF是这样做的：让相邻的路由器用数据库描述分组用来交换自己的链路状态摘要信息，交换完数据库描述分组后，若当前的数据库发现缺少了某些链路状态的详细信息，就会发起链路状态请求分组来进行同步

* 路由器链路状态发生变化

当一个路由器链路状态发生变化，该路由器就使用链路状态更新分组，用泛洪法向全网更新链路状态。这种泛洪法是**可靠**的，所谓可靠是指收到更新分组的路由器会发送确认分组

其它特点

1. 灵活：对不同的链路设置不同的代价
2. 负载平衡
3. 支持可变长度的子网划分和无分类编制的CIDR
4. 所有OSPF路由器之间交换的分组都具有鉴别的功能，保证了仅在信赖的路由器交换链路状态信息





#### 外部网关协议BGP

特点

1. 每个自治系统最少选择一个路由器作为发言人
2. 使用TCP连接，再建立BGP会话交换路由信息





## 传输层

### 概念

两台主机之间的通信实质就是两台主机的应用进程相互通信，而传输层就是负责应用进程之间的**逻辑通信**，提供多路的复用和分用

#### 端口

定义：由于各个操作系统指派进程标识符可能格式不同，而且进程的创建和销毁是动态的，因此采用协议端口号的方式来标识应用进程，端口号由16位标识又分为熟知端口号（0-1023）和短暂端口号

复用：将多个应用进程数据通过传输层传送到网络层

分用：将网络层收到的数据分发给各个应用进程

![](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=3215791253,4029579005&fm=26&gp=0.jpg)

#### TCP与UDP的比较

UDP只在IP数据报之上增加了很少的一点功能：复用和分用功能，差错检测功能

* TCP是可靠传输，UDP是尽最大努力交付
* TCP是面向连接传输，UDP无连接
* TCP有拥塞控制、流量控制，UDP则没有
* UDP是面向报文传输，而TCP是面向字节流传输
* UDP支持多播和广播，而TCP仅能一对一通信
* UDP首部开销小，而TCP的首部固定长度就有20字节

应用场景：需要可靠、准确的传输就使用TCP，不要求太准确但要求快可以使用UDP



### UDP协议

#### 格式

![](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fs3.sinaimg.cn%2Fmiddle%2Fa7f4cc614c325b22f9c72%26690&refer=http%3A%2F%2Fs3.sinaimg.cn&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1613303701&t=36dfd93b1e8232aea58c6004131580e9)

* 源端口号：2个字节
* 目的端口号：2个字节
* 用户数据报长度：2个字节，最小值为8
* 检验和：2个字节

#### 特点

* 面向无连接
* 尽最大努力交付
* 没有拥塞控制
* 支持一对一、一对多、多对一、多对多的交互通信
* 面向报文
* 首部开销小，长度只有8字节



### TCP协议

TCP是面向连接的、可靠传输协议

#### 格式

![](https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=3436320348,126020379&fm=26&gp=0.jpg?ynotemdtimestamp=1610783150747)

* 源端口号：16位
* 目的端口号：16位
* 序号字段：32位，TCP连接是面向字节流的，传送的数据流中每个字节都会编上一个序号，这个序号表示这个数据包所发送的数据的第一个字节的序号
* 确认字段：32位，期望收到下一个报文段的序号
* 数据偏移：4位，指出TCP报文数据起始距离TCP报文段的起始处有多远（即TCP首部长度）
* 保留字段：6位，保留为今后使用
* 紧急比特URG：URG=1表明紧急指针字段有效。它告诉系统此报文段有紧急数据，应尽快传送
* 确认比特ACK：ACK=1表明确认字段有效
* 推送比特PSH：PSH=1的报文段，会尽快交给应用程序，而不再等到整个缓存都填满后再向上交付
* 复位比特RST：当RST=1表明当前TCP连接出现严重差错，应释放连接，然后再重新建立连接
* 同步比特SYN：SYN=1表明这是一个连接请求或者连接接受的报文
* 终止比特FIN：FIN=1表示此报文段的发送方数据已经发送完毕，请求释放TCP连接
* 窗口字段：16位，用来让对方设置发送窗口的依据，明确指出了现在允许对方发送的数据量（例如：发送一个报文段确认号为701，窗口字段为1000时，表示发送方的接收缓存空间还可以接收1000个字节）
* 校验和字段：16位，校验包括首部和数据部分
* 紧急指针字段：16位，指出本报文段中紧急数据有多少字节（紧急数据放在了报文段数据的最前面）
* 选项字段：长度可变
* 填充字段：使报文的首部长度为4字节的整数倍



注：TCP/IP详解的保留字段为4位，新增两个字段

* 拥塞窗口减比特CWR：发送方降低它的发送速率
* ECN回显比特ECE：发送方接收到了一个更早的拥塞通告





#### 特点

* 面向连接
* 可靠传输
* 有拥塞控制
* 仅支持一对一通信
* 面向字节流
* 首部长度固定为20字节



#### 可靠传输的原理与实现

**要求**

1. 传输的信道不产生差错
2. 传输的数据无差错、不丢失、不重复、不乱序

**原理**

* 停止等待协议

概念：每发送完一个分组就停止发送，等待对方确认。在收到确认后再发送下一个分组。这种可靠传输协议成为自动重传请求（ARQ）

评价：简单但是信道利用率低



* 连续ARQ协议

![](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fblog.chinaunix.net%2Fattachment%2F201402%2F17%2F26275986_1392626885IL2q.png&refer=http%3A%2F%2Fblog.chinaunix.net&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1613394039&t=50bdb1cb0a575020584d5be5d94f82aa)

滑动窗口以字节为单位，发送方维持发送窗口，设置前沿和后沿，后沿的后面部分表示已发送且确认的，前沿的前面部分表示未发送未确认，后沿的前半部分表示已发送但是未确认，另一部分表示允许发送但是尚未发送，后沿和前沿原则上是不能后缩的（后沿不能后缩的原因是不能撤销已经确认的报文，前沿TCP强烈建议不能后缩，因为如果发送方发送了窗口的大量数据，后缩之后，就会产生错误）这个发送窗口内的分组都可以连续发送出去，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置

接收方一般采用累计确认机制，即不必对每一个收到的分组逐个发出确认，而是对按序到达的最后一个分组发送确认。这种方式的优点是容易实现，即使确认丢失也不必重传。缺点是不能向发送方正确反映已经正确收到的所有分组的信息。



* 使用超时重传和以字节为单位的滑动窗口来实现TCP的可靠传输

1. 发送窗口表示在没收到B的确认的情况下，A可以连续把窗口内的数据都发送出去，凡是已经发送过去的数据，在未收到确认之前都必须暂时保留，以便超时重传时使用
2. 发送窗口后沿的后面部分表示已经发送并收到确认，前沿表示还未发送而且也不允许发送的
3. 超时计时器用来控制重传，当发送方在一段时间没收到确认时，为了保证可靠传输，发送方会再次重传这部分数据，重置超时计时器
4. 发送方收到确认号落在发送窗口内，则发送窗口可以继续向前滑动，发送新的数据
5. 发送窗口的大小是根据接收窗口来设置的，接收方发送的确认数据包中的窗口字段的值即为发送窗口的大小
6. 超时重传有两种策略：后退N帧协议GBN和选择重传协议SR



**重传时间**

问题：重传时间的选择是一个复杂的过程，重传时间过小，会引起很多不必要的报文段重传，导致网络负荷增大，重传时间过大，会使网络的空闲时间增大，减低传输速率

TCP采用一种自适应的做法，RTT表示为两个报文的往返时间，RTTs表示加权平均往返时间，每次取到一个新的RTT样本，就将旧的RTTs和RTT进行计算



**重传二义性**

发送方发送报文段后，设定的重传时间到了，还没收到确认，于是重传报文，经过一段时间后，收到了确认报文段，这种情况下，发送方并不不能判断此确认报文段是先发送的报文段的确认还是重传的报文段确认，由于RTO的计算是基于RTT样本的，所以错误的判断可能会导致RTO的计算出现偏差



**Karn算法**

* 报文段重传就不采用往返时间的样本，这样得到的RTTs和RTO就会比较准确
* 重传超时时，将重传时间设定为原来的2倍，当不再发生重传则按照原来的方法计算RTO



**带时间戳选项字段的RTT测量**

* 由于TCP有存在累积确认的情况，比如在传输大量数据时，TCP通常采用发送两个报文段返回一个ACK的方法，而并非每一个报文都返回一个ACK，这个时候可以选择使用时间戳字段







#### 数据流与窗口管理



**延时ACK**

* TCP并不对每个报文返回一个ACK，而是利用TCP累计ACK机制。累计确认允许TCP延迟一段时间发送ACK，以便将ACK和相同方向上需要传输的数据结合发送
* 应用场景：这个捎带传输机制适用于批量数据传输
* 评价：显然TCP不能任意时长地延迟ACK，否则对方会误认为数据丢失而出现不必要的重传，采用延时ACK的方法会减少ACK传输数目，从而减少网络负担





**Nagle算法**

* 背景：假设用户只发送一个字符，加上20字节的TCP首部和20字节的IP首部，得到了41字节的数据，这样，用户仅发送一个字符，这些小包会给网络传输带来相当大的负担
* Nagle算法要求，当一个TCP连接中有在传数据，小的报文段（小于SMSS，发送端最大报文段）就不能被发送，直到所有发送的数据都收到了ACK，并且在收到ACK后，TCP会将要发送的数据整合到一个报文段发送，当到达的数据达到了MSS，就立即发送一个报文段
* 当数据较快到达而网络速率较慢时，这种方法可以明显减少所用的网络带宽



**延时ACK和Nagle算法**

* 延时ACK和Nagle算法都是为了减少网络负担所采取的措施，延时ACK是减少了ACK报文的数量，Nagle算法是减少了小包的发送，但是将这两种方式结合起来可能会造成某种程度的死锁
* 假设客户端采用的延时ACK是收到两个数据包才能返回一个ACK，而服务端使用了Nagle算法，直到收到ACK前都不能发送新数据，这样会导致死锁
* 幸运的是，死锁会在延时计时器超时后客户端发送ACK给服务端从而解除死锁，死锁期间会导致整个传输连接处于空闲状态





**流量控制**

目的：让发送方的发送速率不要太快，要让接收方及时接收

实现：采用滑动窗口机制来进行流量控制





**零窗口和持续计时器**

* 零窗口：当接收窗口为0时，即不允许发送方再发送数据，这种称为零窗口
* 情景：发送零窗口后不久，如果接收方的接收缓存又有了空间，这个时候接收方向发送方发送非零窗口报文丢失，导致接收方和发送方相互等待造成死锁

* 解决方案：TCP为每一个连接设置持续计时器，只要接收的一方收到了零窗口报文就启动持续计时器。若计时器到期就发送一个零窗口探测报文，而对方只要在确认这个零窗口探测报文给出自己的窗口值即可，若窗口值为0则重置计时器。这样就打破了死锁



**糊涂窗口综合症**

* 描述：发送端的应用程序产生数据很慢或者接收端的应用数据处理接收缓冲区数据很慢，或者两者兼有之，这样会使得应用进程之间传送的报文段很小
* 情景：假设TCP接收方的缓存已满，而交互进程的应用程序只能从接收缓存中读取一个字节，这样接收缓存空间仅能腾出1个字节，然后向发送方发送确认，并把窗口值设置为1个字节，接着发送方又发来1字节数据，接收方发回确认，仍然将窗口设置为1个字节
* 发送端解决办法（不能发送小的报文）：
  * 采用Nagle算法
* 接收端解决办法（不能通告小的窗口值）：
  * 采用Clark算法：只要有数据到达就发送确认，同时宣布窗口大小为0，直到缓存空间已经能放入具有最大长度报文段，或者缓存空间的一半已经空了
  * 延迟确认：当一个报文段到达时，不立即确认，接收端在确认收到报文段之前一直等待，直到缓存具有足够的空间为止







#### 拥塞控制

* 原因：在某段时间内，网络所需资源超过该资源所能提供的可用部分，网络性能将会变坏

* 网络资源：计算机网络的链路带宽、交换结点的缓存和处理机

* 拥塞条件：∑对资源的需求>可用资源

* 拥塞控制：为防止过多的数据注入网络中，路由器无法处理高速到达的流量而被迫丢弃数据信息（拥塞的现象），这样可以使网络中的路由器或链路不致过载导致网络瘫痪

拥塞控制与流量控制区别

拥塞控制是一个全局性的过程，流量控制是一个端到端的问题，某些拥塞控制算法由于也是由接收方告诉发送方网络出现了拥塞，必须放慢发送速率

![](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fcaopeng.blog.chinaunix.net%2Fattachment%2F201303%2F13%2F24907956_1363163240YFVF.jpg&refer=http%3A%2F%2Fcaopeng.blog.chinaunix.net&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1613463811&t=79f725d68b18a08387e9cc9f48a2603b)

**慢开始**

将cwnd设置为1个最大报文段MSS的数值，没收到一个新的报文的确认，cwnd增加1个MSS数值，这样拥塞窗口cwnd的值就随着传输轮次呈指数级增长。慢开始指它的起点低，用这样的方法来逐步增加拥塞窗口的值比一开始将cwnd值设大来说更加地合理

为防止拥塞窗口cwnd的值增加过大引起网络拥塞，还需要设置一个慢开始门限ssthresh

* 当cwnd < ssthresh时使用慢开始算法

* 当cwnd = ssthresh时既可以使用拥塞避免算法又可以使用慢开始算法

* 当cwnd > ssthresh时使用拥塞避免算法

**拥塞避免**

* 思路：让拥塞窗口cwnd缓慢地增大，每经过一个RTT就把发送方的拥塞窗口cwnd加1，因此拥塞避免阶段有加法增大的特点

网络拥塞判断

* 重传计时器超时
* 收到三个（重复的）ACK

![](https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=3431860378,2888609999&fm=11&gp=0.jpg)

无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（重传定时器超时）：

* ssthresh = max(cwnd/2，2)，cwnd = 1（Tahoe算法）
* ssthresh= max(cwnd/2，2)，cwnd=ssthresh（Reno）

执行慢开始算法

这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。 





**快重传（Reno）**

目的：让发送方尽早知道发生了个别报文段的丢失。

发送方只要接收到一连三个重复确认，就知道接收方没收到报文段，应当立即重传，这样就不会出现超时，发送方也不会误认出现了网络拥塞。



**NewReno**

* Reno算法的缺点：若网络中一次拥塞丢失多个报文，采用Reno算法如果收到了新的ACK报文，就会立即退出快重传状态进入拥塞避免状态（PACK），这样Reno算法会误认为发生了多次拥塞，导致了拥塞窗口和慢启动阈值减半，最终导致TCP发送速率变慢

* 是对快重传算法的改进：既然Reno算法误判了一次拥塞丢失多个报文和多次拥塞的情况，那么NewReno算法就将这两种情况做区分，当所有报文被应答，问题就解决了，这就是NewReno算法的思想
* 做法：记录上一个数据传输窗口的最大序列号，只有收到了不小于该序列号的应答时，才退出快重传状态



**Sack**

* Reno和NewReno算法的缺点：并不哪一个包丢失，造成重复传包的问题
* Sack算法基本思路：告知发送端哪些包丢失了、哪些需要重传
* 做法：在TCP选项设置一个SACK字段，将需要重传的数据区段设置在SACK字段中，发送端就能根据SACK字段重传丢失的包



[NewReno和SACK算法](https://blog.csdn.net/m0_38068229/article/details/80417503)





**快恢复**

当发送端收到连续三个重复的确认时，由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，而是执行快恢复算法 FR (Fast Recovery) 算法：

1. ssthresh = cwnd/2

2. cwnd = ssthresh

3. 开始执行拥塞避免算法，使拥塞窗口缓慢地线性增大。 

乘法减小加法增加（AIMD）

加法增大：拥塞避免阶段，拥塞窗口采用线性增长 

乘法减小：快重传或快恢复时，出现超时或3个重复确认，慢开始门限值ssthresh设置成拥塞窗口cwnd的一半，并大大减小cwnd的值





#### 连接管理

**三次握手**

![](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=2930509917,3519585697&fm=26&gp=0.jpg)

服务端处于监听状态

* 第一次握手：客户端（一般为主动连接一方）预先分配资源来建立TCP连接，客户端发出一个SYN报文（SYN = 1, seq=x）随机选择一个起始序号x，客户端进入SYN_SENT状态
* 第二次握手：服务端（一般为被动接收方）收到请求后，响应SYN报文给客户端（SYN = 1, ACK = 1，ack=x+1，seq=y）服务器也随机选择一个起始序号y，为了确认收到SYN报文，响应报文的会将x+1作为ack字段，确认客户端的连接请求后服务器进入了SYN_RECV状态
* 第三次握手：客户端收到了服务器的连接响应报文，客户端会再发送一个包（ACK = 1，seq = x + 1，ack = y+1）给服务器，该报文段会将y+1字段置为ack字段表示确认收到了响应报文，服务端接收成功后，双方都进入ESTABLISHED状态

为什么是三次握手，假如是两次握手呢？

![](https://user-gold-cdn.xitu.io/2020/4/5/1714a0ee5a4b4e5f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1&ynotemdtimestamp=1610886981092)

为什么是三次握手，假如是两次握手呢？

假如是两次握手，客户端向服务器连接，服务器收到确认后，如果是两次握手，服务器会在第二次握手后直接给客户端发送数据，但数据传输过程中丢失，客户端会认为连接没有建立，因此会重新进行握手，这样服务器会产生多个无效的连接，浪费连接开销。三次握手还可以防止旧的重复连接初始化而造成混乱。



**listen函数**

```c++
int listen(int sockfd, int backlog)
```



作用

* 服务器是被动连接，通过listen函数可以将服务器套接字变成监听状态
* 为当前套接字建立两个连接队列



**半连接队列**

* 客户端发送SYN包，服务端收到后回复SYN+ACK后，服务端进入SYN_RCVD状态，这个时候的socket会放入半连接队列
* 半连接队列的大小由/proc/sys/net/ipv4/tcp_max_syn_backlog控制



**全连接队列**

* 服务端收到客户端的ACK后，三次握手完成，此时socket会从半连接队列移出全连接队列
* 全连接队列大小通过/proc/sys/net/core/somaxconn



**socket函数对应的三次握手**

connect阻塞：客户端向服务端发送SYN报文，客户端进入SYN_SEND状态

accept阻塞：响应客户端，发送SYN+ACK报文给客户端，服务端进入SYN_RCVD状态

connect函数返回：收到SYN+ACK报文段，客户端向服务端发送ACK报文，客户端进入ESTABLISHED状态

accept函数返回：服务端收到ACK报文，服务端进入ESTABLISHED状态







![](https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=1797973876,956426254&fm=26&gp=0.jpg)



**四次挥手**

由于TCP连接是全双工的，因此每个方向都必须单独关闭。当某一方完成完成它的数据发送任务后就能发送一个FIN来终结这个方向的连接。

* 第一次挥手：客户向主机发送FIN报文段（FIN=1，seq=u），表示关闭当前方向的数据传送，并进入FIN-WAIT-1状态，表示没有数据要传送了。
* 第二次挥手：服务器收到FIN报文段后，向客户发送确认包（ACK=1,seq=v，ack=u+1），然后进入COLSE-WAIT状态，这时候客户进入了FIN-WAIT-2，即处于半关闭状态，若服务器还有数据要传输给客户，客户端还需要接收。
* 第三次挥手：等到服务端给客户端发送完数据后，就向客户发送FIN报文段（FIN=1,ACK=1，seq=w，ack=u+1），服务端进入LAST-ACK状态。
* 第四次挥手：客户端收到FIN报文段后，向服务器发送，回复确认报文（ACK=1,seq=u+1，ack=w+1）给服务端，服务端收到确认包后进入COLSED状态。若经过2MSL时间，没有来自服务端的FIN报文段后，客户端进入COLSED状态。

TIME-WAIT状态：TCP主动关闭方收到被动关闭方的请求关闭发送确认包后，等2MSL时间后就能到CLOSED状态

CLOSE-WAIT状态：含义是等待关闭，当对方发送连接释放请求报文，系统回应一个ACK报文给对方，则进入了CLOSE-WAIT状态，这个状态是为了确认是否还有数据要发给对方，若没有那么系统就可以发送一个FIN报文来关闭连接

MSL：最大报文段生存时间，指任何报文段在网络上存在的最长时间，超过这个时间报文将被丢弃

为什么需要2MSL时间？

若客户端发送的释放连接确认包没有被正确的接收，服务端就会重新发送一个释放连接请求报文，一去一来过程刚好2MSL，若TIME-WAIT时间过短，首先会导致客户端收到旧连接的报文，2MSL保证了这些报文从网络中消失，其次是为了保证连接能被正确关闭，若小于2MSL可能导致服务端未收到确认释放的报文，而客户端提早关闭，导致服务端到客户端的连接未被正常关闭。







### 相关问题



#### 如何实现安全可靠的udp

可以采用消息重传来实现其可靠性，采用消息重传的时候有两种方式，一种是发送者发起，另一种是接收者发起。对于发送者发起的方式，一般情况下接收者会发送一个消息包的确认。发送者维护一个计时器并重传那些在某个确定的时间段里没有收到确认的消息包。
对于接收者发起的方式，通信双方的接收者负责错误检测。在这个方式里，序列号被用于检测消息包丢失。当检测到消息包丢失，接收者请求发送者重传消息包。

发起者发起：这一类型的协议容易引起发送者溢出，因为要确认每一个发送的消息包。这种溢出现象被称为发送者（或者 ACK）内爆。

接收者发起：采用这种方法，如果消息包没有到达任何一个接收者，发送者容易因 NACK 溢出。这会引起发送者的负载过高和过多的重传。这种现像被称为 NACK内爆。Ramakrishnan et al.在 1987 年提出可以使用定时器来限制消息包重传，从而避免 NACK 内爆。在
现实应用中这种方式使用得较多。



#### QUIC

QUIC 特点，缺点

QUIC 是 Quick UDP Internet Connections 的缩写，谷歌发明的新传输协议。

与TCP相比，QUIC可以减少延迟。未被普及





![](https://pic1.zhimg.com/v2-fa0fa846a1c792845356f590a25f5574_b.png)

**解决什么问题**

* 依赖操作系统内核的协议僵化：TCP是由操作系统内核实现的，应用程序只能使用而不能修改，如果需要对TCP迭代更新，就需要升级操作系统，由于操作系统升级涉及到了底层软件和运行库的更新，因此更新也较为保守和缓慢，这导致了TCP即使拥有较好的特性更新，但是很难快速推广
* 建立连接的握手延迟大：HTTP需要使用TCP进行传输，同时HTTPS和HTTP2还需要TLS协议进行安全传输，这就导致了两次握手延迟，对于很多短连接的场景，这样的握手延迟影响大，且无法消除
* 队头阻塞：队头阻塞的根本原因是TCP是面向流传输的，使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达也不会被处理
* 所以QUIC协议选择了UDP，首先UDP是面向无连接的，不需要三次握手，优化了连接握手的延迟，同时可以在应用层面实现传输的可靠性，避开了操作系统的限制，提高了灵活性



**QUIC特性**



* 连接建立延迟低：TCP连接需要经过3次握手，QUIC实现了0RTT握手，先前与服务器建立连接的客户端缓存了大部分连接参数，因此在大部分情况下，不需要建立连接就能够传输数据
* 拥塞控制的实现，TCP的拥塞控制主要有慢启动、拥塞避免、快重传、快恢复，QUIC使用了Cubic拥塞控制算法（），同时还对拥塞控制进行了一些改进
  * 可插拔：主要体现三个方面，应用程序可以实现不同的拥塞控制算法，不用依赖操作系统，单个应用程序对不同连接可以采用不同的拥塞控制，应用程序不需要停机和升级就能对拥塞控制进行更换
  * Package Number和Stream Offset：TCP采用的是序列号和确认号来确认消息的有序到达，QUIC使用了严格递增Package Number代替了序列号，严格递增避免了重传二义性，但是重传时仍然需要确认包的顺序，所以有了Stream Offset保证了数据的有序性
  * SACK选项：TCP头部最大为60字节，固定长度为20字节，时间戳字段占10字节，而SACK选项占8字节，因此最多支持3个区间选择重传，但是QUIC提供了256的Ack Block，丢包率较高的情况下，能够快速的恢复网络
  * 延迟ACK：TCP的时间戳字段存在一个问题，接收方只是回显了发送方的时间戳，却没有考虑从回显到发送Ack的时间，导致RTT的误差，QUIC在计算RTT时考虑了延迟ACK，使得RTT更加准确
* 没有对头阻塞的多路复用：QUIC的多路复用与HTTP2类似，都是在一个连接上有多个请求，不同的是，QUIC各个stream互不影响，避免了对头阻塞的问题，同时UDP是基于面向报文的，所以QUIC的传输单元为报文，数据传输单元不会跨包，也避免了对头阻塞问题



[QUIC协议](https://mp.weixin.qq.com/s/vpz6bp3PT1IDzZervyOfqwhttps://mp.weixin.qq.com/s/vpz6bp3PT1IDzZervyOfqw)



#### UDP 伪首部

伪首部一共12个字节

* 源IP地址：4字节

* 目的IP地址：4字节

* 0字段：2字节，全零

* UDP协议字段：2字节，值为17

* UDP长度字段：2字节

  

伪首部仅参与计算校验和而不参与传输，发送方或者接收方根据IP报文获取12字节的伪首部并临时添加到首部前面来按16位一组来进行二进制反码求和再将求和结果的反码填入（检查）校验和字段。

udp中一个包大小究竟为多大合适

局域网环境下，建议将UDP数据控制在1472字节以下（以太网数据帧要在46字节-1500字节，IP数据包首部长度20字节，UDP首部长度8字节）

Internet编程时，建议将UDP数据控制在548字节以下（鉴于Internet上的标准MTU值为576字节， 576-20-8）





#### tcp 选项有什么 

* 时间戳选项和防回绕序列号：允许发送方针对每一个接收到的ACK估算TCP连接的往返时间，该选项由10个字节组成（4+4+2+2）发送方首先会将32位的数值填充到时间戳值字段作为时间戳字段的一部分，然后接收方将时间戳字段值复制到时间戳回显重试字段，其它的2字节用来指明选项的长度和数值，发送方接收到确认包后可以用来计算往返时间RTT，以便设置超时重传时间，第二点是为了处理TCP序号超过2^32的情况，这又被称为防回绕序列号，由于序列号最多为2 ^32 使用高速网络，序列号可能会被重复使用，因此可以将序列号看作拓展的序列号，避免相同序号的报文段产生二义性
* 最大报文段长度（MSS）选项：占4个字节，告知接收方能收到的最大报文段，最大段大小只记录TCP数据报的字节数，为什么需要这个字段？原因是，原因是如果MSS长度小，那么网络的利用率会下降，如果MSS长度较大，那么IP层传输就可能要分解成多个短报文，这样传输出错还要重传，开销增大，因此MSS应该尽可能大一些，只要在IP层传输不需要分片即可，不做设置一般默认为536字节（任何主机至少能够处理576字节的IPv4数据报，减去IPv4头部和TCP头部，则TCP发送的数据部分为576-20-20=536字节），最大段大小并不是通信双方协商的结果，只是一方表明不希望接收到比最大段还大的TCP报文段
* 窗口扩大选项：占3个字节，S为比例因子（0-14），新的窗口值等于16+S，因此窗口值最大可达2^30字节，该选项只能出现于SYN报文段，当连接建立后比例因子与方向绑定



#### 分片和分段区别 

MTU最大传输单元，数据链路层用MTC来限制所能传输的数据包的大小（46-1500字节），分片是在数据链路层对IP数据包进行分片

MSS最大分段大小，指TCP数据包每次能传输的最大数据分段，TCP分段是因为MSS



#### tcp 异常处理，什么时候有RST

1. 连接未断开提前关闭服务器
2. 请求超时
3. 服务器端口未打开



#### 什么时候有PSH URG

* PSH：有时在一端的应用程序在键入一个命令后希望能立即接收对方的响应，这种情况下TCP就可以使用推送操作，而不用等到整个缓存都填满了后在向上交付
* URG：表明该报文段中有紧急数据，应尽快传送，例如已经发送了很长的程序要在远地主机运行，但后来发现了一些问题，需要取消该程序的运行，因此用户从键盘发出中断命令命令，如果不使用紧急数据，那么这两者字符将存储在接收TCP的缓存末尾，只有当处理完所有数据这两个字符才能被交付接收方的应用进程，这样做就浪费了许多时间



#### tcp连接是什么？

所谓连接指的是逻辑上的连接，是双方通过维护一个状态，使得双方好像有一条线来关联双方，这个连接对于网络层是透明的，连接的建立伴随着资源的分配（分配端口号、传输控制块TCB），为了唯一标识这个连接，采用了四元组的方式（源IP，目的IP，源端口，目的端口）



#### tcp怎么计算时间，RTT和RTO ？

RTT：发送一个数据包收到相对应的ACK，所花费的时间

RTO：重传超时时间，发送数据包，启动重传计时器，重传计时器到期所花费的时间



#### TCP如何保证可靠传输

* 校验和：检测TCP的头部和数据是否存在比特差错，如果存在TCP直接将其丢弃
* 序列号：接收端根据接收的序列号判断是否见过该分组，存在则丢弃
* 确认号：接收端发送序列号+1作为确认号的分组给发送端，表示确认收到了该分组
* 超时重传：根据重传计时器的时间来判断分组是否丢失，丢失则重传
* 滑动窗口：记录已经收到的分组以及需要发送的分组，依据分组的状态来发送
* 流量控制：使得接收端能来得及接收发送端的数据
* 拥塞控制：保证在拥塞的网络能够较好的接收分组



#### 常见的拥塞控制算法

* Tahoe
* reno算法，即上述拥塞控制所使用的算法
* newReno

* BBR算法，由Google研发





#### BBR算法 

怎么快，怎么实现，和之前的有什么区别 

* BBR在有一定的丢包率的网络链路上充分利用了带宽，因为不容易区分拥塞控制丢包和错误丢包，BBR就干脆不考虑将丢包作为拥塞的信号
* BBR不使用“加性增，乘性减”来维护窗口大小，而是分别估计极大带宽和极小延迟把它们的乘积作为发送窗口的大小
* BBR是基于发送端的延迟和带宽评估的算法

[BBR算法](https://www.zhihu.com/question/53559433)





#### KeepAlive

https://niyanchun.com/tcp-keepalive-howto.html

一、KeepAlive的必要性：
1、许多防火墙等会自动关闭空闲的 socket 连接，TCP KeepAlive可以防止某些短时间的空闲 socket 不会被关
闭；
2、对于一些非正常断开的连接，如断电，服务器端并不能检测到，为了回收资源，必须提供一种检测机
制；
二、KeepAlive的两种方式
1、TCP 协议自带的 KeepAlive
2、应用层面的心跳包



TCP 中已有 SO_KEEPALIVE 选项，为什么还要在应用层加入心跳包机制？ 
主要是因为 TCP 协议中的 SO_KEEPALIVE 有几个致命的缺陷：

浪费系统资源、不及时、无法检测连接可用

1、keepalive 只能检测连接是否存活，不能检测连接是否可用。比如服务器因为负载过高导致无法
响应请求但是双方的连接仍然存在，此时 keepalive 无法判断该连接是否可用。
2、如果 TCP 连接中的另一方因为停电突然断网等非正常断开的现象，由于服务器端（被动连接/断
开的一方）并不知道客户端已断开连接，此时若服务器正在发送数据，那么会导致数据发送失败并进行
数据重传，由于重传包的优先级要高于 keepalive 的数据包，因此 keepalive 的数据包无法及时发送出
去。
3、当重传超过一定次数，TCP 协议会发送 keepalive 探测包到客户端，一旦探测包没有返回，服务
器端会以 keepaliveinterval 的频率继续发送探测包，经过若干次重试，若服务器一直没有收到应答就
会认为该 TCP 连接已经断开（默认时长是 2 小时），而 2 小时以内这个连接一直不会断开，浪费系统资
源。





#### TIME_WAIT详解

Linux中如何查看TIME_WAIT状态，time_wait状态什么场景下过多， 会造成什么问题？如何解决TIME_WAIT过多

netstat -anp

场景：高并发短连接的服务器

问题：该连接的端口在2MSL时间内会被占用，无法被来自新的连接所使用



[解决TIME_WAIT过多](https://blog.csdn.net/zhangjunli/article/details/89321202)

#### COLSE_WAIT详解

出现大量CLOSE_WAIT状态的原因及解决方法

一般发生于服务端，服务端与客户端通信时，因服务器未关闭socket，而导致COLSE_WAIT过多





#### SYN 超时了怎么处理？

发送方发送syn包，得不到syn+ack包的回复就会一直重试，在Linux中默认5次，重传的时间采用的是二进制退避算法，即一开始为1s，每次重传时间加倍，发送五次得不到结果就会断开连接





#### TCP 粘包、拆包？解决办法

* 要发送的数据大于发送缓冲区剩余空间大小，将会发生拆包
* 要发送的数据大于MSS，TCP传输前会进行拆包

* 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区数据一次发送出去，会发生粘包
* 接收数据端的应用层没有及时读取接收缓冲区的数据，将发生粘包

TCP是面向字节流的，无法理解上层的业务数据，所以底层无法保证数据包不被拆分和重组，这个问题只能由上层应用协议解决

关键在于如何区分数据包的边界。常用的方法有

1. 消息定长：发送端将每个数据包封装为固定长度
2. 设置消息边界：服务端从网络流中按消息边界分离出消息内容，在包尾增加回车换行进行分割
3. 将消息分为消息头和消息体：设置在消息前加入一个固定的结构体成为消息头，消息头中包含消息长度字段



#### TCP 封包和拆包 

封包就是给一段数据加上包头，这样一来数据包就分为包头和包体两部分内容了。包头其实上是个大
小固定的结构体，其中有个结构体成员变量表示包体的长度，这是个很重要的变量，其他的结构体成员可
根据需要自己定义。根据包头长度固定以及包头中含有包体长度的变量就能正确的拆分出一个完整的数据
包。
拆包就是根据包头以及包头中表示包长的结构体的变量，去掉包头的过程。

大概过程描述如下:
A,为每一个连接动态分配一个缓冲区,同时把此缓冲区和 SOCKET 关联,常用的是通过结构体关联.
B,当接收到数据时首先把此段数据存放在缓冲区中.
C,判断缓存区中的数据长度是否够一个包头的长度,如不够,则不进行拆包操作.
D,根据包头数据解析出里面代表包体长度的变量.
E,判断缓存区中除包头外的数据长度是否够一个包体的长度,如不够,则不进行拆包操作.
F,取出整个数据包.这里的"取"的意思是不光从缓冲区中拷贝出数据包,而且要把此数据包从缓存区
中删除掉.删除的办法就是把此包后面的数据移动到缓冲区的起始地址.





#### 半打开和半关闭

**半打开**

TCP连接后，如果未告知另一端情况下通信的一端关闭或者终止（比如切断电源），这样另一端仍然会认为这条链接是有效的

* 异常关闭的一端再次收到另一端的数据时，对此连接并不知情，因此会向另一端发送重置报文段进行响应，两端的连接也因此会被关闭
* 使用KeepAlive机制也能保证该连接正常关闭

[网线断开后又连接](https://blog.csdn.net/whlloveblog/article/details/44707131)





**半关闭**

TCP连接为全双工，客户端到服务端和服务端到客户端是两条传输方向，半关闭应用于这样一个场景，A向B方向的数据传输完毕，但是A仍希望接收B方的数据，因此可以采用半关闭的方式



#### 对头阻塞

tcp http的角度



[TCP大礼包](https://www.nowcoder.com/discuss/530380?type=all&order=time&pos=&page=2&channel=-1&source_id=search_all_nctrack)





## 应用层

为每一类问题规定一种协议，许多协议都是基于BS方式



### DNS

解析：用于将主机IP转化为域名的分布式服务器

为什么机器在处理IP数据报要使用IP地址而不是域名：IP地址长度固定为32位而域名长度并不是固定的，机器处理起来会比较困难

为什么整个互联网不只使用一个域名服务器：会因为负荷而无法正常工作。域名解析系统被设计成为一个联机分布式的数据库系统，并且采用BS方式，DNS使大量名字都在本地解析，仅少量解析需要在互联网上通信。因此DNS的效率高。由于DNS使分布式系统，即使单个计算机出现故障，也不会妨碍整个DNS系统正常运行，而且分布式就近查询也解决了远距离的延迟问题

#### 域名服务器

根：根域名服务器是最高层次的域名服务器。

顶级域名：即TLD服务器，负责管理在该顶级域名服务器注册的所有二级域名。

权限域名：负责一个区的域名服务器

本地域名：当一台主机发出DNS查询请求，这个请求报文就会发送给本地域名服务器

#### 域名解析过程

为了提高域名的查找速度，设置了DNS多级缓存，距离由近到远有浏览器缓存、本地缓存、路由器缓存、IPS服务器缓存、DNS服务器缓存

1. 输入域名，主机先检查浏览器是否有该网站的映射关系，如果有则直接调用，否则执行2
2. 先检查本地hosts文件是否有该网站的映射关系，如果有则直接调用，否则执行3
3. 查找本地DNS解析器缓存，如果有则调用，否则执行3
4. TCP/IP参数设置的DNS服务器，也叫做本地DNS服务器，服务器收到查询时，如果查询的域名包含在本地配置的区域资源中，则将解析结果返回给客户，完成域名解析，此解析具有权威性，如果没有结果则执行4
5. 本地服务器向根服务器进行查询（例如www.baidu.com，本地服务器回向根服务器查询，根服务器收到.com域名会判断是谁来授权管理，并将结果返回给本地服务器，然后查找.com域名管理器的下一级DNS服务器baidu.com，当本地服务器收到这个地址后，就会查找baidu.com的域服务器，重复上述查找，知道找到www.baidu.com的主机），缓存结果，最后将结果告知浏览器





#### DNS欺骗

定义： DNS欺骗就是攻击者冒充域名服务器的一种欺骗行为。 

原理：如果可以冒充域名服务器，然后把查询的IP地址设为攻击者的IP地址，这样的话，用户上网就只能看到攻击者的主页，而不是用户想要取得的网站的主页了，这就是DNS欺骗的基本原理。DNS欺骗其实并不是真的“黑掉”了对方的网站，而是冒名顶替、招摇撞骗罢了。

方法：通过hosts文件修改、DNS劫持

### HTTP1.x



#### URI和URL

![](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic2.zhimg.com%2Fv2-274d4451e88937419e5abeb7acdb8425_b.png&refer=http%3A%2F%2Fpic2.zhimg.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1613550757&t=25f4d4b5ddbc1b2aca1907009a457d45)

URI：统一资源标识符

URL：统一资源定位符，格式（<协议>://<主机>:<端口>/<路径>）

URN：统一资源名称



#### 报文格式

请求报文

![](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E7%BD%91%E7%BB%9C/pic/http请求.png)

* 请求行：请求方法 + URL + HTTP版本
* 请求头：由多个键值对组成，如User-Agent：产生请求的浏览器类型
* 请求体：使用POST请求数据在请求体上



响应报文

![](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E7%BD%91%E7%BB%9C/pic/http响应.png)

* 状态行：HTTP版本 + 状态码 + 解释状态码的短语
* 响应头：用于描述服务器的基本信息，以及数据描述，用于通知客户端如何处理等一下回送的数据
* 响应体：响应消息体，若响应文本类型的是HTML，则返回数据为HTML代码



#### HTTP方法

* GET：最常见的请求方式，使用GET方法时，将请求参数和对应的值放在URL后面，用？来代表URL的结尾和请求参数的开始
* POST：POST方法允许客户端给服务器提供较多的信息，POST请求参数将会封装在请求体上
* HEAD：HEAD就像GET方法，只不过服务端接收到HEAD请求后只返回响应头，而不返回响应内容。当我们查看某个页面状态时，HEAD非常高效
* PUT：上传文件，存在安全性问题
* DELETE：与PUT相反
* OPTIONS：查询指定URL支持的方法
* CONNECT：要求在与代理服务器通信时建立隧道





#### HTTP首部

有4种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段



**通用首部字段**

| 首部字段名        | 说明                       |
| ----------------- | -------------------------- |
| Date              | 创建报文的日期时间         |
| Transfer-Encoding | 指定报文主体的传输编码方式 |
| Warning           | 错误通知                   |
| Cache-Control     | 控制缓存的行为             |
| Connection        | 逐跳首部、连接的管理       |



**请求首部字段**

| 首部字段名      | 说明                       |
| --------------- | -------------------------- |
| User-Agent      | 产生请求的浏览器类型       |
| Accept          | 客户端可识别的内容类型列表 |
| Accept-Charset  | 优先的字符集               |
| Accept-Encoding | 优先的内容编码             |
| Accept-Language | 优先的语言（自然语言）     |
| Host            | 请求资源所在服务器         |
| Range           | 字节范围内请求             |



**响应首部字段**

| 首部字段名称       | 说明                         |
| ------------------ | ---------------------------- |
| Location           | 令客户端重定向至指定 URI     |
| Accept-Ranges      | 是否接受字节范围请求         |
| Proxy-Authenticate | 代理服务器对客户端的认证信息 |



**实体首部字段**

| 首部字段名称     | 说明               |
| ---------------- | ------------------ |
| Content-Length   | 实体主体的大小     |
| Content-Type     | 实体主体的媒体类型 |
| Content-Language | 实体主体的自然语言 |



#### HTPP状态码

| 状态码 | 类别             | 含义                       |
| ------ | ---------------- | -------------------------- |
| 1xx    | 信息性状态码     | 接受的请求正在处理         |
| 2xx    | 成功状态码       | 请求正确处理完毕           |
| 3xx    | 重定向状态码     | 需要进行附加操作来完成请求 |
| 4xx    | 客户端错误状态码 | 服务器无法处理请求         |
| 5xx    | 服务器错误状态码 | 服务器处理请求错误         |

**1xx 信息**

* 100 Continue：服务器收到部分请求，等待客户端继续发送

**2xx 成功**

* 200 OK：客户端请求成功
* 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。
* 206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。

**3xx 重定向**

* 301Moved Permanently 永久重定向
* 302 Temporarily Moved 临时重定向
* 304 Not Modified请求报文包含一些条件，如If-Match，If-None-Match，If-Range，如果不满足条件则返回304

**4xx 客户端错误**

* 400 Bad Request ：请求报文中存在语法错误
* 401 Unauthorized ：该状态码表示用户未经授权
* 403 Forbidden ：请求被拒绝
* 404 Not Found：请求资源不存在

**5xx 服务端错误**

* 500 Internal Server Error ：服务器正在执行请求时发生错误
* 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。



**http1.0和http1.1区别**

1. 缓存处理：HTTP1.1引入了更多的缓存控制策略，新增了缓存处理指令max-age
2. 带宽优化与网络连接的使用：HTTP1.0中存在一些浪费带宽的现象，比如客户端只需要对象的一部分，而服务端却将整个对象传输过来，HTTP1.1，在请求头引入range，它允许只请求资源的某个部分，即返回码为206，这样方便开发者能更好地利用带宽
3. Host头处理：在请求头和请求体增加了Host头域，支持虚拟主机连接
4. 长连接：HTTP1.1支持长连接（设置Connection：keep-alive）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTPP请求和响应，减少了建立和关闭的消耗和延迟

[HTTP](https://blog.nowcoder.net/n/51b5ec0df6934e24af490234b7724ef4#-----)

**连接管理**

HTTP1.1中指定**Connection: keep-alive**，即可HTTP1.1默认长连接，长连接让传输效率大大提升，但是如果要在连接上发多个HTTP报文，多个报文会累积到队列里依次处理，只要队头的请求被阻塞了，后续的HTTP发送就会收到影响，这就是队头阻塞

队头阻塞很大的原因是因为TCP是面向流传输的，HTTP无法确定消息边界，因此也就无法区分每一个请求。接收方通过Content-Length来判断报文是否接收完毕，若接收完毕则可以直接请求解析，这样就解决了队头阻塞问题





### HTTP2协议

HTTP1.X缺陷

* 需要多个连接才能实现并发和缩短延迟
* 不会压缩请求和响应头部，从而导致不必要的网络流量
* 不支持有效的资源优先级，导致TCP连接利用率低下

HTTP2与HTTP1.1区别

![](https://pic2.zhimg.com/80/906e22193e61cd561325d93aae0f1e07_720w.jpg?source=1940ef5c)

区别一：多路复用

HTTP2协议通过单一的TCP连接实现了同时发起多重请求响应消息。HTTP2协议在传输层与应用层之间加了一层：二进制分帧层。这是HTTP2中最大的改变。HTTP2之所以性能比HTTP1.X有那么大的提升，很大程度正是由于这一层的引入。在二进制分帧层，HTTP2协议将所有传输的数据分割成更小的消息和帧，并对它们采用二进制格式编码，其中首部信息会被封装在HEADER帧而相应的Request Body则封装到DATA帧，采用了单连接多资源的方式，减少了服务端的压力，也使得连接的吞吐量增大

![](https://pic4.zhimg.com/80/v2-49eb023bd93fe6343f0c896b3de038cf_720w.jpg?source=1940ef5c)

区别二：首部压缩

HTTP的响应和请求都是由状态行、请求\响应头部，消息主体三部分组成，但是随着请求次数增大，而User-Agent这类基本不变的头部信息，每次要传输这种信息是一种浪费。为了压缩首部，需要在浏览器与服务端之间维护一份相同的静态字典包含了头部名称，以及常见的头部名称与值的组合，以及动态字典来动态添加内容，采用Haffman编码对首部字段进行压缩并添加到字典中，然后双方用字符来代替键值对，从而大大减小传输的数据量

![](https://pic1.zhimg.com/80/v2-9f97f2c92ddc3d56564642d6447d23d1_720w.jpg?source=1940ef5c)

区别三：HTTP2服务器支持推送

页面加载时伴随着许多附加资源的载入，HTTP2采用了服务器推送机制，允许在浏览器和服务器连接后，服务器主动将一些资源推送给浏览器并缓存起来，若浏览器想要访问已缓存的资源，那么浏览器就可以直接读取缓存，充分利用了空闲的网络，改善页面加载时间。



### HTTP3协议

HTTP2缺陷

* HTTP2一个TCP连接上有多条HTTP请求，只要第一个HTTP请求在缓冲区遭遇拥塞，那么剩下的HTTP请求就无法发出，这就造成了队头阻塞

特点一：将传输层的TCP协议替换成可靠的UDP协议（QUIC协议）

* 与TCP相比有更少的延迟
* 没有队头阻塞问题



### HTTPS协议

HTTP有以下安全问题

* 使用明文进行通信，内容可能会被窃听
* 不验证通信方的身份，通信方的身份有可能是伪造
* 无法证明报文的完整性，报文有可能遭篡改



与HTTP的区别

* 端口：HTTPS为443，HTTP为80
* HTTP是超文本传输协议，信息是明文传输，HTTPS是具有安全性的传输协议
* HTTPS运行在SSL/TLS之上
* 费用：HTTP免费，HTTPS的CA证书需要一定费用



**密码学基础**
在正式讲解HTTPS协议之前，我们首先要知道一些密码学的知识。

明文： 明文指的是未被加密过的原始数据。

密文：明文被某种加密算法加密之后，会变成密文，从而确保原始数据的安全。密文也可以被解密，得到原始的明文。

密钥：密钥是一种参数，它是在明文转换为密文或将密文转换为明文的算法中输入的参数。密钥分为对称密钥与非对称密钥，分别应用在对称加密和非对称加密上。

对称加密：对称加密又叫做私钥加密，即信息的发送方和接收方使用同一个密钥去加密和解密数据。对称加密的特点是算法公开、加密和解密速度快，适合于对大数据量进行加密，常见的对称加密算法有DES、3DES、TDEA、Blowfish、RC5和IDEA。
其加密过程如下：明文 + 加密算法 + 私钥 => 密文
解密过程如下：密文 + 解密算法 + 私钥 => 明文
对称加密中用到的密钥叫做私钥，私钥表示个人私有的密钥，即该密钥不能被泄露。
其加密过程中的私钥与解密过程中用到的私钥是同一个密钥，这也是称加密之所以称之为“对称”的原因。由于对称加密的算法是公开的，所以一旦私钥被泄露，那么密文就很容易被破解，所以**对称加密的缺点是密钥安全管理困难**。

非对称加密：非对称加密也叫做公钥加密。非对称加密与对称加密相比，其安全性更好。对称加密的通信双方使用相同的密钥，如果一方的密钥遭泄露，那么整个通信就会被破解。而非对称加密使用一对密钥，即公钥和私钥，且二者成对出现。私钥被自己保存，不能对外泄露。公钥指的是公共的密钥，任何人都可以获得该密钥。用公钥或私钥中的任何一个进行加密，用另一个进行解密。
被公钥加密过的密文只能被私钥解密，过程如下：
明文 + 加密算法 + 公钥 => 密文， 密文 + 解密算法 + 私钥 => 明文
被私钥加密过的密文只能被公钥解密，过程如下：
明文 + 加密算法 + 私钥 => 密文， 密文 + 解密算法 + 公钥 => 明文
由于加密和解密使用了两个不同的密钥，这就是非对称加密“非对称”的原因。
**非对称加密的缺点是加密和解密花费时间长、速度慢**，只适合对少量数据进行加密。
在非对称加密中使用的主要算法有：RSA、Elgamal、Rabin、D-H、ECC（椭圆曲线加密算法）等。



**HTTPS过程**



HTTPS为了兼顾安全与效率，同时使用了对称加密和非对称加密。数据是被对称加密传输的，对称加密过程需要客户端的一个密钥，为了确保能把该密钥安全传输到服务器端，采用非对称加密对该密钥进行加密传输，总的来说，**对数据进行对称加密，对称加密所要使用的密钥通过非对称加密传输。**

HTTPS在传输的过程中会涉及到三个密钥：
服务器端的公钥和私钥，用来进行非对称加密
客户端生成的随机密钥，用来进行对称加密
一个HTTPS请求实际上包含了两次HTTP传输，可以细分为8步。

1. 客户端向服务器发起HTTPS请求，连接到服务器的443端口
2. 服务器有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器保存则私钥，不将其泄露，公钥可以发给任何人
3. 服务器将公钥发给客户端
4. 客户端收到服务端的公钥后，会对其合法性检查，如果发现公钥有问题，HTTPS传输就无法继续。如果公钥合格，客户端就会生成随机值，这个随机值就是用来对称加密的密钥，即客户端密钥。然后客户端用服务器的公钥和自己生成的密钥进行非对称加密，客户端密钥就变成了密文，至此HTTPS的第一次请求接收
5. 客户端发起HTTPS中的第二个HTTP请求，将加密之后的客户端密钥发给服务器
6. 服务器收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥堆数据进行对称加密，这样数据就变成了密文
7. 服务器将加密的数据发给客户端
8. 客户端收到服务器发来的密文，用自己的密钥对其进行对称加密，得到服务器的数据，这样就完成了HTTPS的响应



**CA证书**

![](C:\Users\Steven\Desktop\CS-Note\网络\pic\数字证书.png)

数字证书就是由客户端和服务端双方都信任的数字证书认证机构颁发的，服务端的人员通过向机构提出证书申请，批准后会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，服务端会自己保留一份私钥，客户端向服务端请求时，服务端会将生成数字证书，这个证书内容分明文部分和密文部分，明文包含了公钥内容，签发者信息，有效期等，密文内容是对明文内容使用了hash加密算法，hash加密是单向的，也就是只能从明文转为密文而不能从密文转为明文，将该证书发送给客户端，客户端收到后，会对明文内容进行hash加密，然后与密文内容进行比较，不一致说明明文内容可能被篡改或者证书不是由CA签发，一致那么就签名合法，就获得了服务端的公钥







### DHCP协议

介绍：DHCP协议提供了即插即用连网机制，这种机制允许一台计算机加入新的网络和获取IP地址时不用手工。参与需要IP地址的主机在启动时就向DHCP服务器广播发送发现报文，这时该主机就成为DHCP客户。DHCP服务器收到该报文后，会从IP地址池中取一个地址分配给该计算机，DHCP服务器的回答报文叫做提供报文



### FTP协议

特点：FTP服务器进程分为两大部分

* 主进程：负责接收新的请求
* 从属进程：负责处理单个请求







**常用端口**

| 应用               | 应用协议 | 端口号 | 传输层协议 | 备注                       |
| ------------------ | -------- | ------ | ---------- | -------------------------- |
| 域名解析           | DNS      | 53     | UDP/TCP    | 长度超过512字节使用TCP协议 |
| 动态主机配置协议   | DHCP     | 67/68  | UDP        |                            |
| 文件传输协议       | FTP      | 20/21  | TCP        | 控制连接21，数据连接20     |
| 超文本传输协议     | HTTP     | 80     | TCP        |                            |
| 超文本传输加密协议 | HTTPS    | 443    | TCP        |                            |



### 相关问题



Http1.1 特点，缺点

* 默认支持长连接，支持流水线机制
* 增加了缓存控制
* 支持虚拟主机HTTP访问
* 允许字节范围内请求，返回码为206

http2.0 特点，缺点

* 多路复用，使用了二进制分帧层
* 头部压缩
* 支持服务器推送



http3.0 特点，缺点

http 和 https



可以伪造证书吗？中间人攻击能预防吗？



对称加密和非对称加密，RSA 具体说说



DES 和 AES 区别



HTTPS 证书是啥？加密内容？



HTTPS与HTTP的区别，HTTPS密钥交换过程，CA信任链



CA证书的验证过程



[https原理](https://www.javadoop.com/post/https)





http的请求过程，https的加密过程



https的连接过程



HTTP请求报文格式：首行、headers、空行、body

请求行、请求头、请求体、响应行、响应头、响应体都包括什么

HTTP状态码？304 Not Modifed/400系列讲一下



get和post的区别

含义：GET用于获取资源，POST用于传输实体主体

* 提交方式：GET提交，提交的数据会附在URL之后，以？分割URL和提交数据，多个参数则用&连接，如果是中文则直接把字符串用BASE64加密。POST提交把提交的数据放置在是HTTP请求体。

* GET提交的数据会在地址栏中显示出来，而POST提交，地址栏不会改变。

* 传输数据的大小：虽然HTTP协议没有对传输的数据大小进行限制。但是GET请求的长度受限于浏览器对URL长度的限制。因此对于GET提交时，传输数据就会受到URL长度的限制。POST由于不是通过URL传值，理论上数据不受限。

* 幂等性：所谓幂等性是指HTTP请求执行一次和执行多次的效果是一样的。GET方法是幂等的，POST方法不是幂等的。



HTTP如何实现缓存，怎样告诉浏览器这个可以被缓存以及缓存时间

* 缓存的目的，首先是为了减少服务端的压力，其次降低了用户请求资源的延迟

* HTTP使用Cache-Controll来控制缓存策略
* Cache-Controll有如下参数
  * no-store：表示禁止缓存
  * no-cache：缓存服务器必须向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端请求进行响应
  * private：规定将资源作为私有资源，只能被用户单独使用
  * public：规定将资源作为公有资源，可以被多个用户共享使用
* 缓存过期机制
  * max-age：出现在请求报文并且缓存资源的缓存时间小于该指令的指定时间，那么就接受该缓存，出现在响应报文，则表示缓存资源在缓存服务器保存的时间
  * Expires：告知缓存服务器该缓存什么时候过期
* 缓存验证ETag



输入一个url发生了什么

1. DNS解析
2. TCP三次握手
3. 若为https则需要进行验证，否则为普通的http连接
4. 浏览器发送请求报文
5. 请求报文内容
6. 服务端发送响应报文
7. 响应报文内容
8. 浏览器收到数据渲染页面。若为短连接则关闭TCP连接即四次握手





HTTP的长连接和实现原理

长连接是干啥用的？举个场景说

长连接的连接数有限制吗？

* Connection：keepAlive用来告诉对方请求响应完后不要断开连接

keep_alive参数

* timeout：过期时间，如果过期时间间隔内没有请求则断开连接
* max：最大请求次数，如果为0则强制断开





为什么使用Session和Cookie

HTTP的请求响应是无状态的，也就是说服务器并不区分客户是谁，但是有时候是需要保存客户端的一些信息的，需要去记录客户端的连接状态、识别请求状态。为了解决这一类问题，就需要使用到Cookie和Session

Session和Cookie的区别以及如何解决分布式session问题

* Cookie：客户端访问某个地址，会将请求交给服务器进行处理，浏览器会将请求内容一并交给服务端处理。在处理的过程中，Cookie在服务端保存，生成Cookie对象时，需要确定具体的名称和到期时间，服务端再将Cookie发送给浏览器，浏览器接收到后，会将Cookie信息保存在本地，下次访问该网页进行请求时，会附带Cookie信息一并发送给服务端
* Session：Session在服务端生成，存储在服务器端，即存在内存中。一般来说一个SessionID就对应了一个用户



总结

1. Cookie存在客户端、Session存在服务端
2. 安全性要求较高使用Session，要求低使用Cookie
3. Cookie只能存储字符串，Session可以存储任何信息
4. 在存储相对持久的信息，应当考虑使用Cookie。在进行登录的验证或者信息的拦截，可以使用Session
5. Session由于存储在服务端，如果大量用户信息都用Session存储会让服务器压力增大，因此不宜将所有用户信息都用Session存储



SSL握手和工作流程，SSH/SSL的区别，详细说明

对称加密和非对称加密

DNS查询过程，递归查询和迭代查询的区别





跨域了解吗？

cookie支持跨域吗？

cookie可以包括哪些类型的数据？

csrf 预防，http/dns 劫持

dns欺骗怎么办？ arp欺骗？CSRF攻击？xss攻击？syn flood攻击？应对方法





## 网络安全

### IP欺骗

通过IP地址伪装成某台主机，使得这台主机被另外的主机所信任





### SYN泛洪攻击

#### 原理

一个或多个恶意客户端伪造源IP地址，向服务器发送一系列SYN报文段，服务器收到SYN报文段，会给每一个连接创建分配一定数量的连接资源。由于连接尚未建立，服务器会因为维护大量的半打开连接耗尽自己的内存后，从而拒绝为后面的合法连接服务



#### 防范

基本思想就是当SYN报文到达后，为这条连接存储的大部分信息进行编码并保存在SYN+ACK字段中，只有当SYN+ACK报文段被确认后，且服务器收到了响应后，才会真正为这条连接分配内存









### TCP重置攻击

TCP重置攻击中，攻击者通过向通信双方中的一方或者双方发送伪造的数据，告诉他们立刻断开连接，从而使通信双方连接中断，它利用了TCP重置机制，当接收的报文段对于相关连接不正确，那么TCP会发送一个重置报文，从而导致TCP连接重建，攻击者通过伪造重置报文，防止连接被用来进一步交换信息，这种攻击只对于长连接有杀伤力，因为短连接，在完成信息交换就已经断开连接了



伪造报文的步骤

* 嗅探通信双方交换信息
* 截获一个ACK报文段，并读取其ack号
* 伪造一个TCP重置报文段（RST=1）将序列号置为ack号





### 中间人攻击

#### 原理

中间人攻击指的是攻击者与通信双方建立连接，使得通信双方都认为自己通过一个私密连接与对方直接对话，实际上整个对话都被攻击者完全控制



