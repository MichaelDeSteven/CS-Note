# 计算机系统概述

## 硬件

### 冯诺依曼结构

冯诺依曼结构计算机的基本思想主要包括以下几个方面

1. 采用“存储程序”工作方式
2. 计算机由运算器、控制器、存储器、输入设备、输出设备五大基本部件组成
3. 存储器能存储指令和数据，形式上数据和指令没有区别，但是计算机能够区分它们。控制器能够自动执行指令，运算器能够进行加减乘除4种基本运算，并且能够进行逻辑运算。操作人员可以通过输入输出设备来使用计算机。
4. 计算机内部用二进制形式表示指令和数据

**总结**

运算器、控制器：通常集成在CPU上，CPU是执行程序时进行运算和控制的设备，它直接控制着计算机各个部件工作，是硬件的核心

存储器：用来存放指令和数据的部件

硬件是操作系统存在的物质基础。硬件层提供给操作系统的接口是机器的指令系统。操作系统的程序使用指令系统提供的机器指令所具有的功能，实现对硬件的直接管理和控制。





![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\经典计算机系统组成硬件.png)



### CPU

作用：基本职责是用来执行指令

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\CPU基本组成原理图.png)

程序计数器PC：存放下一条指令的地址

指令寄存器IR：存放当前指令的地址

指令译码器ID：对IR中的操作码部分进行分析解释，产生相应的译码信号提供给”操作控制信号形成部件“，以产生控制信号

时序信号产生部件：以时钟脉冲为基础，产生不同指令对应的周期、节拍、工作脉冲等时序信号，实现机器指令执行过程的时序控制

操作控制信号形成部件：该部件综合了时序信号、指令译码信号和执行部件反馈的条件标志等。形成不同指令的操作所需要的控制信号。

算术逻辑单元ALU：最基本的部件是加法器，通过加法运算和逻辑运算来完成基本的算术运算

总线控制逻辑：实现对总线（地址线、数据线、控制线）传输的控制，包括对数据和地址信息的缓冲与控制。

中断机构：实现对异常情况和外部中断请求的处理







### 存储器

根据存储器的特点和使用方法的不同，可以有以下几种分类方法

1. 按存储元件分类

* 半导体存储器
* 磁表面存储器
* 光盘存储器

2. 按存取方法分类

* 随机存取存储器：按地址访问存储单元
* 顺序存取存储器：信息按顺序存放和读取
* 直接存取存储器：兼有随机访问和顺序访问的特点

3. 按功能分类

* 高速缓冲存储器：位于CPU和主存之间，存取速度接近CPU的工作速度，用来存放当前CPU经常使用的指令和数据
* 主存储器：用来存放系统中运行和程序和数据
* 辅助存储器：系统运行时直接和主存交换信息的存储器





寄存器

寄存器位于CPU内部，是CPU的组成部分。它是计算机系统内CPU访问速度最快的存储部件，完全能与CPU协调工作，不过由于价格太贵，只能做得很小。寄存器用来存放系统最常访问的数据，为了解决CPU访问贮存速度过慢的问题。



内存

CPU可以通过指令直接存取主存中的数据，但是这个速度远低于CPU的执行速度，为了解决这个问题，引入了寄存器和高速缓存，高速缓存也属于内存的一部分都是它与一般的主存实现方式不同，它是由SRAM组成，访问速度比DRAM快。高速缓存的作用就是用来存放主存中一些经常被访问的信息。磁盘缓存本质就是主存划分的一个小区域，他是为了减少CPU通过IO操作次数，用来存储存储较为频繁的磁盘内容





## 软件

### 系统软件

**操作系统**



**命令解释器shell**





### 应用软件

如终端程序tty，用来获取用户键盘输入，然后将输入发送给shell，拿到命令行程序的输出结果并将输出结果通过图形界面显示在显示屏上。







# 操作系统概述

## **定义**

操作系统是系统软件，用于控制和管理计算机内部的各种资源（处理器、存储器、IO设备、文件），有效地组织多道程序运行，为用户提供接口，方便用户使用计算机。



为什么要使用操作系统？如果没有操作系统？



##  分类

单道批处理系统

内存只有一道用户作业

缺点

* 由于内存仅有一道程序，每次IO请求后，CPU处于等待状态利用率低



多道批处理系统

用户将作业提交放在外存中，并排成一个队列称为”后被队列“，如何由作业调度系统按一定的算法，从后备队列选择若干个作业调入内存中，使它们共享CPU和系统中的各种资源。

优点

* 资源利用率高：多道程序交替运行，使CPU处于忙碌状态。内存装入多道程序提高了内存的利用率，此外还提高了IO设备的利用率
* 系统吞吐量大：CPU和其他资源保持”忙碌状态“

缺点

* 平均周转时间长：由于作业要排队依次处理，因而作业的周转时间较长
* 无交互能力：用户一旦把作业交给系统后，直到作业完成，用户都不能与自己的作业进行交互，不方便修改和调试



分时操作系统

所谓分时就是将处理器的时间分成若干个小的时间片，把每个时间片轮流分给各个程序。分时操作系统的出现解决了人机交互问题和共享主机问题。

特征

* 多路性：允许多个终端同时连接一台主机上，按分时原则为每个用户服务
* 独立性：每个用户在各自的终端上进行操作，互不干扰
* 及时性：用户的请求能在很短的时间内获得响应
* 交互性：用户可以通过终端与系统进行人机交互



实时操作系统

主要设计目的：实时响应及处理能力高，高可靠性，安全性

与分时操作系统差异

* 交互性：分时操作系统可以运行任何用户程序，对用户的不同请求予以响应，而实时操作系统中的应用程序是预先设计好的，只能响应预先约定好的用户请求
* 实时性：分时操作系统是以人能接受的程度来确定响应时间的通常为秒级别，而实时操作系统是以控制过程或处理信息过程所能容忍延迟来确定，通常为毫秒或者微秒级别
* 可靠性：实时操作系统要求高度可靠



## 基本特征

**并发**

并发：多个进程在同一时间间隔轮流执行

并行：多个进程在同一时刻轮流执行



**共享**

多个进程可以共享一块资源

分类

* 互斥共享方式：如打印机、磁盘带这些临界资源同一时间内只允许一个进程访问该资源
* 同时访问方式：允许在一段时间内由多个进程宏观上同时对他们进行访问，如磁盘设备



**虚拟**

思想来源于通信技术领域的复用技术，将一个物理实体变成若干个逻辑上的对应物

操作系统采用是时分复用和空分复用技术来实现虚拟的

* 时分复用：为每一道程序至少建立一个进程，即使系统只有一台处理器，在用户的视图中，会认为有一台专门为他服务的处理器，提高了处理器的利用率

* 空分复用：通过空分复用技术提高了内存的利用率



**异步**

进程不可预知的速度向前推进



## 主要功能

* 处理机管理
  * 进程控制：为使多道程序并发执行，系统要为这些程序设置进程和分配必要的资源，同时还需要对这些进程的状态进行维护，当进程结束后，还应该需要回收该进程的资源
  * 进程同步：多个进程并发执行时，需要对进程进行协调，协调的方式主要有同步和互斥
  * 进程通信：当一组进程需要合作去完成某项任务时，需要进程之间的通信
  * 调度：通过某种调度算法，来为进程合理的分配资源，从而提高资源利用率
* 内存管理
  * 内存分配：为每个进程提供合适的内存空间，提高存储器的资源利用率
  * 内存保护：为保证用户程序地址空间的独立性，每个地址空间互不干扰
  * 地址映射：系统内存空间存在物理地址与逻辑地址，需要通过硬件的支持下进行地址的映射
  * 内存扩充：从逻辑上扩充内存容量，使用户感觉自己使用的内存容量比实际内存大得多，以便能运行更多的程序
* 文件管理
  * 文件存储空间管理：为每个文件分配必要的外存空间，提高外存资源的利用率，同时还要记录存储空间的消息，以便分配空间。
  * 目录管理：实现方便的按名字存取文件
  * 文件读写管理和保护：根据用户的请求对文件进行读取，同时为了防止文件被非法窃取和破坏，还要提供对文件的保护
* 设备管理
  * 缓冲管理：为了有效缓解不同设备之间速度不匹配的矛盾，提高资源的利用率，通过设置缓冲区的方法，来提高系统的性能
  * 设备分配：根据用户I/O请求和当前资源的情况，对设备进行分配
  * 设备处理：实现CPU与设备控制器之间的通信



# 进程管理

## 进程

### 概念

为了能使程序并发执行，可以对并发执行的程序加以描述和控制，人们引入了进程的概念，进程就是进程实体（包括了程序段，相关数据段，进程控制块PCB）的运行过程，是系统进行资源分配（独立的地址空间、存放全局变量的数据段，处理器的状态）和调度的一个独立单位



### 特征

* 动态性：进程的实质是进程实体的执行过程，它由创建而产生，由调度而执行，由撤销而消亡，因此进程实体就有生命期，而程序只是一组有序指令的集合，其本身并不就有活动的含义，因而是静态的
* 并发性：多个进程实体同存与内存中，且能在一段时间内同时执行，而程序是不能参与并发执行的
* 独立性：独立性是指进程实体能独立运行，独立获得资源和独立接受调度，而未建立PCB的程序不能作为一个独立的单位参与运行
* 异步性：各个进程之间是按异步方式运行的，即按各自独立的，不可预知的方向推进，因此其产生结果具有不可再现性。但是通过配置相应的进程同步机制就能保证并发执行的结果是可再现的

### 内存结构

![image-20210210224117737](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/进程的地址空间.png)



* 内核空间区：位于最上面，包括了与进程相关的数据结构，task_struct、内核栈、mm结构，物理内存、内核代码和数据
* 载入的程序：包括代码、已初始化数据、未初始化数据，位于最下面
* 用户栈：位于内核空间区的下面，向下生长
* 运行时堆：位于程序区上面，向上生长
* 内存映射区域：包含了共享库和共享内存的物理地址



### PCB

* 定义：进程控制块PCB是系统为了描述和控制进程的运行而定义的数据结构，PCB中记录了操作系统所需全部关于进程的描述和控制信息，它是进程存在的唯一标识

**包含信息**

1. 进程标识信息
   * PID：进程的惟一标识号
   * PName：进程的名称
   * 用户和组标识：控制进程对系统的访问权限，实现资源的安全访问
   * 族亲信息：记录进程的父进程、兄弟进程以及子进程的信息

2. 处理器信息
   * 程序状态字：当前的状态信息，比如执行方式是用户态还是系统态
   * 指令计数器：指示要访问的下一条指令地址
   * 处理器中的主要寄存器
   * 用户栈指针：进程存放过程和系统调用参数及调用地址的一组系统栈

3. 进程控制信息
   * 进程的状态：指出当前进程的状态
   * 调度信息：调度的算法、优先级、剩余时间片
   * 计时信息：计时和定时器，给出程序占有和利用CPU情况，是调度、统计、分析的依据
   * 通信信息：与其他进程通信的信息

4. 进程资源信息
   * 进程打开的文件资源
   * 有关的存储器的地址和资源



**组织方式**

* 索引表结构：就绪索引表、阻塞索引表，将索引表的首地址记录在专门的单元记录中
* 链表结构：如就绪队列、阻塞队列



在linux中，PCB是一个名为tast_struct的结构体，称为任务结构体，它位于源代码的include/linux/sched.h

```c++
struct task_struct {
    pid_t pid; // 进程标识符
    uid_t uid,euid,suid,fsuid; // 用户标识符
    gid_t gid,egid,sgid,fsgid; // 用户组标识符
    struct task_struct *p_opptr, *p_pptr, *p_cptr, *p_ysptr, *p_osptr; // 祖先进程、父进程、子进程、弟进程、兄进程的指针
    struct task_struct *prev_task, *next_task; // 进程队列指针
    volatile long state; // 进程状态
    long counter; // 剩余时间片
    long priority; // 优先级
    unsigned long policy, rt_priority; // 调度策略、实时优先级
    struct mm_struct *mm; // 存储器资源
    struct fs_struct *fs; // 打开文件资源
}
```



**任务结构体的管理**

为了方便管理系统中的所有进程，系统在内核空间设置了一个指针数组task[]，该数组每一个元素指向一个任务结构体，所以task数组又称为task向量。

![image-20210129134529543](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/task数组.png)

```cpp
struct task_struct *task[NR_TASKS]={&init_task}
```

其中NR_TASKS决定了数组的大小，在/include/linux/task.h它的默认值被定义为512

task的第一个指针指向名为init_task的结构体，它是系统初始化进程init的任务结构体

为了记录实际存在的进程数，系统定义了一个全局变量nr_tasks，在kernel/fork.c它的定义以及初始化未

int nr_tasks = 1

Linux中把所有进程的任务结构体相互连成一个双向循环链表，其首结点就是init的任务结构体init_task

### 运行过程





### 状态转换

#### 进程控制

![](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/进程五种状态转换图.png)

* 概念：进程控制的任务就是通过控制进程的创建、终止使各个进程有条不紊的推进，从而实现对系统中全部进程的有效管理
* 原理：进程控制是由进程使用操作系统提供的一组系统调用来实现的，这些系统调用具有原语的性质，也成为进程控制原语

**创建原语**

作用：为被创建的进程建立一个PCB，并填入相应的初始化项

主要操作

* 先向系统申请一个空闲的PCB
* 根据父进程提供的参数将子进程的PCB初始化
* 将此PCB插入就绪队列
* 返回一个进程标识符

**撤销原语**

撤销原因：任务完成、发生错误、父进程被撤销

作用：收回被撤销的进程占用的所有资源，并撤销它的PCB

主要操作

* 从祖先进程找到要撤销的基础PCB，如果有子孙进程，需要遍历其进程树，找到所有子孙进程的PCB
* 释放它及其子孙进程所占用的全部资源
* 删除其子孙进程
* 把进程PCB从其所在的队列中删除，并回收PCB
* 如果撤销的是正在运行进程，则需要从就绪队列中选择一个进程投入运行



**阻塞原语**

挂起原因：资源匮乏、等待IO操作

作用：将进程从执行状态或其他状态转为阻塞状态

主要操作

* 如果进程正处于运行状态，中断处理器保存该进程的CPU现场
* 将该进程插入等待队列
* 从就绪队列中选择一个新的进程投入运行



**唤醒原语**

作用：由发现者进程将处于阻塞状态的进程由阻塞状态变为就绪状态

主要操作

* 将响应的阻塞队列查找等待时间的阻塞进程，将进程状态恢复成就绪态
* 把该进程从阻塞队列中撤出，并将该进程插入就绪队列

![](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/具有挂起的进程状态转换图.png)

**挂起原语**

引入原因

* 终端用户的需要。当终端用户发现自己的程序在运行期间发现可疑的问题，希望暂停程序，以便用户研究其执行情况或对程序进行修改。
* 父进程请求。有时父进程希望挂起自己的某个子进程，以便观察和修改子进程，协助各子进程的活动
* 负荷调节的需要。当实时系统的工作负荷较重，系统可以将一些不重要的进程挂起，以保证系统能正常运行

挂起和阻塞的区别

* 发生的时机不同：阻塞一般是进程在等待资源时发生的，而挂起是由于用户或系统的需要
* 恢复时机不同：阻塞如果获得了等待的资源后，才进入就绪状态，等待被调度执行，而挂起的进程有其挂起的对象在时机符合的时候将其挂起
* 对系统资源占用不同：阻塞状态的进程仍然在内存中，而挂起的进程通过”对换“技术被换出外存

主要操作

* 首先检查被挂起进程的状态并进行相应操作（执行态、活动就绪态—静止就绪态；活动阻塞态—静止阻塞态）
* 为便于用户或父进程考察该进程的运行情况，把该进程的PCB复制到某指定的内存区域
* 最后，若被挂起的进程正在运行，则转向调度程序重新调度



**激活原语**

当发生激活进程事件

* 将进程从外存调入内存
* 检查该进程的状态并进行相应操作（静止就绪态—活动就绪态；静止阻塞态—活动阻塞态）



#### Linux系统实现

![image-20210129171242858](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/linux进程状态转换.png)



**进程的创建**

进程通过fork函数系列（fork、vfork、clone）来创建进程，都是复制父进程来得到子进程

```cpp
#include <unistd.h>
pid_t fork(void);
// 父进程返回子进程PID
// 子进程返回0
// 读时共享、写时复制
```

**fork函数工作原理**

[thread_info](https://www.cnblogs.com/chenxinshuo/p/11968329.html)

```cpp
long _do_fork(unsigned long clone_flags,
	      unsigned long stack_start,
	      unsigned long stack_size,
	      int __user *parent_tidptr,
	      int __user *child_tidptr,
	      unsigned long tls)
{
	struct task_struct *p;
	int trace = 0;
	long nr;

	/*
	 * Determine whether and which event to report to ptracer.  When
	 * called from kernel_thread or CLONE_UNTRACED is explicitly
	 * requested, no event is reported; otherwise, report if the event
	 * for the type of forking is enabled.
	 */
	if (!(clone_flags & CLONE_UNTRACED)) {
		if (clone_flags & CLONE_VFORK)
			trace = PTRACE_EVENT_VFORK;
		else if ((clone_flags & CSIGNAL) != SIGCHLD)
			trace = PTRACE_EVENT_CLONE;
		else
			trace = PTRACE_EVENT_FORK;

		if (likely(!ptrace_event_enabled(current, trace)))
			trace = 0;
	}

	p = copy_process(clone_flags, stack_start, stack_size,
			 child_tidptr, NULL, trace, tls);
	/*
	 * Do this prior waking up the new thread - the thread pointer
	 * might get invalid after that point, if the thread exits quickly.
	 */
	if (!IS_ERR(p)) {
		struct completion vfork;
		struct pid *pid;

		trace_sched_process_fork(current, p);

		pid = get_task_pid(p, PIDTYPE_PID);
		nr = pid_vnr(pid);

		if (clone_flags & CLONE_PARENT_SETTID)
			put_user(nr, parent_tidptr);

		if (clone_flags & CLONE_VFORK) {
			p->vfork_done = &vfork;
			init_completion(&vfork);
			get_task_struct(p);
		}

		wake_up_new_task(p);

		/* forking complete and child started to run, tell ptracer */
		if (unlikely(trace))
			ptrace_event_pid(trace, pid);

		if (clone_flags & CLONE_VFORK) {
			if (!wait_for_vfork_done(p, &vfork))
				ptrace_event_pid(PTRACE_EVENT_VFORK_DONE, pid);
		}

		put_pid(pid);
	} else {
		nr = PTR_ERR(p);
	}
	return nr;
}

/*/*
 * This creates a new process as a copy of the old one,
 * but does not actually start it yet.
 * 根据clone_flags标志拷贝寄存器，以及其他进程环境
 * It copies the registers, and all the appropriate(适当)
 * parts of the process environment (as per the clone
 * flags). The actual kick-off is left to the caller. 
 * 搞好的这个新的进程的启动由调用者完成启动 
 */
task_struct *copy_process(unsigned long clone_flags,
                          unsigned long stack_start,
                          struct pt_regs *regs,
                          unsigned long stack_size,
                          int __user *child_tidptr,
                          struct pid *pid,
                          int trace)
{
  struct task_struct *p;
  //1.复制进程内核栈(thread_info)和进程描述符结构
  p = dup_task_struct(current);
  //2.一些相关处理
  。。。 shm_init_task(p);
  security_task_alloc(p, clone_flags);
  if (nr_threads >= max_threads)
      goto bad_fork_cleanup_count;
  //3.复制父进程的所有数据结构
  copy_semundo(clone_flags, p);
  copy_files(clone_flags, p);
  copy_fs(clone_flags, p);
  copy_sighand(clone_flags, p);
  copy_signal(clone_flags, p);
  copy_mm(clone_flags, p);
  copy_namespaces(clone_flags, p);
  copy_io(clone_flags, p);
  //4.初始化子进程的内核栈。将寄存器%eax置为0，也是子进程pid返回0的原因
  copy_thread_tls(clone_flags, args->stack, args->stack_size, p,
                  args->tls);

  stackleak_task_init(p);
  pid = alloc_pid(p->nsproxy->pid_ns_for_children); //分配新的 Pid
  //设置子进程的 pid
  p->pid = pid_nr(pid);
  //如果是创建线程
  if (clone_flags & CLONE_THREAD)
  {
    p->exit_signal = -1;
    p->group_leader = current->group_leader;
    //tgid 是当前线程组的 id
    p->tgid = current->tgid;
  }
  else
  {
    if (clone_flags & CLONE_PARENT)
      p->exit_signal = current->group_leader->exit_signal;
    else
      p->exit_signal = (clone_flags & CSIGNAL);
    p->group_leader = p;
    p->tgid = p->pid;
  }

  if (clone_flags & (CLONE_PARENT | CLONE_THREAD))
  {
    //如果是创建线程，那么同一线程组内的所有线程共享进程空间
    p->real_parent = current->real_parent;
    p->parent_exec_id = current->parent_exec_id;
  }
  else
  {
    //如果是创建进程，当前进程就是子进程的父进程
    p->real_parent = current;
    p->parent_exec_id = current->self_exec_id;
  }

  attach_pid(p, PIDTYPE_PID);
  nr_threads++;

  //返回被创建的 task 结构体指针
  return p;
}

/*为新进程创建新的内核堆栈(thread_info)和PCB(task_struct)结构。*/
static struct task_struct *dup_task_struct(struct task_struct *orig)
{
       struct task_struct *tsk;
       struct thread_info *ti;
       int node = tsk_fork_get_node(orig);

       //创建进程描述符对象 
       tsk = alloc_task_struct_node(node);
       //创建进程内核栈 thread_info
       ti = alloc_thread_info_node(tsk, node);
       //使子进程描述符和父进程一致
       err = arch_dup_task_struct(tsk, orig);
       //进程描述符stack指向thread_info
       tsk->stack = ti;
       //使子进程thread_info内容与父进程一致但task指向子进程task_struct
       setup_thread_stack(tsk, orig);
       return tsk;
}
```

* fork函数大部分操作都是在do_fork函数进行的

* 首先判断是否需要跟踪这个进程，这一步主要用于GDB调试
* 接着函数调用copy_process函数，这个函数是用来设置进程描述符和子进程所需的内核数据结构
* copy_process函数首先调用dup_task_struct函数为新进程创建新的内核栈、thread_info和PCB，此时子进程和父进程描述符完全相同
* 检查当前用户拥有的进程数是否超过分配的限制
* 初始化子进程的内核栈，将其与父进程区分开来，如将寄存器%eax置为0，这也是子进程pid=0的原因
* 子进程状态被设置为不可中断的睡眠状态，保证它不会投入运行
* 复制父进程的所有数据结构（父进程打开的文件、父进程的信号）
* 分配和设置子进程的PID
* 设置子进程的父进程
* 最后copy_process函数做清楚工作并返回一个指向子进程的指针
* 返回到_do_fork函数，如果copy_process函数成功返回，那么子进程将被唤醒并将其投入使用



**写时复制技术**

原因：传统的fork是子进程的虚拟空间都会拷贝父进程的代码段、数据段，物理空间会父子父进程的数据段，但是fork之后往往是会执行exec调用别的程序，那么前面的复制过程将白费，使用写时复制技术，将推迟甚至避免拷贝。内核此时并不复制整个进程地址空间，而是让父进程和子进程共享一个拷贝。

引入Copy-on-write技术后：fork出的子进程只创建了自己的地址空间，如何父进程的地址空间初始化，每个页表项置为父进程的页表项，共享父进程的物理页，并将所有页面改为只读。当改变父子进程的数据时，cpu运行会发生缺页错误，因此cpu状态控制权给操作系统，操作系统会给子进程分配一个新的物理页，然后将页表该页地址修改成新的物理页地址



好处：避免拷贝大量无用的数据，使Unix进程就有快速执行的能力







**可执行状态**

Linux系统中将运行态和就绪态统一为TASK-RUNNING状态，同时将这些进程链接组成双向链表，称为可运行队列



exec函数族

```cpp
#include<unistd.h>

字母p:
不 带 字 母 p(表 示path)的第一个参数必须是程序的相对路径或绝对路径,例如“/bin/ls”或“./a.out”,
而不能是“ls”或“a.out”。

对于带字母p的函数:如果参数中包含/,则将其视为路径名。
否则视为不带路径的程序名,在PATH环境变量的目录列表中搜索这个程序。

字母l:
带有字母l(表示list)的要求将新程序的每个命令行参数都当作一个参数传给它,
命令行参数的个数是可变的,因此函数原型中有...,...中的最后一个可变参数应该是NULL

字母v:
对于带有字母v(表示vector)的函数,则应该先构造一个指向各参数的指针数组,
然后将该数组的首地址当作参数传给它,数组中的最后一个指针也应该是NULL,
就像main函数的argv参数或者环境变量表一样。

字母e:
对于以e(表示environment)结尾的exec函数,可以把一份新的环境变量表传给它,
其他exec函数仍使用当前的环境变量表执行新程序。
    
exec调用举例如下:
char *const ps_argv[] ={"ps", "-o", "pid,ppid,pgrp,session,tpgid,comm", NULL};
char *const ps_envp[] ={"PATH=/bin:/usr/bin", "TERM=console", NULL};
execl("/bin/ps", "ps", "-o", "pid,ppid,pgrp,session,tpgid,comm", NULL);
execv("/bin/ps", ps_argv);
execle("/bin/ps", "ps", "-o", "pid,ppid,pgrp,session,tpgid,comm", NULL, ps_envp);
execve("/bin/ps", ps_argv, ps_envp);
execlp("ps", "ps", "-o", "pid,ppid,pgrp,session,tpgid,comm", NULL);
execvp("ps", ps_argv);
```







**可中断的睡眠状态**

```cpp
Linux中等待队列是由一个wait_queue结构体组成的单向循环链表
struct wait_queue {
    struct task_struct *task;
    struct wait_queue *next;
}
```



当进程调用一个阻塞的系统函数，该进程被置于睡眠状态，这是内核调度其他进程运行，直到该进程等待的事件发生了（网络上接到数据包，调用sleep指定的睡眠时间到了），他才有可能继续运行

处于这个状态的进程因为等待某某事件的发生（比如等待socket链接，等待信号量）而被挂起，这些进程的task_struct结构将被放入对应事件的等待队列中，当这些事件发生后，对应的等待队列的一个或者多个进程将被唤醒

一般情况下，进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE状态



**不可中断的睡眠状态**

与TASK_INTERRUPTIBLE状态类似，进程处于睡眠状态，但是此刻进程是不可中断的，不可中断不是CPU不响应外部硬件的中断，而是指进程不响应异步信号。TASK_UNINTERRUPTIBLE状态存在的意义在于，内核的某些处理流程是不能被打断的，比如在进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行对应设备驱动的代码，并与对应的物理设备进行交互，需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护，以免造成设备陷入不可控的状态，由于这个状态非常短暂，所以ps命令很难捕捉到



**暂停或者追踪状态**

向进程发送一个SIGSTOP信号，它就会因响应该信号而进入TASK_STOPPED状态。（SIGSTOP与SIGKILL信号一样，是非常强制的。不允许用户进程通过signal系列的系统调用重新设置对应的信号处理函数。）

当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。

向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。

而TASK_TRACED状态相当于在TASK_STOPPED之上多了一层保护，处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。



**终止状态**

僵尸进程

* 概念：一个进程执行系统调用exit函数结束自己的生命时，进程占有的所有资源将被回收，除了task_struct结构其中包含了退出状态以及对一些其他对父进程有用的信息，这个保留下来的PCB就成为僵尸进程
* 原因：如果一个进程已经终止，但是它的父进程没有对它进行清理，这时子进程将会一直保持僵尸状态
* 危害：父进程不断创建子进程，而子进程存活时间短，若父进程对子进程的终止状态不管不顾，将会产生许多的僵尸进程，而每一个僵尸进程都占用一个进程列表，时间一长就没有多余的地方来创建进程
* 解决方法
  * 使用wait/waitpit
  * 父进程不关心子进程什么时候结束，那么可以使用signal(SIGCHILD, SIGINT) 通知内核，子进程推出后由内核负责回收

孤儿进程

* 概念：父进程先于子进程结束，则子进程称为孤儿进程，子进程的父进程变成了1号进程init



```cpp
#include <sys/types.h>
#include <sys/wait.h>
// 返回：如果成功，则为子进程的 PID，如果出错，则为-1. 
pid_t waitpid(pid_t pid, int *status , int options);
// 返回：如果成功，则为子进程的 PID. 如果出错，则为-1.等价于waitpit(-1, &status, 0)
pid_t wait(int *status);

检查已回收子进程的退出状态
WIFEXITED(status)：如果子进程通过调用 exit 或者一个返回(return)正常终止，就返回真
WEXITSTATUS(status) ： 返回正常终止子进程的退出状态
WIFSIGNALED(status)：如果子进程是因为一个信号终止的，那么就返回真
两个函数的区别
1. 如果父进程的所有子进程都还在运行,调用wait将使父进程阻塞,而调用waitpid时如
果在options参数中指定WNOHANG可以使父进程不阻塞而立即返回0。
2. wait等待第一个终止的子进程,而waitpid可以通过pid参数指定等待哪一个子进程。
```





**Linux查看进程状态**

```shell
ps -aux
1.R——Runnable（运行）：正在运行或在运行队列中等待
2.S——interruptible sleeping（中断）：休眠中，受阻，在等待某个条件的形成或接收到信号
3.D——uninterruptible sleep(不可中断)：收到信号不唤醒和不可运行，进程必须等待直到有中断发生
4.Z——zombie（僵死）：进程已终止，但进程描述还在，直到父进程调用wait4()系统调用后释放
5.T——traced or stoppd(停止)：进程收到SiGSTOP,SIGSTP,SIGTOU信号后停止运行
状态后缀表示：
<：优先级高的进程
N：优先级低的进程
L：有些页被锁进内存
s：进程的领导者（在它之下有子进程）
+：位于后台的进程组
```





### 进程的调度

任务

* 保存处理器现场信息
* 按某种算法选取进程
* 把处理器给配给进程

#### 调度算法

按进程分类可以被分为IO密集型和计算密集型

IO密集型：大部分时间都是用来提交IO请求或是等待IO请求，因此运行时会因为经常等待IO情况导致进程处于阻塞状态，比如大多数的用户图形新界面等待来自鼠标或者键盘的用户交互操作，这类进程的目标是要求响应时间短

计算密集型：大部分时间用在执行代码上，这类进程的目标是高吞吐量

按进程的调度方式可分为抢占方式和非抢占方式

非抢占方式：一旦将处理机分配给某个进程，就让他一直运行下去，不会被其它进程抢占，直到进程完成或发生某事件而阻塞，才会将处理机分配给其他进程

抢占方式：非抢占的缺点是进程可能会长时间占用处理机，为确保处理机能公平地为所有进程提供服务，采用了抢占方式，抢占方式满足了实时任务的需要。但是抢占的方式比较复杂且系统开销较大

调度策略通常需要在这点寻找平衡：响应时间、高吞吐量



**先来先服务调度算法**

顾名思义。就是先来的先进入内存或占用处理机。对于作业调度，就是从后备作业队列中选择一个或多个最先进入队列的作业，将其调入内存。对于进程调度就是从就绪队列选择最新进入的进程，为之分配处理机。

优点：实现简单

缺点：有时短作业等待时间过长，对短作业不公平



**短作业优先调度算法**

顾名思义。就是在选择作业或进程的时候，先估算每个作业、进程的服务时间，选择其中最短的优先获得处理机。

优点：具有最短的平均周转时间

缺点：长作业容易产生饥饿现象



什么是优先级倒置现象？可以采用什么方法来解决？

低优先级进程先占有了高优先级进程所需的临界资源（CPU），而阻塞高优先级进程，这样就会出现优先级倒置现象

解决方法：当进程进入临界区，CPU就不能被剥夺



**优先级调度算法**

这种算法给进程加了一个属性，那就是优先权。这个算法的本质就是，高优先权的优先调用。优先权有两种类型，一种是静态的，即每个进程、作业的优先权在它创建的时候就已经确定，此后都不能改变。另一种是动态的，即进程、作业的优先权是可以改变的。最常见的做法就是进程、作业在等待中，优先权以一定速率随时间增长，这样等待时间越长，被调用的可能性就越大。





**基于时间片轮转调度算法**

这就是分时系统中采用的调度算法。原理就是把所有的就绪队列进程按先来先服务的原则排成队列。每次都把CPU分配给队首，让其执行一个时间片，执行完毕，调度器中断进程，并把该进程移至就绪队列的队尾，然后再取一个队首进程，继续执行下一个时间片。时间片是什么，就是一段很短的CPU时间，几毫秒到几百毫秒不等。



**多级反馈队列调度算法**

实质就是前面算法的结合体：优先级+多级队列+时间片

* 设置多个就绪队列，对每个队列赋予优先级，优先级由高到低，优先级越高所赋予的执行时间的时间片越短
* 每个队列采用FCFS算法
* 只有当优先级高的队列空闲，才能去调用优先级低的队列

这是当下公认的比较好的，使用最广泛的调度算法。其原理也不难。例如，某计算机采用多级反馈队列调度算法，设置了5个就绪队列。第一个就绪队列优先级最高，时间片为2ms。第二个就绪队列优先级第二，时间片为4ms，其余队列也一样，优先级依次递减，时间片依次增加。如果某个进程进入就绪队列，首先把它放在第一个就绪队列的末尾，轮到它执行就执行2ms，时间片结束，若该进程还没有执行完毕，就把该进程移入第二个就绪队列的末尾。只有当第一个队列的进程都执行完时间片，才会执行第二个队列。如此依次执行，若该进程服务时间很长，将被移到最后一个就绪队列。在最后一个就绪队列，进程将按照时间片轮转调度法执行。处理机执行过程中，只有当优先级高的队列中的线程都执行完毕，才会执行优先级低的队列。



优点

* 所有作业在很短的时间内启动，用户获得响应
* 短批处理作业能在较短时间内完成
* 系统吞吐量高
* 长批处理作业不会造成饥饿现象





**CFS调度算法**

* 动态优先级：0（低优先级）到99（高优先级），该值可动态配置，针对RT进程
* 静态优先级：使用nice值-20（高优先级）到19（低优先级），针对普通进程
* 完全公平的含义就是所有进程的虚拟时间都相同，通过虚拟时间将静态优先级和动态优先级映射到了虚拟时间上，屏蔽掉了静态优先级的影响

引入了虚拟时间 Virtual runtime ＝ （physical runtime） X （nice value 0的权重）/进程的权重



* 通过物理时间来计算虚拟时间，然后以虚拟时间为key插入到红黑树中，最小虚拟时间的进程将被优先调度







[Linux进程调度算法的前世](https://mp.weixin.qq.com/s/W68WIT4AGdS7xJSecnHYcQ)



#### 死锁

**概念**

死锁发生在两个或两个以上进程在执行过程中，因为争夺资源而造成的一种相互等待的现象，若无外力作用，他们将无法推进下去，此时称为死锁



**必要条件**

只要系统发生死锁，那么这四个条件必然成立

* 互斥条件：同一时间段内，某资源只能被一个进程占有（临界资源），如果它被其他进程请求该资源，则请求过程只能阻塞等待
* 请求和保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放
* 不可抢占条件：进程以获得的资源，在未使用完之前，不能被强行剥夺
* 循环等待条件：若干个进程之间形成了一种头尾相连的循环等待资源关系



**解决方法**

解决死锁一般有预防死锁、避免死锁、死锁检测和解除

**预防死锁**：事先预防，打破死锁的必要条件

* 破坏请求和保持条件

第一种方式：进程必须一次性申请整个运行过程中的资源

优点：简单、易行

缺点：容易造成进程的饥饿现象；资源被浪费

第二种方式：是第一种方式的改进。运行一个进程只获得初期所需的资源后，便开始运行。进程运行过程中会逐步释放已分配给自己的资源，然后再申请新的资源

* 破坏不可抢占条件

当一个已经保持某些不可抢占的资源时，提出新的资源请求不能得到满足，则必须释放已经保持的所有资源

评价：实现复杂，且需要付出很大的代价

* 破坏循环等待条件

有序资源分配法：对系统的所有资源按线性排序，并赋予不同的序号，规定每个进程必须按序号递增的顺序请求资源，当需要请求序号较低的资源必须先释放所持有的相同或更高序号的资源，然后再进行申请

评价：各类资源所规定的序号相对稳定，限制了新类型设备的添加



**避免死锁**：事先预防，通过某种方法检测资源动态分配过程中是否进入不安全状态，从而避免死锁（银行家算法）

安全状态：允许进程动态申请资源，但在系统进行资源分配之前，应计算资源分配的安全性

不安全状态：分配资源时使系统陷入死锁

银行家算法：基本步骤是先判断有无资源分配的可能，若有可能则进行预分配，判断预分配后的系统是否安全，若安全，才真正实施分配

银行家算法的数据结构

（1）可利用资源向量Available，$Available[j]=K$表示现有的资源Rj个数为K

（2）最大需求矩阵Max，$Max[i，j]=K$表示进程i需要Rj资源数为K

（3）分配矩阵Allocation，$Allocation[i，j]=K$表示进程i现有Rj资源数为K

（4）需求矩阵Need，$Need[i，j]=K$表示现在进程还需要Rj资源数为K

上述三个矩阵存在如下关系

$Need[i，j] = Max[i，j] - Allocation[i，j]$​

算法步骤

每个新进程进入系统，必须事先声明每种资源的最大单元数目

$Request_i[j]=K$表示进程$Pi$需要K个$R_j$资源，当进程发出申请后，系统会进行检查

1. $Request_i[j] <= Need[i，j]$便转向2
2. $Request_i[j] <= Available[i，j]$转向步骤3
3. 系统**试探性**把资源分配给进程$Pi$，并对数据结构进行如下修改
   * $Allocation[i，j]= Allocation[i，j] + K$
   * $Available[j] = Available[j] - K$
   * $Need[i，j] = Need[i，j] - K$
4. 执行安全性算法

安全性算法数据结构

（1）工作向量$Work:=Available$，表示系统可提供给进程继续运行所需的各个资源数

（2）Finish：表示系统是否有足够的资源分配给进程，使之运行完成，开始时$Work:=false$

算法步骤

1. 从进程集合找到一个能够满足下述条件的进程，若找到执行2，否则执行3
   * $Finish[i]=false$
   * $Need[i, j] <= Work[j]$
2. 当进程$Pi$获得资源后，可以顺利执行，并释放出它分配的资源，此时执行
   * $ Work[j] = Work[j] + Allocation[i, j] $
   * $Finish[i] = true$
   * 继续执行1

3. 如果所有进程的$Finish[i] = true$，则表示系统处于安全状态；否则为不安全状态



**检测死锁**：不试图阻止死锁，而是检测到死锁发生时，采取措施进行恢复



**解除死锁**：发生死锁，采取某种措施解除死锁

* 抢占资源
* 终止或撤销进程





#### 进程上下文切换

* CPU上下文

电脑执行程序的过程就是CPU不断执行指令的过程，CPU执行指令的过程第一步是取指令将其放到寄存器，然后对指令进行译码，进行操作，最后计算下一条指令地址，将其送到程序计数器，CPU根据程序计数器的地址取指，将取到的指令送到指令寄存器。

因此，在程序执行前，需要系统事先将CPU的寄存器和程序计数器设置好

* 进程的用户态内核态转化引起的上下文转换

进程由于系统调用或者异常进入内核态，将这个进程在用户态的CPU上下文存储起来，找到对应系统调用指令地址，并将其加载到CPU的上下文中，系统调用结束后，内核态转为用户态，CPU上下文被切换为原来的上下文，因此一次系统调用的过程，发生了两次CPU上下文切换，这种上下文切换发生在一个进程中

* 进程间的上下文转换

引发原因：时间片耗尽，进程sleep挂起，硬件中断

过程

1. 切换页目录以使用新的地址空间
2. 切换内核栈（进程在内核态的上下文）
3. 切换CPU上下文

接收到切换信号，挂起进程，保存当前的用户态资源，将这个进程在CPU中的上下文储存起来，然后在内存寻找下一个进程的上下文，并加载到CPU上下文当中





#### Linux进程上下文切换

linux上下文切换主要工作有：地址空间的切换、处理器上下文切换



**处理器上下文切换**

处理器上下文切换就是将前一个进程的数据和当前执行的指令地址存放在一块内存当中，即将要执行进程的数据和将要执行指令的地址从内存恢复到寄存器当中



**地址空间切换**

Linux的进程地址空间是使用成员变量mm_struct结构体来描述的，这个结构体最重要的成员就是pgd（页全局目录的虚拟地址），地址空间切换中最重要的就是pgd的切换，该pgd最开始的设置是在fork进程时，分配进程地址空间，会分配进程页全局目录的所在页，然后将首地址赋给pdg

进程地址空间切换时，很简单且优雅的可以将pdg转化为物理地址然后存放在页表基址寄存器中，当访问用户地址空间时，MMU会从寄存器获取pdg然后遍历页表获得物理地址，地址空间切换还会清空tlb，由于新进程切换时，面对的是空的tlb，造成了很大的性能损耗，因此使用了ASID来减少tlb的清空



**ASID机制**

ASID叫做地址空间唯一标识符，是为了减少进程切换tlb被清空的机会，ASID是用来区分不同的进程页表项

* 组成：软件ASID由全局ASID版本号和新分配的硬件ASID组成，一共64位
* 内核会为每个进程分配一个软件ASID，存放在了mm_struct结构体中的context结构的id中，进程创建后值初始化为0
* 内核使用位图来管理硬件ASID的分配
* 硬件ASID分配策略
  * 如果进程的ASID版本号与全局的ASID版本号相同，则不需要重新分配ASID
  * 如果进程的ASID版本号与当前全局的ASID版本号不相同，且进程原本的硬件ASID已经被分配，则需要将当前全局ASID版本号组合新分配的硬件ASID写到进程的软件ASID中
  * 如果进程的ASID版本号与当前全局的ASID版本号不相同，原本的硬件ASID还没被分配，那么只需要更新ASID版本号，同时将位图对应的位置为1
  * 如果进程的ASID版本号与当前全局的ASID版本号不相同，且位图都为1，说明当前版本的硬件ASID均被分配完毕，这个时候才清空tlb，清空位图，全局ASID版本号+1，然后再重新分配软件ASID







### 进程的通信

每个进程都有自己的地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间交换数据必须通过内核，在内核当中开辟一条缓冲区，一个进程把数据从用户空间拷贝到内核缓冲区，另一个进程再从内核缓冲区把数据读走，内核提供的这种机制称为（基于共享内存）的进程间通信（IPC, Inter Process Communication）



#### 信号

**介绍**

实质是软件层面上对CPU中断机制的模拟，CPU在碰到外部应急事件时如用户按击键盘、网络分组到达，电源故障，相关部件会发送一个信号，这是CPU会立即暂停当前执行的程序，保存CPU上下文，转去执行中断处理程序，处理完毕后，再返回之前程序继续执行，信号机制则是通知了进程系统中发生了与该进程相关的某种事件，这个事件可能是来自用户、内核、其它进程，比如用户在命令行按Ctrl+C，则会终止当前进程，实际上是用户发送了一个SIGINT进程终止信号。信号是一种进程间异步通信机制，每种信号是用1-31或者1-63的整数表示

**信号的工作原理**

1. **信号的诞生**

来源

* 内核检测到系统事件，比如除0错误，内存访问越界时，会发送信号
* 人为调用信号发送函数发送指定的信号

**函数**

```cpp
#include <sys/types.h>
#include <signal.h>
// 该系统调用可以用来向任何进程或进程组发送任何信号。参数pid的值为信号的接收进程
// pid>0 进程ID为pid的进程
// pid=0 同一个进程组的进程
// pid<0 pid!=-1 进程组ID为 -pid的所有进程
// pid=-1 除发送进程自身外，所有进程ID大于1的进程
int kill(pid_t pid, int sig);
// 向进程本身发送信号，参数为即将发送的信号值。调用成功返回 0；否则，返回 -1。
int raise(int sig);


#include <unistd.h>
// 系统调用alarm安排内核为调用进程在指定的seconds秒后
// 给调用alarm的进程发出一个SIGALRM的信号。
// 如果指定的参数seconds为0，则不再发送 SIGALRM信号。
// 后一次设定将取消前一次的设定。
// 该调用返回值为上次定时调用到发送之间剩余的时间，
// 或者因为没有前一次定时调用而返回0。
// 注意，在使用时，alarm只设定为发送一次信号，如果要多次发送，就要多次使用alarm调用。
unsigned int alarm(unsigned int seconds)

    
#include <stdlib.h>
// 向进程发送SIGABORT信号，默认情况下进程会异常退出，当然可定义自己的信号处理函数。
// 即使SIGABORT被进程设置为阻塞信号，调用abort()后，SIGABORT仍然能被进程接收。该函数无返回值。
void abort(void);
```



**kill的替代函数sigqueue**

```cpp
#include <sys/types.h>
#include <signal.h>
int sigqueue(pid_t pid, int sig, const union sigval val)
// 调用成功返回 0；否则，返回 -1。


// 第一个参数是指定接收信号的进程ID，第二个参数确定即将发送的信号，第三个参数是一个联合数据结构union sigval，指定了信号传递的参数

typedef union sigval {
    int  sival_int;
    void *sival_ptr;
} sigval_t;
 
/* 区别:
sigqueue()是比较新的发送信号系统调用，主要是针对实时信号提出的（当然也支持前32种），支持信号带有参数，与函数sigaction()配合使用。

sigqueue()比kill()传递了更多的附加信息，但sigqueue()只能向一个进程发送信号，而不能发送信号给一个进程组。

在调用sigqueue时，sigval_t指定的信息会拷贝到对应sig注册的3参数信号处理函数的siginfo_t结构中，这样信号处理函数就可以处理这些信息了。由于sigqueue系统调用支持发送带参数信号，所以比kill()系统调用的功能要灵活和强大得多。*/
```



**alarm的替代函数setitimer**

```cpp
现在的系统中很多程序不再使用alarm调用，而是使用setitimer调用来设置定时器，用getitimer来得到定时器的状态，这两个调用的声明格式如下：

int getitimer(int which, struct itimerval *value);

int setitimer(int which, const struct itimerval *value, struct itimerval *ovalue);

在使用这两个调用的进程中加入以下头文件：

#include <sys/time.h>

参数:

该系统调用给进程提供了三个定时器，它们各自有其独有的计时域，当其中任何一个到达，就发送一个相应的信号给进程，并使得计时器重新开始。三个计时器由参数which指定，如下所示：

TIMER_REAL：按实际时间计时，计时到达将给进程发送SIGALRM信号。

ITIMER_VIRTUAL：仅当进程执行时才进行计时。计时到达将发送SIGVTALRM信号给进程。

ITIMER_PROF：当进程执行时和系统为该进程执行动作时都计时。与ITIMER_VIR-TUAL是一对，该定时器经常用来统计进程在用户态和内核态花费的时间。计时到达将发送SIGPROF信号给进程。

 

定时器中的参数value用来指明定时器的时间，其结构如下：

struct itimerval {
    struct timeval it_interval; /* 下一次的取值 */
    struct timeval it_value; /* 本次的设定值 */
};

 

该结构中timeval结构定义如下：

struct timeval {
    long tv_sec; /* 秒 */
    long tv_usec; /* 微秒，1秒 = 1000000 微秒*/
};

 
返回值 :
在setitimer 调用中，参数ovalue如果不为空，则其中保留的是上次调用设定的值。定时器将it_value递减到0时，产生一个信号，并将it_value的值设定为it_interval的值，然后重新开始计时，如此往复。当it_value设定为0时，计时器停止，或者当它计时到期，而it_interval 为0时停止。调用成功时，返回0；错误时，返回-1，并设置相应的错误代码errno：

EFAULT：参数value或ovalue是无效的指针。
```



**/bin/kill 程序发送信号**

/bin/kill 程序可以向另外的进程发送任意的信号，比如

```shell
ki11 -9 15213
```

表示发送信号9（SIGKILL）给进程15213。





2. **信号注册**

信号产生后，需要让进程感知，因此在进程task_struct当中设置了未觉信号集sigpending

未觉信号集：位于task_struct表项的数据结构，该域中每一位对应一个信号。内核给一个进程发送软中断信号的方法，是在这个数据结构中的域设置对应于信号的位

```cpp
struct sigpending{
    struct sigqueue *head, *tail;
    sigset_t signal;
};

第一、第二个成员分别指向一个sigqueue类型的结构链（称之为"未决信号信息链"）的首尾，
信息链中的每个sigqueue结构刻画一个特定信号所携带的信息，并指向下一个sigqueue结构:

struct sigqueue{
    struct sigqueue *next;
    siginfo_t info;
}

第三个成员是进程中所有未决信号集，
信号集数据结构

信号集被定义为一种数据类型：
typedef struct {
    unsigned long sig[_NSIG_WORDS]；
} sigset_t

信号集用来描述信号的集合，每个信号占用一位。

信号在进程中注册指的就是信号值加入到进程的未决信号集sigset_t signal（每个信号占用一位）中，
并且信号所携带的信息被保留到未决信号信息链的某个sigqueue结构中。只要信号在进程的未决信号集中，
表明进程已经知道这些信号的存在，但还没来得及处理，或者该信号被进程阻塞。
```

（非实时信号）不可靠信号：早期Unix的信号是不可靠的，不可靠是信号可能会丢失，一个信号发送了，而进程却不知道。

（实时信号）可靠的信号：可靠信号可以被多次发送，也可以多次注册在进程，信号因此不会丢失

信号注册：信号注册却决于信号值，信号值小于SIGMIN的信号最多被注册一次，信号值介于SIGMIN与SIGMAX之间的信号，只要被进程接收就被注册



3. **信号屏蔽**

每个进程都有一个用来描述被阻塞的信号量集，该信号量集中的信号被送进进程将会被阻塞

```cpp
int sigsuspend(const sigset_t *mask))；
sigsuspend(const sigset_t *mask))用于在接收到某个信号之前, 临时用mask替换进程的信号掩码, 并暂停进程执行，直到收到信号为止。sigsuspend 返回后将恢复调用之前的信号掩码。信号处理函数完成后，进程将继续执行。该系统调用始终返回-1，并将errno设置为EINTR。
```







4. **信号处理时机**

在进程从内核态返回用户态时会检测是否有信号在等待处理且该信号没有被进程阻塞，如果有则在信号处理执行之前，进程把信号在未觉信号链上移除，对于非实时信号来说，由于最多被注册一次，所以会将该信号从信号量集中注销，对于实时信号会直到该信号的所有sigqueue结构都被移除，才会在信号量集中注销该信号





5. **信号处理**

进程收到信号后，有三种执行动作

1. 对信号做缺省操作，一般是进程终结
2. 忽略某个信号，对该信号不做任何处理
3. 执行信号处理函数

如果经常要处理某一信号，需要在进程中安装该信号，安装信号主要是用来确定信号的值和要执行的动作。

Linux提供了两种信号安装函数signal()和sigaction()，signal()只有两个参数，不支持信号传递信息，主要用于前32个非实时信号的安装，而signaction()是较新的函数，有3个参数，支持信号传递信息，主要和sigqueue()系统调用配合使用，signaction优于signal主要体现在支持信号带有参数

```cpp
#include <signal.h>

void (*signal(int signum, void (*handler))(int)))(int);

如果该函数原型不容易理解的话，可以参考下面的分解方式来理解：

typedef void (*sighandler_t)(int)；

sighandler_t signal(int signum, sighandler_t handler));

第一个参数指定信号的值，第二个参数指定针对前面信号值的处理，可以忽略该信号（参数设为SIG_IGN）；可以采用系统默认方式处理信号(参数设为SIG_DFL)；也可以自己实现处理方式(参数指定一个函数地址)。

如果signal()调用成功，返回最后一次为安装信号signum而调用signal()时的handler值；失败则返回SIG_ERR。

传递给信号处理例程的整数参数是信号值，这样可以使得一个信号处理例程处理多个信号。
```





```cpp
#include <signal.h>

int sigaction(int signum,const struct sigaction *act,struct sigaction *oldact));

sigaction函数用于改变进程接收到特定信号后的行为。第一个参数为信号的值，可以为除SIGKILL及SIGSTOP外的任何一个特定有效的信号（为这两个信号定义自己的处理函数，将导致信号安装错误）。
第二个参数是指向结构sigaction的一个实例的指针，在结构sigaction的实例中，指定了对特定信号的处理，可以为空，进程会以缺省方式对信号处理；
第三个参数oldact指向的对象用来保存返回的原来对相应信号的处理，可指定oldact为NULL。如果把第二、第三个参数都设为NULL，那么该函数可用于检查信号的有效性。
struct sigaction {
    union{
        __sighandler_t _sa_handler;
        void (*_sa_sigaction)(int,struct siginfo *, void *);
    }_u;
    sigset_t sa_mask;
    unsigned long sa_flags;
}
```





#### 管道

**无名管道**

概念

管道就是操作系统内核的一个内存缓冲区，对于这个文件的操作要通过两个进程进行，这两个进程对应了管道的两端。一个进程向管道中写的内容被管道另一端的进程读取。

特性

* 只能用于有亲缘关系的进程之间的通信
* 半全双工的通信模式，具有固定的读端和写端
* 管道可以看成一种特殊的文件，可以使用IO中的read和write函数

使用方式

```cpp
无名管道可以由pipe()函数创建

#include <unistd.h>
int pipe(int pipefd[2]);

pipe函数调用成功返回0，调用失败返回-1。
pipefd[0]对应读端，pipefd[1]对应写端
```



**有名管道**

概念

为了克服无名管道的缺点而提出的

* 无名管道只能用于具有亲缘关系的进程之间，限制了无名管道的使用
* 有名管道可以通过路径名指出，这个路径名在文件系统中可见，即使是两个没有关系的进程也能互相通信

创建

* 命令行创建

```shell
$ mkfifo myfifo
```

* API创建

```cpp
#include <sys/types.h>
#include <sys/stat.h>


int mkfifo(const char *filename,mode_t mode);

mkfifo函数成功返回0，失败返回-1并且设置errno。
O_RDONLY、O_WRONLY和O_NONBLOCK标志共有四种合法的组合方式：

flags=O_RDONLY：open将会调用阻塞，除非有另外一个进程以写的方式打开同一个FIFO，否则一直等待。

flags=O_WRONLY：open将会调用阻塞，除非有另外一个进程以读的方式打开同一个FIFO，否则一直等待。

flags=O_RDONLY|O_NONBLOCK：如果此时没有其他进程以写的方式打开FIFO，此时open也会成功返回，此时FIFO被读打开，而不会返回错误。

flags=O_WRONLY|O_NONBLOCK：立即返回，如果此时没有其他进程以读的方式打开，open会失败打开，此时FIFO没有被打开，返回-1。
```

使用



**PIPE和FIFO的区别和联系**

相同点

* 虽然管道，特别是有名管道可以很方便地在双向打开读写，但是其内核实现仍然是单向的
* 读总是从最开始读取数据，写总是把数据添加到末尾
* 都不支持lseek等文件定位操作

区别

* 创建并打开一个管道只需调用pipe，创建并打开一个FIFO需要在调用mkfifo后再调用open



#### 消息队列

消息队列就是消息的链表，存放于内核当中，一个消息队列由一个标识符来标识

消息队列独立于发送和接收进程的存在，消除了同步命名管道的打开和关闭时可能产生的麻烦，消息队列提供了一种进程之间以数据块为单位传输数据方法，每个数据块可被看作某种数据类型，接收进程可以独立地接收含有不同类型值的数据块，除了可以避免命名管道的同步和阻塞问题外，还可以提前查看紧急消息。与管道类似，其不足之处就是每个数据块都有最长大小限制，总长度也有上限

![](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/消息队列结构.png)

特点

* 生命周期随内核，消息队列会一直存在，需要使用手动来删除
* 消息队列可以双向通信
* 解决了管道只能传输无格式字节流的缺点

相关函数

```cpp
1.msgget
功能：创建和访问一个消息队列 
原型：

#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/msg.h>
int msgget(key_t key, int msgflag);

参数： 
key：某个消息队列的名字，用ftok()产生 
msgflag：有两个选项IPC_CREAT和IPC_EXCL，单独使用IPC_CREAT，如果消息队列不存在则创建之，如果存在则打开返回；单独使用IPC_EXCL是没有意义的；两个同时使用，如果消息队列不存在则创建之，如果存在则出错返回。 
返回值：成功返回一个非负整数，即消息队列的标识码，失败返回-1

#include <sys/types.h>
#include <sys/ipc.h>
key_t ftok(const char *pathname, int proj_id);

调用成功返回一个key值，用于创建消息队列，如果失败，返回-1

2.msgctl
功能：消息队列的控制函数 
原型：

#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/msg.h>
int msgctl(int msqid, int cmd, struct msqid_ds *buf);

参数： 
msqid：由msgget函数返回的消息队列标识码 
cmd：有三个可选的值，在此我们使用IPC_RMID

IPC_STAT 把msqid_ds结构中的数据设置为消息队列的当前关联值
IPC_SET 在进程有足够权限的前提下，把消息队列的当前关联值设置为msqid_ds数据结构中给出的值
IPC_RMID 删除消息队列
返回值： 
成功返回0，失败返回-1

3.msgsnd
功能：把一条消息添加到消息队列中 
原型：

#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/msg.h>
int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg);

参数： 
msgid：由msgget函数返回的消息队列标识码 
msgp：指针指向准备发送的消息 
msgze：msgp指向的消息的长度（不包括消息类型的long int长整型） 
msgflg：默认为0 
返回值：成功返回0，失败返回-1

消息结构一方面必须小于系统规定的上限，另一方面必须以一个long int长整型开始，接受者以此来确定消息的类型

struct msgbuf
{
     long mtye;
     char mtext[1];
};

4.msgrcv
功能：是从一个消息队列接受消息 
原型： 
ssize_t msgrcv(int msqid, void *msgp, size_t msgsz, long msgtyp, int msgflg); 
参数：与msgsnd相同 
返回值：成功返回实际放到接收缓冲区里去的字符个数，失败返回-1
    
// 删除消息队列
ipcs:显示IPC资源 
ipcrm:手动删除IPC资源 
```



#### 共享内存

概念

每个进程将一段地址空间分出来映射到同一段物理内存当中，

特征

* 最快的一种通信方式，因为没有中间直接，数据的共享不用传送而是直接访问内存
* 共享内存没有提供同步机制，需要配合信号量进行同步



![image-20210131200640532](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/共享内存通信原理.png)



相关函数

```cpp
// 共享内存创建
int shmget(key_t key, size_t size, int shmflg);

第一个参数，共享内存段的命名，shmget函数成功时返回一个与key相关的共享内存标识符（非负整数），用于后续的共享内存函数。调用失败返回-1.

注：其它的进程可以通过该函数的返回值访问同一共享内存，它代表进程可能要使用的某个资源，程序对所有共享内存的访问都是间接的，程序先通过调用shmget函数并提供一个键，再由系统生成一个相应的共享内存标识符（shmget函数的返回值），只有shmget函数才直接使用信号量键，所有其他的信号量函数使用由semget函数返回的信号量标识符。

第二个参数，size以字节为单位指定需要共享的内存容量。

第三个参数，shmflg是权限标志，它的作用与open函数的mode参数一样，如果要想在key标识的共享内存不存在时，创建它的话，可以与IPC_CREAT做或操作。共享内存的权限标志与文件的读写权限一样，举例来说，0644,它表示允许一个进程创建的共享内存被内存创建者所拥有的进程向共享内存读取和写入数据，同时其他用户创建的进程只能读取共享内存。
// 启动对共享内存的访问
void *shmat(int shm_id, const void *shm_addr, int shmflg);
第一次创建完共享内存时，它还不能被任何进程访问，shmat函数的作用就是用来启动对该共享内存的访问，并把共享内存连接到当前进程的地址空间。
第一个参数，shm_id是由shmget函数返回的共享内存标识。
第二个参数，shm_addr指定共享内存连接到当前进程中的地址位置，通常为空，表示让系统来选择共享内存的地址。
第三个参数，shm_flg是一组标志位，通常为0。
调用成功时返回一个指向共享内存第一个字节的指针，如果调用失败返回-1.
    
// 将共享内存从当前进程中分离出来
int shmdt(const void *shmaddr);
该函数用于将共享内存从当前进程中分离。注意，将共享内存分离并不是删除它，只是使该共享内存对当前进程不再可用。
参数shmaddr是shmat函数返回的地址指针，调用成功时返回0，失败时返回-1。
    
// 控制共享内存
int shmctl(int shm_id, int command, struct shmid_ds *buf);
第一个参数，shm_id是shmget函数返回的共享内存标识符。
第二个参数，command是要采取的操作，它可以取下面的三个值 ：
    IPC_STAT：把shmid_ds结构中的数据设置为共享内存的当前关联值，即用共享内存的当前关联值覆盖shmid_ds的值。
    IPC_SET：如果进程有足够的权限，就把共享内存的当前关联值设置为shmid_ds结构中给出的值
    IPC_RMID：删除共享内存段
第三个参数，buf是一个结构指针，它指向共享内存模式和访问权限的结构。

struct shmid_ds{
    uid_t shm_perm.uid;
    uid_t shm_perm.gid;
    mode_t shm_perm.mode;
}
// 指令
ipc -m:显示IPC共享内存资源 
ipcrm -m [shmid]:手动删除IPC共享内存资源  
```



#### 信号量机制

概念

信号量是一种表示和维护可用资源的数据结构，可以表示如下

```cpp
typedef struct _semaphore {
	intvalue; // 信号量值，表示可用资源数
	WaitQueue L; // 阻塞队列，等待资源的进程队列
} semaphore;
```

其本质就是一种封装了加1减1的操作。其基本思想就是当临界资源空闲时，让请求进程进入临界区，而当临界资源被占用时，强迫进程阻塞，避免浪费了CPU的时间（参考TS指令解决同步互斥问题）；并要求从临界区退出的进程唤醒其它因请求资源而被阻塞的进程，使其进入临界区。



PV操作

一组对信号量加一减一的原语操作

```cpp
P原语操作的动作是：
（1）S减1；
（2）若S减1后仍大于或等于零，则进程继续执行；
（3）若S减1后小于零，则该进程被阻塞后进入与该信号相对应的队列中，然后转进程调度。
primative wait(semaphore &S)
{
    if (S.value == 0)
    block(S.L); // 在队列 S.L 挂起
    S.value = S.value-1; // 可用资源数减1
}
V原语操作的动作是：
（1）S加1；
（2）若相加结果大于零，则进程继续执行；
（3）若相加结果小于或等于零，则转进程调度。
PV操作对于每一个进程来说，都只能进行一次，而且必须成对使用。在PV原语执行期间不允许有中断的发生。
primative signal(semaphore &S) //V 操作
{
    S.value=S.value+1; // 可用资源数加1
    if(!empty(S.L)) // 判断等待队列是否为空
    wakeup(S.L); // 唤醒一个等待线程
}
```



#### socket套接字

用于不同设备的进程之间的通信



### 经典同步问题

#### 生产者消费者问题

描述：是指若干个进程通过有限的缓冲区交换数据时缓冲区数据的使用问题。假设生产者进程不断向缓冲区写入数据，而消费者不断从缓冲区读出数据，缓冲区共N个。任何时刻只能有一个进程对共享缓冲区操作，所以生产者和消费者之间要协调，以完成对共享缓冲区的操作。

共享缓冲区当中，生产者写入的数据块为消费者的可用资源，消费者读出数据后的缓冲块为生产者的可用资源

* 设置full为有数据的缓冲块个数
* empty为无数据的缓冲块个数
* mutex为访问缓冲区的互斥，初值为1
* 有full+empty=N的关系成立

```cpp
semaphore full = 0, empty = N;
semaphore mutex = 1;
int buf[N];
void Producter() {
    int item;
    while (true) {
        item = produce();
        wait(empty);
        wait(mutex);
        // 插入数据
        insert(item, buf);
        signal(mutex);
        signal(full);
    }
}
void Customer() {
    int item;
    while (true) {
        wait(full);
        wait(mutex);
        item = remove(buf);
        signal(mutex);
        signal(empty);
    }
}
```



#### 读者写者问题

描述：有一个写者和多个读者，多个读者可以同时读文件，但是写者写文件时不允许有读者去读文件，同时读者读文件时不允许写者去写文件

* 使用计数器count来记录当前在读读者数量，并设置互斥量mutex来保证更新count为互斥操作
* rw保证读者写者互斥访问

```cpp
// 读者优先
int count = 0;
semaphore mutex = 1;
semaphore rw = 1;
writer() {
    while (true) {
        wait(rw);
        write();
        signal(rw);
    }
}
reader() {
    while (true) {
        wait(mutex);
        if (count == 0) wait(rw);
        count++;
        signal(mutex);
        read();
        wait(mutex);
        count--;
        if (count == 0) signal(rw);
        signal(mutex);
    }
}
// 这种情况下，读者是优先的，容易造成写者饿死现象
// 如果需要公平的话，可以再加一对PV操作
```

```cpp
// 写者优先
int countr = 0;
int countw = 0;
semaphore readLock = 1;
semaphore mutex = 1;
semaphore writeLock = 1;
semaphore resourse = 1;
writer() {
    while (true) {
        wait(writeLock);
        countw++;
        if (countw == 1) wait(readLock);
        signal(writeLock);
        
        wait(resourse);
        write();
        signal(resourse);
        
        wait(writeLock);
        countw--;
        if (countw == 0) signal(readLock);
        signal(writeLock);
    }
}
reader() {
    while (true) {
        wait(readLock);
        wait(mutex);
        if (countr == 0) wait(resourse);
        countr++;
        signal(mutex);
        signal(readLock);
        
        read();
        
        wait(mutex);
        countr--;
        if (countr == 0) signal(resourse);
        signal(mutex);
    }
}
```



```cpp
// 写者和读者都不会饥饿
int countr = 0;
semaphore resourseAccess = 1;
semaphore readCountAccess = 1;
semaphore serviceQueue;	// FIFO队列

void writer() {
    wait(serviceQueue);
    wait(resourseAccess);
    signal(serviceQueue);
    write();
    signal(resourseAccess);
    
}

void read() {
    wait(serviceQueue);
    wait(readCountAccess);
    countr++;
    if (countr == 1) wait(resourseAccess);
    signal(readCountAccess);
    wait(serviceQueue);
    
    read();
    
    wait(readCountAccess);
    countr--;
    if (countr == 0) signal(resourseAccess);
    signal(readCountAccess);
}
```







#### 哲学家进餐问题

![image-20210131225038550](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/哲学家进餐问题.png)



方法一：保证最多只允许4位哲学家同时拿起左边的筷子，这样能保证至少有1位哲学家能进餐

```cpp
semaphore chopstick[4] = {1, 1, 1, 1, 1};
semaphore mutex = 4;
void philosopher(int i) {
    while (true) {
        wait(mutex);
        wait(chopstick[i]);
        wait(chopstick[(i + 1) % 5]);
        eat();
        signal(chopstick[(i + 1) % 5]);
        signal(chopstick[i]);
        signal(mutex);
    }
}
```

方法二：使用AND型变量

```cpp
semaphore chopstick[4] = {1, 1, 1, 1, 1};
void philosopher(int i) {
    while (true) {
        Swait(chopstick[i];chopstick[(i + 1) % 5]);
        eat();
        signal(chopstick[i];chopstick[(i + 1) % 5]);
    }
}
```

方法三：规定奇数先拿左筷子再拿右筷子，偶数哲学家则相反，保证了至少有一个人能拿到两根筷子







## 线程

### 概念

引入原因

早期的计算机系统为了并发执行程序，引入了进程的概念，但是也产生了新的问题

1. 为每个进程分配资源的开销较大
2. 进程之间通信麻烦
3. 进程频繁切换会有额外的系统开销

于是人们就想到了在进程内存空间开辟多个轻量级的进程，然后利用多个轻量级进程来完成多个任务，这些轻量级进程就成为了线程，这些线程之间共享同一片地址空间，且只拥有堆栈、程序计数器等少量的资源

进程和线程的区别和联系

1. 线程不能独立存在，必须依赖于进程
2. 进程是资源管理的最小单位，线程是程序执行的最小单位
3. 数据共享和同步方面，进程的地址空间是私有的，数据共享需要使用IPC机制，同步复杂，对于线程，同一个进程内的所有线程共享同一片地址空间，同步简单
4. 资源方面，进程占用内存多，切换复杂CPU利用率低，线程占用内存少，切换简单CPU利用率高
5. 生命周期方面，进程的创建销毁慢，线程的创建和销毁快
6. 可靠性方面，进程之间不会相互影响，可靠性高，而一个线程挂掉可能会导致整个进程都会挂掉

进程、线程、协程比较

[协程库](https://blog.csdn.net/qq910894904/article/details/41911175)



#### 内存结构

![image-20210201145328709](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/线程内存结构.png)

线程间共享的资源

内核区：文件描述符表、每种信号的处理方式、当前的工作目录

用户区：堆区、数据区

线程间私有的资源

1. 线程ID：每个线程都有自己的线程ID，这个ID在本进程是唯一的
2. CPU寄存器：线程是并发执行的，每个线程都有不同的运行线索，当一个线程切换另一个线程时，必须保存原来线程寄存器集合的状态，以便线程重新运行时能恢复
3. 错误返回码：由于同一个进程有多个线程运行，某个线程进行系统调用时设置了error值，而在该线程还没有处理这个错误时，另一个线程就被调度器投入运行，这样错误码有可能会被更改，因此每个线程需要独立的错误返回码变量
4. 信号屏蔽字：由于每个线程所感兴趣的信号不同，所以线程的信号屏蔽字应该由线程自己管理
5. 调度优先级：线程要向进程那样可调度，就必须提供每个线程可供调度的参数，这个参数就是调度优先级
6. 独立的用户栈空间：每个线程有自己的参数和变量，线程间应该独立设置用户栈空间





#### 线程切换

Linux中，线程切换和进程切换最大的不同就是线程不需要切换地址空间

1. 切换内核栈
2. 切换硬件上下文



#### 用户级和内核级

进程的实现只能由操作系统来完成，而线程既可以有操作系统来完成也可由用户来实现，因此线程的实现分为了内核态线程和用户态线程

**内核态线程**

操作系统管理线程像管理进程一样，将线程控制块放在了操作系统的内核空间，那么操作系统就能控制线程

优点

1. 在多处理器系统，内核能同时调度同一进程的多个线程并行执行
2. 如果一个线程执行阻塞操作，那么操作系统可以调度其它线程占有CPU执行
3. 内核支持的线程具有很小的数据结构和堆栈，线程切换快、切换开销小

缺点

1. 对于用户的线程切换来说，切换开销大，这是因为用户的线程在用户态运行，而线程的调度和管理是在内核态实现的，切换开销大

**用户态线程**

优点

1. 线程切换不需要切换到内核空间。对于一个进程来说，其所有线程的管理数据结构均在用户空间，因此不必切换到内核空间来做线程管理，节省了切换开销
2. 调度算法可以由进程自定义。
3. 用户级线程的实现与OS无关，因为线程管理的代码属于用户程序的一部分

缺点

1. 存在系统调用阻塞问题。在基于进程机制的OS中，当一个线程执行系统调用时，进程内其他的进程都会被阻塞
2. 在单纯的用户级线程实现方式中，多线程应用不能利用多处理器来处理多线程，内核每次分配进程只有一个CPU，因此进程仅有一个线程能执行，在这个线程放弃CPU之前，进程中内的其他线程必须等待



#### 线程安全

![](https://raw.githubusercontent.com/MichaelDeSteven/CS-Note/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%26%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/pic/可重入函数与线程安全函数的集合关系.png)

线程安全函数：被多个并发执行的线程调用，一定能得到正确的结果

线程不安全函数：被多个并发执行的线程调用，可能得到错误的结果

可重入函数：属于线程安全函数的一类，又分为显式可重入和隐式可重入函数，

显式可重入函数：所有的函数参数都是值传递的，并且所有的数据的引用都是本地变量，没有全局或者静态变量

隐式可重入函数：显式可重用函数参数一部分是引用传递，并且调用线程小心地传递指向非共享数据的指针，那么它是可重入的



#### 应用场景

原则就是充分发挥CPU的性能，让IO与计算相互重叠，降低时延

* 首先要有多个CPU可用
* 线程之间有共享数据
* 共享数据是可修改的
* 多线程能有效地划分责任和任务



### 基本使用



#### 线程标识





#### 线程创建





#### 线程终止





### 线程同步

#### 互斥量





#### 条件变量





#### 读写锁





#### 自旋锁





#### 线程屏障









### 实例







# 文件管理

## 概念



## 文件的内容结构



## 文件存储空间管理





## 文件控制块FCB





## 文件与进程的关系



## 文件加载过程









# 内存管理

内存管理主要任务有

* 内存分配：为每个进程分配一定的地址空间

* 内存扩充：使用虚拟存储技术对内存进行扩充
* 内存保护：检查地址的合法性，防止越界
* 地址映射：将逻辑地址转化为物理地址



## 存储器相关

### RAM

随机存取又分为静态随机存取器SRAM和动态随机存取器DRAM



|          | SRAM           | DRAM     |
| -------- | -------------- | -------- |
| 组成     | 4or6           | 1        |
| 占用面积 | 大             | 小       |
| 功耗     | 大             | 小       |
| 是否刷新 | 无需刷新       | 需要刷新 |
| 读写速度 | 快             | 慢       |
| 造价     | 高             | 便宜     |
| 用途     | 高速缓冲存储器 | 主存储器 |







### 主存储器

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\主存储器基本框图.png)



读过程

* CPU首先将需访问单元的地址送到主存地址寄存器MAR
* 通过地址线将主存地址送到主存中的地址寄存器
* 地址译码器进行译码后选择相应的单元
* 同时CPU将读写控制信号通过控制线送入主存的读写控制电路
* 主存读出选中单元的内容通过数据线送到CPU的MAR

写操作

* CPU将需要访问单元的地址送到主存地址寄存器MAR
* 将要写的信息送到主存地址寄存器MDR
* 通过地址线将主存地址送到主存的地址寄存器
* 地址译码器进行译码后选择相应的单元
* 同时CPU将读写控制信号通过控制线送入主存的读写控制电路
* 在读写控制电路的控制下，经数据线将MDR的信息写入到选中的单元



### 磁盘

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\磁盘结构.png)



**组成**

有多个盘片，每个盘片有各自的磁头。每个盘面分成多个磁道，磁道又分多个扇区，每个扇区512字节



**读写过程**

磁盘读写操作主要经过了寻道、旋转等待、读写操作

* 寻道：磁头移动到指定磁道
* 旋转等待：磁头旋转到指定扇区
* 读写：传输一个扇区的数据



## 存储器的层次结构

### 概念

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\存储器层次结构.png)

**为什么计算机内部采用层次结构存储体系？**

1. 处理器的性能不断提高，造成了处理器与存储器之间的性能差异越来越大，为了缩小存储器与处理器两者之间在性能方面的差距因此采用层次化的存储器体系结构
2. 存储器也很难同时满足大容量、高速度、低成本的要求，因此很有必要把不同容量和不同存取速度的存储器按一定结构有机地组织在一起。



**特点**

* 速度越快则容量越小，越靠近CPU
* 数据使用时一般只在相邻两层之间复制传送
* 传送的单元是一个定长块，因此需要确定定长块的大小，并在相邻两层间建立块之间的映射



### 局部性原理

存储器层次存储体系能**高效运作**的很大原因是因为**局部性原理**，局部性原理又分为两种空间局部性和时间局部性

* 空间局部性：指存储在单元格的数据或指令在被访问后，相邻的单元格也会被访问到
* 时间局部性：指访问某个单元格的数据或指令后，在不久的将来还会再次访问这个单元格

```cpp
void test(int a[N][M]) {
    int t = 0;
    for (int i = 0; i < N; i++)
        for (int j = 0; j < M; j++)
            t += a[i][j];             // 对于变量t来说具有时间局部性，每次循环都会访问到
    								  // 对于数组a来说具有良好的空间局部性，每次会按步长为1按列访问
}
```



利用局部性原理，计算机采用了缓存，所谓缓存就是用容量小的、速度快的存储块来存放容量大的、速度慢的存储单元，这个缓存存储访问相对频繁的指令或者数据，例如学生放学回家时，只带回家用的书，书包就好比缓存块





## CPU Cache

cache要解决的问题

* cache的空间与主存空间如何进行地址映射
* 发生映射冲突的替换策略
* 替换时的一致性问题



### 工作原理

* cache就是一种小容量的高速缓冲存储器，由SRAM构成，速度与CPU几乎为一个量级，它是CPU寄存器与主存之间的缓存

* 为了方便cache和主存之间交换信息，cache和主存被划分为相等的区域，将cache划分的区域称为行，主存则称为块
* 为了说明cache行的有效性，每个cache行都有一个有效位，1表示有效



### 读取过程

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\带cache的CPU访存操作过程.png)

1. cpu给出访存地址
2. 先将地址进行映射检查cache缓冲块当中是否存在该地址块
3. 如果存在则直接将内容返回给cpu，访存结束
4. 如果不存在则从主存取出地址所在的块，利用映射关系将地址块存入cache对应的行，有效位置为1，如果需要替换则采用替换算法
5. 最后将cache对应的行返回给cpu



### 映射



**直接映射**

* 采用模运算的方式对每一个主存块进行映射，cache行号 = 主存块号 mod cache行数
* 优点是实现简单
* 缺点是若访问集中在同余的内存块那么就会引起频繁的调进调出影响效率

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\直接映射.png)



**全相联映射**

* 基本思想就是cache行只要空闲那么主存块就能装入
* 优点是不容易产生冲突
* 缺点是查找的时间开销大，实现复杂

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\全相联.png)



**组相联映射**

* 结合了直接映射和全相联映射的方式
* 对Cache分成大小相等的组，组内采用全相联映射，组之间采用直接映射

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\组相联映射.png)



### 淘汰

* 实际情况当中，会发生多个主存块映射到同一个cache行，因此需要选择淘汰某一块，这就是替换算法需要做的事
* 如果采用的是直接映射，显然每次都会发生冲突，直接替换即可，因此不用考虑替换策略问题



**FIFO算法**

* 选择最早装入cache的主存块被替换掉
* 实现方便，但是不能正确的反映程序局部性原理



**LRU算法**

* 总是选择近期最少使用的主存块替换掉
* 算法实现复杂，能之前的反映程序局部性原理
* 程序实现LRU算法的思路是采用哈希表加双链表的方式进行



**LFU算法**

* 总是选择cache中引用次数最少的替换掉





### 一致性



#### 写入操作

**写直达**

* 判断数据是否在Cache中，如果不存在则直接写入内存
* 在Cache中，就直接将数据更新到内存中



**写回**

通过修改位减少了数据写回内存的频率

* 数据写入Cache时，如果缓存命中，则只写入Cache，并标记已修改
* 缓存不命中，且修改位已被标记则写入内存



#### 多CPU一致性



实现多CPU缓存一致性两个条件

* 写传播：某个CPU更新Cache数据时，会通知其它CPU
* 事务串行化：执行相同顺序的命令



**总线嗅探**

* 写传播通过总线以广播形式通知其它CPU
* 占用总线效率低
* 不支持事务串行化



**MESI协议**

* M（Modified）：代表该缓存行中的内容被修改，且该缓存行只被缓存在该CPU中
* E（Exclusive）：该缓存行对应的内存区域只被该CPU缓存
* S（Shared）：缓存对应的内存区域在多个CPU被缓存
* I（Invaild）：表示该缓存行的内容无效





MESI协议中，每个缓存行不仅知道自己的读写操作，同时也监听其它缓存行的读写操作，根据自己的缓存行和其它CPU缓存行的读写操作进行状态转移

它的监听机制也叫做**总线嗅探机制**，它的本质就是总线将信号广播到所有的处理器，每个处理器通过监听总线上传播的数据来检查自己的缓存是否过期，如果处理器发现自己的缓存行对应的内存地址修改，就会将当前处理器的缓存行设置为无效





## 程序的装入和链接

用户程序要在系统中允许，必须先把它装入内存，如何变成一个可执行的程序

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\程序处理步骤.png)

整个过程即编译—链接—装入—运行

### 程序的链接

* 链接程序的目的是将程序以及所需的库函数装配成一个完成的装入模块，根据链接时间不同，可把链接分成3类

* 静态链接：在编译时就实现进行链接，之后不再拆分的链接方式

* 装入时动态链接：装入内存时，边装入边链接的链接方式。

* 运行时动态链接：对某些模块的装入推迟到程序运行时再确定是否装入。加快了程序装入时间，节省了内存空间



### 程序的装入

* 绝对装入方式：用于单道程序运行，装入的程序逻辑地址等于物理地址，一旦程序或数据被修改时，可能要改变程序中的所有地址
* 可重定位装入方式：程序在装入时程序的起始地址不与内存地址相同且装入程序之后不再改变逻辑地址不再改变
* 动态运行装入方式：实际情况中进程会切换，因此程序运行的位置可能会发生变化，这个时候原来的逻辑地址会失效，因此推迟装入程序的逻辑地址转化为物理地址



## 连续分配

### 单一连续分配

* 仅仅用于单任务、单用户的系统，内存分为了系统区和用户区，用户仅装入一道程序，整个用户区将被独占
* 不利于进程的并发

### 固定分区分配

是一种最早的也是最简单的可运行多道程序的存储管理方式，为了能够在内存装入多道程序，且使这些程序不会相互干扰，将内存划分为若干个固定的内存区域，每一个内存区域只装入一道作业，当有空闲的分区时，从后备队列中选择大小适当的程序装入该分区

对于内存的用户空间的划分，有如下两种划分

* 分区大小相等：适用于多个大小固定且刚刚好的控制系统。
* 分区大小不相等：对于大小不一的程序来说更加灵活。

为了方便内存分配，通常将分区按其大小进行排队，并为之建立一张分区使用表，这张表包含了起始地址、大小、状态，当一个程序需要装入内存时，系统会查找分区使用表是否有合适的分区，如果有则为程序分配分区



### 动态分区分配

**数据结构**

1. 空闲分区表：每个分区占一个表目，包括了表目序号，起始地址，分区大小，状态
2. 空闲分区链：每个分区起始部分设置分区分配信息还有指向前面的分区指针，分区尾部则设置一后向指针，通过前后链接成一个双链表

**分配和回收操作**

分配操作

1. 按照某种分配算法从空闲表（链）查找所需的大小的分区，设请求分区大小为u，空闲分区大小为m
2. 若m小于u则继续查找，直到找到m大于u，如果没有则分配失败
3. 找到了m大于u，判断m-u是否小于等于size
4. 小于等于认为是合适的空闲分区，将其分配，并修改有关数据结构，分配成功
5. 大于则空闲分区过大，需要划分u大小分区给请求者，剩余的部分仍然留在空闲表（链）中

回收操作

1. 进程释放内存时，系统根据回收区的首地址找到相应的插入点
2. 若回收区与插入点的前一空间分区相邻，则与前一分区合并
3. 若回收区与插入点的后一空间分区相邻，则与后一分区合并
4. 回收区与插入点前后两个分区相邻，则将这三个分区进行合并
5. 如与前后分区均不相邻则自建一个新表项



**分区分配算法**

基于顺序搜索的动态分区分配查找

1. 首次适应算法FF：从链首开始查找一个满足大小的空闲分区，按作业的大小划分，剩下的空间则留在空闲链中，若从链首到链尾都不能找到满足要求的一个分区，则失败返回，优点是实现简单，缺点是内存的利用率低
2. 循环首次适应算法NF：与FF算法不同的是NF从上一次找到的下一个分区开始查找，直到找到一个满足大小的分区，NF能使空闲分区变得均匀，但是缺乏了大的分区
3. 最佳适应算法BF：将所有空闲分区按容量以从小到大顺序形成一空闲分区链，第一次找到的空闲区必然为最佳的，这种方式在每次分配的时候，留下来的剩余空间小，造成了许多难以利用的内存碎片
4. 最坏适应算法WF：与BF相反，每次从容量大的开始查找，这样留下的剩余空间不至于太小，产生碎片的可能性小

基于索引搜索的动态分区分配查找

1. 快速适应算法：也叫做分类搜索法，基本思路就是将各个大小不同的空闲分区进行分类，每一类单独设置空闲分区链表，同时内存设立索引表，每个索引项对应一个空闲分区链表，查找空闲分区时，可以根据分区的大小确定索引的下标，然后从链表中分配空闲分区并且不对分区产生任何分割，相对于按顺序搜索而言时间效率高，但是分区归还主存时算法复杂，系统开销大



**伙伴算法**

* 已分配分区或者空闲分区其大小均为2的次方，将具有相同的空闲分区单独设立一个空闲分区双链表
* 当需要为进程分配大小为n的存储空间，首先计算i值使得$2^{i-1} < n <= 2^i$，然后在空闲分区大小为$2^i$上的空闲分区链查找，若找到则分配，找不到则在$2^{i + 1}$分区中查找，如果有则将$2^{i + 1}$分成两份，一个分区用于分配，另一个分区加入大小为$2^i$的空闲分区链表中，最坏情况下需要寻找k次进行k次分割才能得到所需分区
* 回收时也需要经过多次合并，如回收大小为$2^{i}$的分区，若存在$2^i$的空闲分区，则将其合并，若存在$2^{i+1}$分区，则再次合并，以此类推



**slab缓存器**

* 内部碎片：类似分页机制的存储管理方式，只分配固定大小的分区，可能会产生某分区存在多余的空间
* 外部碎片：频繁的分配和回收导致了大量的、连续且小的页面块夹在了已分配的页面中间

slab的基本原理用到了对象的概念，对象就是内核中的数据结构以及对这些数据结构进行创建和撤销的操作。它的基本思想就是把经常使用的对象放到高速缓存中，并由系统保持初始的可利用的状态，比如进程描述符，内核频繁对其进行申请和释放，当内核申请新的进程时，内核直接从slab分配器获取一个已经初始化的对象，进程结束时，该结构不直接销毁而是重新返回slab分配器中，节省了内核花费时间去进行分配、初始化、销毁的时间

slab的使用前提首先是系统频繁分配和释放资源，其次就是申请内存大小是固定的

slab目标

* 搭配伙伴算法使用，减少了伙伴算法分配小块内存所产生的内部碎片
* 将频繁使用的对象缓存起来，减少分配、初始化、销毁花费的时间









### 对换

* 对换就是将内存中暂时不能运行的进程或者暂时不用的程序和数据换出外存，以便腾出足够的内存空间，再把已具备运行条件的进程或者进程所需的程序和数据换入内存。

* 如果发生了频繁发生对换，那么说明了内存不足



### 动态重定位分区分配

在连续分配中，由于程序都是连续放入内存当中，很可能会造成了许多难以利用的碎片，即使这个碎片的总和大于要装入的程序，由于这些分区不相邻，无法把该程序装入内存，因此可以采用以下方法解决



**拼凑**

通过将所有内存中的作业移动到一段，使得所有碎片形成了一个大的空闲区，由于拼凑使得程序和数据的地址发生了改变，需要对每个程序的起始地址进行重定位



**实现**

* 作业装入内存的所有地址都为相对地址，将相对地址转化为物理地址推迟到程序指令真正要执行再进行

* 为了使得地址的转换不会影响指令的执行速度，采用硬件机制来实现，即设置一个重定位寄存器，用来存放程序在内存的起始地址，程序在执行时，真正要访问的地址是相对地址加上寄存器的地址
* 进行拼凑操作后，无需对程序进行修改，只需用该程序在内存的新起始地址来替换原来的起始地址即可



### 总结

存储管理方式是随着OS的发展不断发展的，当OS由单道程序向多道程序发展，存储管理方式从单一连续分配发展为固定分区分配，为了更好的适应不同大小的用户程序，存储管理方式又从固定分区分配发展为动态分区分配，为了减少内存碎片、更好地提高内存的利用率，存储管理方式从动态分区分配方式发展成为了动态重定位分区分配方式

发展是向前的。连续分配方式有可取之处，但是减少内存碎片是由拼凑这种消耗系统性能为代价的，OS的存储管理方式也因此由连续分配方式发展到了离散分配方式





## 离散分配

### 介绍

离散分配是指将程序分散转到多个不相邻的分区，这种分配方式的单位有”页“和”段“，分成了分页存储管理、分段存储管理、段页式存储管理



### 虚拟存储器

#### 概述

连续存储管理具有两个特点

* 一次性：是指作业必须一次性全部装入内存后才能运行，这一特性直接限制了大作业在小内存的运行，无法进一步提高系统的多道程序度，进而影响处理器的运行效率以及系统的吞吐量。而且作业运行时，并不需要用到全部的指令和数据，显然是对内存空间的浪费
* 驻留性：是指程序一旦装入内存当中，就会一直驻留在内存当中，即使是运行的进程因IO阻塞，直到运行结束后才释放内存，这种情况也是对内存的浪费

针对上述两个问题分别由其解决办法

* 首先程序具有局部性原理，因此在程序运行之前，没有必要全部装入内存，仅把要运行的页或段装入内存即可，运行时如果访问的页为在内存中，再利用OS的请求调页功能，将页调入内存，这个方案解决了一次性问题
* 针对驻留性，如果内存满了，可以利用页面置换功能，将内存中暂时不用的页调至磁盘，于是就有了空闲页



直接面向物理内存所带来的问题

* 进程与进程的内存空间不具备隔离性，使得运行多道程序变得困难
* 用户程序受到物理内存的限制
* 物理内存容易遭到破坏



#### 定义

* 虚拟内存是指用户会感觉内存的容量比实际内存容量大得多，实际上这是一种错觉
* 虚拟内存为进程提供了大的、一致的、私有的地址空间，它将物理内存看作是磁盘的高速缓存，主存只保存活动区域

#### 特性

* 需要说明的是，虚拟存储器的实现一定是在基于离散分配存储管理方式，因为连续存储管理方式就要求了作业必须装入一个连续的内存区域，而且需要申请注意容纳该作业的内存空间，显然这与虚拟内存的定义相违背，也就不符合虚拟存储器的性质
* 多次性：允许程序和数据分成多次调入内存，即只需将当前要运行的那部分程序和数据装入内存即可运行，以后要运行尚未调入的那部分程序，再将它调入。
* 对换性：允许将暂时不用的作业从内存调至外存，待以后需要再将它们从外存调入内存
* 虚拟性：从逻辑上扩充了内存容量，使得用户所看到的内存容量比实际内存大



**为什么使用虚拟存储器**

* 安全
* 更容易运行多道程序
* 用户程序不受物理内存限制



虚拟存储器的大小一般取决于CPU字长，如32位的字长，进程的地址空间就可达4G



#### 实现方式

**请求分页系统**

* 在分页系统的基础上，增加请求调页功能、页面置换功能所形成的页式虚拟存储系统
* 它允许只装入若干页的用户程序和数据，便可启动运行

硬件支持

* 请求分页的页表机制
* 缺页中断机构
* 地址变换机构



**请求分段系统**

* 在分段系统的基础上，增加请求调段功能以及分段置换功能所形成的段式虚拟存储系统
* 它允许只装入若干段的用户程序和数据，便可启动运行

硬件支持

* 请求分段的段表机制
* 缺段中断机制
* 地址变换机制





### 基本分页存储管理方式

#### 介绍

* 将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页，并为各页编号
* 把内存空间分成与页面相同大小的若干个存储块，称为块或页框
* 以块为单元的物理块可以装入进程中的若干个页，这些物理块不一定要相邻



#### 页表数据结构

为了能够找到程序地址相应的物理块，因此为进程建立页表，这个页表实现了从页号到物理块的地址映射

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\页表项数据结构.png)

* 页号：对应进程逻辑地址空间的某一页
* 物理块号：对应物理内存的某一块
* 状态位：表示该页是否已调入内存
* 访问字段：记录本页被访问的次数，供置换算法选择调出页参考
* 修改位字段：标识该页调入内存后是否被修改了，如果未被修改则不必将该页写回外存，减少系统的开销和读写磁盘次数
* 外存地址：用于指出该页在外存的地址



#### 工作过程

快表：为了减少访存的开销，将页表的活跃页表项复制到高速缓冲中



![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\请求分页地址变换过程.png)



#### **缺页异常**

缺页异常与缺页中断

* 缺页中断是指访问的页面不在内存中，是缺页异常情况之一
* 缺页异常也有可能是地址不在虚拟地址空间，或者是没有访问权限



**缺页中断过程**

* 检查虚拟地址是否合法
* 查找并分配一个物理页（物理内存满了则需要相应的置换算法）
* 填充物理页（如果是读则初始化物理页，如果是写则从磁盘加载相应的页）
* 建立虚拟页与物理页的映射关系
* 重新执行发生缺页中断的指令





**CPU访存过程（包含了cache、快表）**

* CPU将地址AD（逻辑地址）送给快表，检查对应页表项是否在TLB中
* 如果页号大于页表长度，说明不合法，产生越界中断
* 如果在快表中，则将VA转为物理地址PA，然后在cache中检查是否存在对应主存块
* 如果存在地址块，则CPU将cache的信息送入CPU，如果不存在则cache缺失
* 检查cache是否有空闲行，如果有空闲行直接将主存块送入cache
* 没有空闲行否则使用cache替换算法从cache当中替换一块
* CPU将需访问的物理地址送到主存地址寄存器MAR
* 通过地址线将主存地址送到主存中的地址寄存器
* 地址译码器进行译码后选择相应的单元
* 同时CPU将读写控制信号通过控制线送入主存的读写控制电路
* 取到主存的某一块数据后，将数据保存在cache缓存当中
* 对应的页表项不在TLB，会产生TLB缺失，访问内存中的页表
* 如果访问页面存在于内存，则修改该页表项的访问位，如果是写操作还需要修改修改位，然后更新TLB将VA转换为物理地址PA，最后再去cache查找对应主存块
* 访问页不在内存中则产生缺页中断，从外存中找到缺页
* 如果页表满了，则需要使用相应的页表置换算法，对页表进行替换
* 被替换的页表若修改位为1则需要将其写入外存当中，否则直接覆盖
* 然后操作系统启动IO读写，将外存的缺页换入内存
* 修改快表的信息，然后形成物理地址，CPU取访问主存，并将该物理块存入cache中



#### 页面置换算法

进行地址映射时，如果所在页不在内存会产生缺页中断，如果操作系统没有足够的空闲页表，需要在内存中选择并淘汰一个页面，这个选择的过程就是页面置换算法



**最佳置换算法**：选择最长时间不被访问或者永远不用的页进行淘汰，这种算法是性能最好的算法，但是并无法实现，因为很难预知进程中哪一页最长时间不被访问

**FIFO算法**：淘汰先进入内存的页表，即替换掉进入内存最久的页表

**LRU算法**：最近最少使用算法，即淘汰掉最近时间内最少被使用的页表，这个算法考虑了程序访问的局部性原理，性能较好，但是需要较多的硬件支持，会增加硬件的成本

**CLOCK算法**：CLOCK算法是LRU的进似算法，又分为了简单版本和改进版本

* 简单的CLOCK算法：每个页设置访问位，再将内存中的所有页面通过指针连接成一个循环队列，当某一页被访问时被置为1，置换算法在页淘汰时，如果访问位为0则将该页换出，如果为1则置为0，按照FIFO算法进行循环检查

* 改进的CLOCK算法：考虑到页修改写回外存的情况，未被修改的页置换时并不需要写回外存，而修改的页则必须写入外存这样的性能开销会变大，因此该算法除了考虑访问位A之外还考虑了修改位M，算法步骤是，从指针指示的当前位置开始，扫描循环队列，优先寻找（A=0，M=0）的页面，将其作为淘汰页，同时第一次扫描时并不改变A，如果第一轮为找到理想淘汰页，则开始第二轮寻找（A=0，M=1）的页面，将其作为淘汰页，并将所有扫描的页面A置为0，如果第二轮失败则重复第一轮的步骤，如果仍失败，再重复第二轮的步骤，四个步骤之后，就一定能够找到淘汰页，该算法减少了磁盘IO的次数



#### 抖动

工作集：进程在某一时间间隔内需要访问的内存集合

**抖动**

页面置换时，刚把某一页面淘汰并替换新的页面时，下次仍然请求页面仍然缺页，导致了页面频繁更换现象

**抖动原因**

内存中运行的进程多，但是每个进程分配的物理块少，致使每个进程在运行中频繁缺页，必须请求系统将所缺少的页调入内存中

**解决办法**

1. 采用局部置换策略：某进程发生缺页时，仅在分配给自己的内存空间进行置换，避免了影响其它进程
2. 将工作集算法融入处理器调度：将作业从外存中调入内存，需要事先检查每个进程在内存的驻留页面是否足够多，如果足够多，则将从外存中调入作业，反之，如果某些进程的内存空间不够，导致缺页率较高，则不再调入新的作业
3. 暂停进程：暂停优先级低的进程，释放物理块给缺页率偏高的进程





### 基本分段存储管理方式

#### 介绍

在分段存储管理方式中，作业被划分为若干个段，每个段都是一组逻辑信息，从0开始编制拥有连续的地址空间，短的信息由逻辑信息组的长度决定，因而段长不等

* 段的逻辑地址被划分为了段号和段内地址
* 系统为每个进程建立段表，用于实现物理段到物理内存的映射

**优点**

* 方便编程：用户可以把作业按照逻辑关系划分为若干个段，拥有各自的名字和长度
* 信息共享：段是信息的逻辑单元，也就是说一条指令和或一条信息不可能被分割成两个段，因此段可以实现信息的共享
* 信息保护：信息保护是对信息逻辑单元的保护
* 动态增长：在实际运用中，某些数据段会在使用过程中不断增长，而分段存储管理方式很好地应付了这种动态增长的情况
* 动态链接：动态链接是指作业运行之前，并不把几个目标程序段链接起来，运行时如果需要某段，才将某段调度到内存中并进行链接，显然动态链接要求了以段作为管理的单元

**缺点**

* 容易造成外部碎片问题（段与段之间有无法被利用的空间）
* 内存交换效率低





#### 分段与分页的区别

* 页是信息的物理单元，分页是为了满足系统管理需求，而段是信息的逻辑单元，分段是为了满足用户的需求
* 页的大小固定且由系统决定，段的大小不固定且由用户编写的程序决定
* 分页的作业地址空间是一维的，即使用页号就能够表示某个页，分段的作业地址空间是二维的，即需要给出段号还要给出段内地址





### 段页存储管理方式

#### 介绍

段页存储管理方式即吸收了便于实现、信息共享、信息保护、动态增长、动态链接等分段存储管理方式，又能像分页存储管理方式那样解决内存的外部碎片问题



#### 实现原理

* 先将用户分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名
* 段页式的地址结构即为段名、段内页号、页内地址
* 需要访问3次内存，第一次是访问段表获取页表地址，第二次是访问内存的页表获取页内的物理地址，第三次才是真正从访问所得的地址取出指令或数据



## 内存分配

### malloc\free

**内存分配原理**

分配的是虚拟页，如果真正读写页时才会触发缺页中断

* 使用系统调用函数brk，从低地址向高地址偏移分配执行分配大小
  * 需要等待高地址内存释放后低地址才能释放，可能会造成内存碎片
* 使用系统调用mmap，在堆和栈找到一块空闲内存分配





## 内存映射



### mmap

```cpp
void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);
```



**作用**

* 用于内存映射文件的函数，实现了进程的地址空间和文件磁盘地址的映射关系，进程可以采用指针方式读写这段内存，可以用来实现不同进程的文件共享

[mmap函数](https://blog.csdn.net/qq_33611327/article/details/81738195)



### jemalloc

















# 操作系统接口



## 系统调用

### 系统态和用户态

计算机系统中，通常运行两类程序：系统程序和应用程序，为了防止应用程序对操作系统的破坏，应用程序和OS的内核是运行在不同的状态，内核运行在系统态，而应用程序运行在用户态



处理器会在两个状态间相互切换，同时现代多数OS也将CPU分成了特权指令和非特权指令两类

* 特权指令是指在系统态运行的指令，它对内存空间的访问范围基本不受限制，同时能够启动外部设备、设置系统时钟时间、关中断、转换执行状态等，特权指令只允许OS使用，不允许用户进程使用，避免引起系统混乱
  * 对内存空间的访问范围不受限制
  * 能够直接访问系统的硬件和软件
* 非特权指令是在用户态运行的指令。应用程序使用的是非特权指令·，不能对系统中的硬件和软件直接访问，对内存访问范围也只局限于用户空间，这样，可以防止应用程序运行异常对系统造成破坏
  * 对内存空间访问受限
  * 不能够直接访问系统的硬件和软件，要使用系统调用函数





### 系统调用

#### **概念**

系统调用就是应用程序请求内核完成某功能时的一种过程调用，它是一种特殊的过程调用，首先它运行在系统态，而一般的过程调用都是在用户态完成的，运行系统调用时，由于调用和被调用过程是工作在不同的系统状态的，所以需要先由用户态转换为系统态，待内核执行完毕后，才从系统态切回用户态





#### 分类



**进程控制类**

* 创建和终止进程
* 获取或者设置进程信息
* 获取和设置进程属性
* 等待某事件出现
* 分配或者释放内存

典型的有fork、exit、wait



**文件操纵类**

* 创建和删除文件
* 获取或者设置文件信息
* 打开和关闭文件
* 读和写文件

典型的有open、write、read、close



**设备管理类**

* 申请或者释放设备
* 获取或者设置设备信息
* 读、写、重定向

ioctl、write、read



**信息维护类**

* 获取或者设置日期和时间
* 获取或者设置系统信息
* 获取或者设置进程、文件、设备属性

getpid、alarm、sleep



**进程通信类**

* 创建共享存储区
* 打开关闭连接
* 发送接收消息

pipe、mmap





#### 系统调用的实现

系统调用通过中断机制实现的，操作系统的是所有系统调用都是通过一个中断入口来实现，Linux给应用程序授权了4个终端号：3，4，5以及80h，前面三个终端号是提供给应用程序调试所使用的，而80h正是系统调用的中断号







### Unix的系统调用

* 创建（fork）和终止（exit）进程
* 执行一个程序（exec）和等待子进程结束（wait）
* 创建文件（create）
* 打开（open）和关闭（close）文件
* 读（read）和写（write）文件
* 消息机制：创建消息队列（mesget），发送消息（mgssend），接收消息（mgsrcv）
* 共享存储器机制：创建共享存储器（shmget），共享存储器连接到虚地址空间（shmat），拆除连接（shmdt）



**Linux的系统调用工作流程**

* 取系统调用号，检验合法性
* 执行int80h产生中断
* 进行地址空间转换，以及堆栈的切换，进入内核态
* 进行中断处理，根据系统调用号来定位内核函数地址
* 根据通用寄存器内容，从用户栈中取出入口参数
* 核心函数执行，最后把结果返回给应用程序





## 中断机制

### 概念

* 中断提供了一种异步的事件处理机制，用于提高处理器的并发度。
* 中断是指CPU正常运行期间，由于内外部事件或程序预先安排的事件引起的CPU暂停正在运行的程序，转而为该内外部事件或者预先安排事件服务的程序中去，待服务执行完毕后再返回去继续运行被中断的程序，Linux把中断分为了外部中断（由CPU外部产生的）和内部中断（CPU内部产生的）



### 中断与异常

异常一般指的是程序非法操作导致的异常，如除0错误、缺页中断等。而中断一般指硬件设备通过特定的中断请求信号线向CPU提出中断申请。如在获取完磁盘块后磁盘会生成中断来通知到操作系统可以准备读取数据。



### 过程

* 保护断点和程序状态：为了保证中断处理完成后能够继续执行程序，需要保存现场，即把下一条要执行的指令，以及当前程序的数据和指令保存到寄存器当中
* 关中断：在执行异常或者中断处理程序时又出现了新的中断，开/关中断机制就是用来开启/禁止处理中断时再去响应新的中断，一般通过中断允许位来实现，中断允许位为1则为开中断，0表示关中断
* 识别中断事件并转向相应的处理程序执行：识别中断事件后才能确定指定中断处理程序的入口，识别机制可以由硬件或者软件实现，硬件识别机制又称为向量中断方式，将中断处理程序的首地址称为中断向量，所有中断向量保存在一个表，称为中断向量表，通过查询的方式来找到指定的中断处理程序





### 原理机制

中断处理请求应该要尽可能短和快，这样才能减少对正常执行程序运行调度影响，而且中断处理程序可能会关中断，如果执行时间过长，可能就会丢失当前其他设备的中断请求，因此Linux将中断处理分成了两个部分：上半部和下半部

上半部完成尽可能少的比较紧急的功能，他往往只是简单地读取寄存器中的中断状态并清除中断标记然后将稍后完成地工作推迟给下半部去完成，这意味着下半部为工作重心，完成了中断事件绝大部分的任务

* 下半部可以被新的中断事件打断，而上半部一般被设置为关中断
* 下半部完成的任务相对来说并不是非常紧急，而且相对比较耗时
* 如果中断要处理的工作很少，那么所有工作就交由上半部来完成



#### 上半部机制

* 由硬件请求，也称为硬中断。用于处理耗时短的任务



#### 下半部机制

* 由内核触发，主要完成上半部未完成的任务，通常为耗时的任务，可以被打断

linux实现下半部机制主要有三种：软中断、工作队列、Tasklet





**软中断**

软中断不能睡眠，不能阻塞，不能进程切换，不能被自己打断只能被硬件中断打断，可以并发运行在多个CPU上



**Tasklet**

tasklet是通过软中断实现的，软中断通过轮询的方式处理，才能最终执行对应的处理函数，为了提高处理效率，于是产生了tasklet，tasklet采用无差别队列，有中断才去执行，免去了循环查表



**工作队列**

由于软中断不能睡眠、阻塞、进程切换，所以如果软中断一旦睡眠或者阻塞，内核就会僵死，为了能够让任务睡眠，能够在不同的进程间切换，以完成不同的工作，出现了工作队列，工作队列本质就有一组内核线程，作为终端守护线程来使用，多个终端可以放在一个线程中，也可以每个中断分配一个线程，使用结构体workqueue_struct表示工作者线程，链表由work_struct结构体组成，这个结构体描述了一个工作，一旦工作被执行完毕，相应的work_struct就会从链表上移去





# 设备管理



## IO系统

### IO控制

DMA控制器： 由若干个寄存器组成，用来控制数据在主存和外设之间直接传送的接口的硬件

直接内存访问(DMA) ：开始时，DMA发送“启动DMA传送”，发送完命令后，CPU转去执行其他任务，而请求I/O的用户进程会进入阻塞状态，DMA控制器控制外设和主存进行数据交换，完成I/O操作后，发起“DMA完成”请求中断信号，CPU检测到信号后就暂停当前执行的任务，转去执行请求I/O的用户进程

程序控制I/O：直接通过查询程序来控制主机和外设的数据交换

中断控制I/O：需要I/O操作时，CPU发起控制命令启动I/O后，转去执行其他工作，当外设完成I/O操作时，发起一个中断请求，CPU检测到这个信号时，就暂停进程，转入中断服务程序，进行数据交换





1. 什么是程序直接控制I/O方式？说明其工作原理。

   A：I/O设备将自己的状态放入状态寄存器，CPU通过不断地查询状态寄存器中的外设的状态，来控制主机与外设数据的交换，直到I/O设备准备就绪，才执行读写

   优点：简单、易控制、外围接口控制少

   不足：效率低，速度慢，查询开销大

2. 什么是中断控制I/O方式？ 说明其工作原理。

   A：需要IO操作时，会启动外设进行IO，然后CPU转去执行其他的工作，执行IO的进程进入阻塞状态，当外设就绪时，向CPU发送中断请求，CPU响应中断请求，调用中断服务系统，执行数据传送，然后返回被打断的进行继续执行

   缺点：一次数据交换CPU为了响应和执行中断服务程序需要执行许多额外的操作：包括保存断点、保存现场、设置中断屏蔽字等，对于像磁盘的高速外设IO，如果采用这种方式，那么会由于外设数据传输速度快，导致CPU响应和处理中断的额外开销变大

   

3. 什么是DMA控制I/O方式？ 说明其工作原理。

   A：开始时，DMA发送“启动DMA传送”，发送完命令后，CPU转去执行其他任务，而请求I/O的用户进程会进入阻塞状态，DMA控制器控制外设和主存进行数据交换，完成所有I/O操作后，发起“DMA完成”请求中断信号，CPU检测到信号后就暂停当前执行的任务，转去执行请求I/O的用户进程

   应用场合：高速设备、数据间间隔时间短的成批数据交换



### IO模型

一般而言IO请求分两步完成

* 等待数据准备好，经典案例就是Socket等待数据从网络中到达，当所有数据都到达，将会被复制到缓冲区
* 从内核向进程复制数据，将内核缓冲区的数据拷贝到进程的缓冲区



#### 五大IO模型

**阻塞IO**

* 从等待数据到达到可以准备对数据读写这一过程中都处于阻塞称为阻塞IO
* 阻塞过程其它进程都可以运行，不占用CPU资源，因此CPU的利用率高

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\BIO.png)







**非阻塞IO**

* 相对于BIO，NIO在执行系统调用时会返回错误码，使得程序可以继续运行，在数据传输到内核缓冲区时，进程会不断进行系统调用查询数据是否都准备好，如果没有传输完毕则返回错误，否则说明所有数据已经到达内核缓冲区，然后就可以将内核缓冲区的数据拷贝到进程缓冲区当中
* 相比于阻塞IO，非阻塞IO更耗费CPU资源

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\NIO.png)



**IO复用**

* 也叫做事件驱动IO，用户调用select的进程将会阻塞，然后内核会检查每一个select所负责的socket，如果某一个socket数据准备好了，那么select就会返回，此时进程就能够进行内核缓冲区到进程缓冲区的数据拷贝
* 相比于阻塞IO，IO复用劣势是多了一次系统调用，但是IO复用能够等待多个描述符就绪，因此可以让单个进程具有处理多个IO事件的能力

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\IO复用.png)



**信号驱动IO**

* 利用了信号机制，让内核在描述符就绪时发送SIGIO信号通知我们，应用进程可以利用sigaction系统调用安装一个信号处理函数，然后系统调用返回，程序能够继续执行，当数据准备好了时候，会发出SIGIO信号，然后调用信号处理函数，可以在函数里面对准备好的数据进行操作
* 这种IO模型优势在于在数据报到达之前不被阻塞，可以继续执行



![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\SIGIO.png)



**异步IO**

* 系统调用AIO操作然后立即返回，进程不会被阻塞，相比于信号驱动IO来说，信号驱动IO告诉了用户可以准备IO，异步IO则是告诉了用户IO已经完成了



![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\AIO.png)





#### 比较

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\IO.png)



![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\synchronous&asynchronous.png)

* **关于同步、非同步、阻塞、非阻塞，在不同的层面下讨论是不同的，这里主要指的是networkIO**
* 同步IO：阻塞IO、非阻塞IO、IO复用、信号驱动IO，它们是第一阶段不同
* 异步IO：AIO模型，第二阶段IO操作完会通知进程（不导致请求IO进程阻塞）
* 阻塞IO：阻塞IO和IO复用第会因为发起IO操作时等待而被阻塞
* 非阻塞IO：非阻塞IO、信号驱动IO、AIO



### IO复用



#### select

**API**

```c++
int select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, 
           const struct timeval *timeout);
sruct timeval {
    long tv_sec;  // 秒
    long tv_usec; // 微秒
}

在select的第二到第四个参数是fd_set*类型
fd_set是一种位数组类型,也就是说数组中的数组元素值只能是0或1
readfd表示要进行监管的读操作的套接字的数组
writefds表示要进行监管的写操作套接字的数组
exceptfds表示要进行监管的异常事件套接字的数组
    
maxfdpl值为最大描述符+1，因为maxfdl表示描述符的个数，而描述符是从0开始的

timeval为阻塞时间，阻塞有3种情况
1. 设置为NULL，表示永远阻塞
2. 设置timeval，等待固定时间
3. 设置timeval=0，检查描述符后立刻返回
    
    
返回值有3种情况
1. 失败返回-1（监听集合传入无效文件描述符，select在工作中被信号中断，maxfdpl不合法）
2. 超时
3. 只要有一个套接字就绪了，select就会返回准备就绪的描述符个数并停止阻塞
    
    
宏
FD_SET(int fd, fd_set *set)，将文件描述符加入到fd_set的位数组
FD_ZERO(fd_set *set)，将所有位置为0用于初始化
FD_CLR(int fd, fd_set *set)，把fd在set对应的位置置为0
FD_ISSET(int fd, fd_set *set)，判断fd是否在set位数组中为1（代表准备就绪）
```



**例子**

```java
#include <stdio.h>
#include <stdlib.h>
#include <sys/time.h>
#include <sys/types.h>
#include <unistd.h>
#include<strings.h>
#include<sys/socket.h>
#include<iostream>
#include<arpa/inet.h>
using namespace std;

int main(void) {
    
    /**step1 :  select工作之前,需要知道要监管哪些套接字**/
   int listen_fd=0;
   
    fd_set  read_set;   
    FD_ZERO(&read_set);
    FD_SET(listen_fd,&read_set);
    

    /*step2 : select开始工作,设定时间内阻塞轮询套接字是否就绪*/
    struct timeval tv;
       tv.tv_sec = 5;
        tv.tv_usec = 0;
    int ret=select(listen_fd+1,&read_set,NULL,NULL,&tv);

    /*step3 : select完成工作,即如果出现就绪或者超时 ,则返回*/
    if(ret==-1){
        cout<<"errno!"<<endl;
    }
    else if(ret==0){
        cout<<"time out"<<endl;
    }
    else if(ret>0){
        if(FD_ISSET(listen_fd,&read_set));
        {  
            char *buffer=new char[10];
            read(listen_fd,buffer,sizeof(buffer));
            cout<<"Input String : "<<buffer<<endl;
        }
    }

}
```





**源码分析**

![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\select.png)



select充当了一个监管员的身份，它负责接收IO请求，select有5个参数，最大文件描述符数，读、写、异常监听数组、等待时间，返回值分别有-1，0，大于0，分别代表出错、当前无IO请求和有IO请求，select工作之前需要设置监听哪些文件描述符，使用的数据结构是FDSET位数组，使用相应的宏操作来完成初始化和设置监听文件描述符，设置相应的超时时间，如果在时间段内有相应的事件发生，那么select会返回

select的底层实现首先是系统调用了sys_select，而select大部分工作都是在copy_sys_select完成的，这个函数主要是先在内核空间开辟内存，然后创建监听位数组并初始化，然后将用户态的监听数组拷贝到内核区，再调用do_select进入阻塞，满足条件时返回，最后将结果拷贝会应用层，do_select函数会遍历所有监听的描述符，并分别为每一个文件描述符申请一个等待队列元素然后将其添加到对应驱动程序的等待队列中，然后睡眠等待，条件满足时，驱动会通过等待队列通知并唤醒调用select进程，同时返回一个掩码，这个掩码表示事件的类型

select的文件描述符受FD_SETSIZE限制一般为1024

通知事件给进程时，需要将整个监听位数组拷贝到用户态

有事件发生时需要遍历监听位数组才能知道是哪个文件描述符可读或者可写

几乎支持所有平台，适用于处理监听事件数较少的IO复用







#### poll

与select类似

**API**

```cpp
int poll(struct pollfd *fds, unsigned int nfds, int timeout);

与select监听采用的fd_set位数组不同，poll采用了pollfd事件结构体数组，然后在结构体数组设置需要监听的文件描述符，以及要监听的事件等信息
struct pollfd {
   int   fd;         /* 文件描述符 */
   short events;     /* 注册的事件 */
   short revents;    /* 实际发生的事件，由内核填充 */
};

event表示要监听的事件类型，比如POLLIN表示数据可读（包括了普通数据和优先数据），POLLOUT表示数据可写（包括普通数据和优先数据）
revents表示实际发生的事件，由内核设置
    
nfds表示fds结构体数组大小
timeout：表示poll超时的时间，单位为毫秒
    
函数返回值
返回值小于0表示出错
返回值等于0表示poll函数等待超时
返回值大于0表示就绪文件描述符的个数
```



poll函数与select类似，但是poll采用了基于链表结构的监听列表，结点为pollfd，包含了文件描述，注册的事件和实际发生的事件，它的优点是监听的文件描述符没有最大个数限制，缺点同select一样





#### epoll



```cpp
#include <sys/epoll.h>
#include <stdlib.h>
#include <error.h>
#include<iostream>
#include <unistd.h>
using namespace std;
int main(){
    //step1: epoll开始工作之前 先把文件描述符纳入epoll监管
    struct epoll_event  listen_fd;
    listen_fd.data.fd=0;
    listen_fd.events=EPOLLIN;    
    int epoll_fd=epoll_create(10);
    epoll_ctl(epoll_fd,EPOLL_CTL_ADD,0,&listen_fd);

    //step2: epoll开始工作 阻塞的等待文件描述符就绪
    struct epoll_event ready_events[10];
    int ret=epoll_wait(epoll_fd,ready_events,10,-1);
    
    //step3:epoll完成工作  看自己感兴趣的套接字是否就绪
    if(ret<0){ cout<<"epoll error"<<endl; return -1;}
    else if(ret==0){cout<<"spoll time out";return -1;}
    else{
        for(int i=0;i<ret;i++){
            if(ready_events[i].data.fd==0){
                char  tmp[10];
                read(0,tmp,10);
                cout<<tmp<<endl;
            }
        }

    }

}

```





```cpp
struct epoll_event结构如下：
struct epoll_event {
    __uint32_t events; /* Epoll events */
    epoll_data_t data; /* User data variable */
};

其中
typedef union epoll_data {
    void *ptr;
    int fd;
    __uint32_t u32;
    __uint64_t u64;
} epoll_data_t;

// events特殊的宏
EPOLLLT：将EPOLL设为于水平触发(Level Triggered)。
EPOLLET：将EPOLL设为边缘触发(Edge Triggered)模式，
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
    
LT模式：水平触发模式，epoll_wait监听文件描述符，如果文件描述符就绪，不立即对该描述符进行操作，那么下一次调用epoll_wait会再通知进程，这种模式同时支持阻塞和非阻塞
ET模式：边缘触发模式，通知之后必须立即处理事件，下一次再调用epoll_wait时不会再得到该事件到达的通知，只支持非阻塞
    
```



**epoll_create**

```cpp
int epoll_create(int size);
创建一个epoll句柄，size表示需要监听的数目

struct eventpoll{
    ....
    /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/
    struct rb_root  rbr;
    /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/
    struct list_head rdlist;
    ....
};

在epoll中，每一个事件会对应一个epitem结构体
struct epitem{
    struct rb_node  rbn;//红黑树节点
    struct list_head    rdllink;//双向链表节点
    struct epoll_filefd  ffd;  //事件句柄信息
    struct eventpoll *ep;    //指向其所属的eventpoll对象
    struct epoll_event event; //期待发生的事件类型
}
```



![](C:\Users\Steven\Desktop\CS-Note\计算机基础&操作系统\pic\eventpoll.png)



**epoll_ctl**

```cpp
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
作用：指定监听事件
第一个参数是epoll_create的返回值
第二个参数表示动作，用三个宏来表示
EPOLL_CTL_ADD：注册新的fd到edfd中
EPOLL_CTL_MOD：修改已经注册的fd
EPOLL_CTL_DEL：从epfd中删除一个fd
第三个表示需要监听的fd
第四个是告诉内核需要监听什么事件以及传过来的数据放哪，即对应的事件结构体
返回值
    
原理：注册新的描述符或者改变某个文件描述符的状态，这些描述符会在内核被维护在一棵红黑树上，所有添加到epoll事件都会与设备驱动建立回调关系，一旦事件发生就会回调这个方法，然后会将发生的事件添加到rdlist的双向链表中
```





**epoll_wait**

```cpp
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
作用：监听事件
epfd表示epoll_create的返回值
events表示得到的就绪时间，内核会将得到的就绪事件的集合复制到该数组
maxevents告诉events数组的大小，不能超过epoll_create的大小
    
返回值
大于0：就绪的文件描述符个数
等于0：表示超时
小于0：表示出错（参数不合法、信号被中断）
```



为了解决select和poll缺点，使得IO复用具有更高的性能，出现了epoll,epoll主要有epoll_create\epoll_ctl\epoll_wait方法，create是用来创建一个epoll句柄，调用该方法后内核会创建一个eventpoll结构体，这个结构体有两个重要的成员变量，一个是红黑树的根节点，红黑树用来存储所有添加到epoll中需要监控的事件，双链表存放着将要通过epoll_wait返回给用户的满足条件的事件，对于每个事件都会建立epitem结构体，包含了事件的信息，期待发生的信息，epoll_ctl是epoll的注册函数，它是用来告诉内核需要监听什么事件，epoll高效的地方就在于红黑树，ctl会将监听的事件挂在红黑树上，这样重复注册的事件可以通过红黑树高效识别，所有添加到epoll事件都会与相应的设备驱动程序建立回调关系，如果该事件发生后会调用这个回调方法，回调方法会将对应的事件添加到双链表中，通过epoll_wait函数可以用来检测就绪的事件，如果检测到就绪事件，内核就会将就绪事件复制到events数组中。

可以看出epoll避免了像select、poll那样对文件描述符的重复拷贝，每次注册新事件后，ctl函数就会将其插入到红黑树当中，事件发生后，epoll并不会轮询所有注册事件，而是轮询双链表中的就绪事件，epoll同时支持水平触发和边沿触发





#### 总结



**对比**

* select使用位数组fd_set来监听事件，能监听的个数受限于FD_SETSIZE
* 源码中的do_select采用的是for循环的形式来遍历，因此文件描述符越多，性能越差
* 源码中的core_sys_select在每次轮询的时候都需要将用户态监听的位数组拷贝到内核态fds里面，产生巨大的开销
* select返回的是整个数据，需要遍历整个数组才能直到哪些句柄发生了事件
* 用户可以在一个线程里同时处理多个socket的IO请求
* 具有跨平台性
* poll底层使用的是poll_list来管理，由于是基于链表的形式，所以没有监听个数限制
* 同select一样，轮询期间都需要将监听的数据结构拷贝到内核空间，返回结果也需要遍历才能发现句柄发生了什么事件
* epoll不会向select和poll对文件描述符进行重复的拷贝，epoll_ctl对注册新事件到epoll句柄中才会将文件描述符拷贝进内核，保证了每个fd都只拷贝一次
* epoll不会向select和poll那样对文件描述符轮询，而是为每一个文件描述符指定一个回调函数，当设备准备就绪，唤醒等待队列的等待者时就会唤醒回调函数，回调函数就把就绪的文件描述符加入到就绪链表



**应用场景**

* select可移植性好，适用于所有主流平台，且需要处理的文件描述符少
* poll没有最大描述符数量的限制，如果平台支持则可以以使用poll
* epoll适用于在Linux平台，有大量描述符需要轮询





## 零拷贝



### 传统IO读写



**读操作**

读操作需要经历1次DMA拷贝、1次CPU拷贝、2次上下文切换

1. 执行read系统调用，由用户态切换为内核态
2. CPU利用DMA控制器将数据从磁盘拷贝到内核的读缓冲区
3. CPU将读缓冲区的数据从内核区拷贝到用户空间的读缓冲区
4. 由内核态切换到用户态





**写操作**

写操作需要经历1次DMA拷贝、1次CPU拷贝、2次上下文切换

1. 执行write系统调用，由用户态切换为内核态
2. CPU将用户空间的写缓冲区拷贝到内核空间的套接字缓冲区
3. CPU利用DMA控制器将套接字缓冲区拷贝到外设当中
4. 由内核态切换为用户态







### mmap+write

使用mmap来代替read，减少了一次CPU拷贝，





### sendfile



```cpp
sendfile(int socket_fd, int file_fd, int len);
```

sendfile减少了2次CPU拷贝和2次上下文切换，但是用户不能对数据进行修改，只是单纯将数据从磁盘传输到了外设





### sendfile+DMA gather copy

通过硬件的支持，DMA有了gather的功能，通过该功能，DMA可以根据内存地址以及偏移地址来批量将读缓冲区的数据直接拷贝到外设，减少了仅有一次的CPU拷贝







